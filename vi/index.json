[{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Trong trang này tôi sẽ giới thiệu chi tiết về Nhật ký công việc (Worklog) của mình. Nội dung sẽ bao quát toàn bộ quá trình thực tập: từ cách thức tôi tiếp cận và hoàn thành các nhiệm vụ, thời lượng cụ thể của chương trình, cho đến những công việc và kỹ năng thực tế mà tôi đã tích lũy được trong suốt khoảng thời gian vừa qua:\nWeek 1: Làm quen với Cloud Computing, IAM và Quản lý chi phí (AWS Budgets)\nWeek 2: Xây dựng hạ tầng mạng: VPC Multi-AZ, Bảo mật (SG/NACL) và Load Balancing (ELB)\nWeek 3: Triển khai kiến trúc Hybrid DNS với Route 53 Resolver\nWeek 4: Làm quen với AWS Console/CLI, EC2 và các dịch vụ lưu trữ cơ bản (S3, Storage Gateway)\nWeek 5: Lưu trữ nâng cao (S3 Glacier/Snow Family), Di chuyển máy ảo (VM Import) và hệ thống tệp FSx\nWeek 6: Quản trị FSx nâng cao, Phân phối nội dung (CloudFront) và Nền tảng bảo mật IAM\nWeek 7: Quản trị bảo mật doanh nghiệp (Organizations, Security Hub) và Tự động hóa với Lambda\nWeek 8: Quản lý danh tính nâng cao (IAM Advanced), Mã hóa (KMS) và Kiểm toán hệ thống (CloudTrail/Athena)\nWeek 9: Tối ưu hóa bảo mật IAM và Triển khai ứng dụng với Cơ sở dữ liệu quan hệ (RDS)\nWeek 10: Di chuyển cơ sở dữ liệu (DMS/SCT) và Xây dựng đường ống phân tích dữ liệu Serverless\nWeek 11: Cơ sở dữ liệu NoSQL (DynamoDB), Quản lý chi phí và Chuẩn bị dữ liệu với Glue DataBrew\nWeek 12: Phân tích dữ liệu lớn (EMR, Redshift), Trực quan hóa (QuickSight) và Tổng kết khóa học\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Chứng nhận ISO năm 2025 và CSA STAR hiện đã khả dụng cùng với hai dịch vụ bổ sung *Bởi Chinmaee Parulekar, đăng ngày 17 tháng 9 năm 2025, thuộc chuyên mục Announcements, Foundational (100), *Security, Identity \u0026amp; Compliance\nAmazon Web Services (AWS) đã hoàn tất thành công cuộc kiểm toán mở rộng mà không có bất kỳ phát hiện sai sót nào cho các tiêu chuẩn ISO 9001:2015, 27001:2022, 27017:2015, 27018:2019, 27701:2019, 20000-1:2018, 22301:2019 và Tiêu chuẩn Cloud Security Alliance (CSA) STAR Cloud Controls Matrix (CCM) v4.0. Cuộc kiểm toán được thực hiện bởi EY CertifyPoint, và các chứng chỉ đã được cấp lại vào ngày 13 tháng 8 năm 2025. Mục tiêu của cuộc kiểm toán là giúp AWS mở rộng phạm vi các chứng nhận ISO và CSA STAR để bao gồm thêm hai dịch vụ AWS Resource Explorer và AWS Incident Response. Các tiêu chuẩn ISO này bao phủ các lĩnh vực như quản lý chất lượng, an ninh thông tin, bảo mật đám mây, bảo vệ quyền riêng tư, quản lý dịch vụ và duy trì hoạt động kinh doanh liên tục. Việc đạt được các chứng nhận này thể hiện cam kết của AWS trong việc duy trì các biện pháp kiểm soát an ninh mạnh mẽ và bảo vệ dữ liệu khách hàng trên toàn bộ các dịch vụ của mình.\nTrong cuộc kiểm toán mở rộng này, chúng tôi đã bổ sung thêm hai dịch vụ AWS mới vào phạm vi chứng nhận kể từ lần cấp chứng chỉ gần nhất vào ngày 26 tháng 5 năm 2025. Hai dịch vụ được bổ sung bao gồm:\nAWS Resource Explorer\nAWS Security Incident Response\nĐể xem danh sách đầy đủ các dịch vụ AWS đã được chứng nhận theo tiêu chuẩn ISO và CSA STAR, vui lòng truy cập trang AWS ISO and CSA STAR Certified. Khách hàng cũng có thể truy cập các chứng chỉ này trực tiếp trong AWS Management Console thông qua AWS Artifact.\nChinmaee Parulekar là Quản lý Chương trình Tuân thủ (Compliance Program Manager) tại AWS, với 6 năm kinh nghiệm trong lĩnh vực an ninh thông tin. Cô sở hữu bằng Thạc sĩ Khoa học (Master of Science) chuyên ngành Hệ thống Thông tin Quản lý (Management Information Systems), cùng các chứng chỉ nghề nghiệp như CISA và HITRUST CCSF Practitioner. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Ngô Hữu Đạt\nSố điện thoại: 0911449689\nEmail: datngo2005@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Trí Tuệ Nhân Tạo\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Nắm vững các khái niệm cơ bản về Điện toán Đám mây theo định nghĩa của AWS. Hiểu rõ Hạ tầng Toàn cầu (Global Infrastructure) của AWS, bao gồm Region, Availability Zone (AZ), và Edge Locations. Làm quen với các công cụ quản lý cơ bản (Console, IAM) và tối ưu hóa chi phí ban đầu trên AWS. Hoàn tất thiết lập tài khoản ban đầu theo nguyên tắc bảo mật (MFA, IAM User) và quản lý ngân sách (AWS Budget) Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu định nghĩa Cloud, mô hình thanh toán, lợi ích cốt lõi (tối ưu chi phí, khả năng thêm bớt tùy ý, mở rộng toàn cầu). Nghiên cứu Hạ tầng Toàn cầu AWS (Data Center, AZ, Region, Edge Locations) 09/01/2025 09/01/2025 3 - Thực hành tạo tài khoản AWS (xác thực email, SĐT, phương thức thanh toán). Thiết lập MFA ảo cho Root User để bảo mật 09/02/2025 09/02/2025 4 - Nghiên cứu các công cụ quản lý (Console, Root/IAM User, CLI, SDK). Thực hành tạo IAM Admin Group và IAM Admin User\n09/03/2025 09/03/2025 5 - Nghiên cứu các phương thức thanh toán giảm giá (On-Demand, RI, Saving Plans, Spot Instances) và mô hình Serverless. Thực hành tạo AWS Budget theo Template (ngân sách hàng tháng) 09/04/2025 09/04/2025 6 - Thực hành tạo Cost Budget (Custom) và Usage Budget (giới hạn theo mức sử dụng). Nghiên cứu các gói AWS Support (Basic, Developer, Business, Enterprise). Dọn dẹp tài nguyên (Clean Up Budgets) 09/05/2025 09/05/2025 Kết quả đạt được tuần 1: Hiểu định nghĩa Cloud là việc phân phối tài nguyên CNTT theo nhu cầu qua Internet với chính sách thanh toán theo mức sử dụng (pay-as-you-go). Nắm vững các lợi ích cốt lõi như tối ưu hóa chi phí (có thể tắt máy chủ vào buổi tối) và khả năng thêm bớt tài nguyên tùy ý (Scalability). Hiểu cấu trúc Hạ tầng Toàn cầu: Availability Zone (AZ) được thiết kế để cô lập lỗi (fault isolation), và AWS khuyến nghị triển khai tối thiểu 2 AZ để đảm bảo tính sẵn sàng cao. Hoàn thành việc tạo tài khoản và thiết lập bảo mật cơ bản: Đã thiết lập MFA cho Root User. Đã tạo IAM Admin Group và IAM Admin User, thực hiện theo best practice hạn chế dùng Root User. Làm quen với các mô hình chi phí: On-Demand (cao nhất), Cam kết lâu dài (RI/Saving Plans), và Tài nguyên tạm thời (Spot Instances, giảm tới 90%). Đã thiết lập AWS Budget để theo dõi chi phí (Cost Budget) và giới hạn mức sử dụng tài nguyên (Usage Budget). Phân biệt được 4 gói AWS Support cơ bản (Basic miễn phí, Developer, Business cho môi trường Production, Enterprise) "},{"uri":"https://datngo196.github.io/Internship_Report/vi/4-eventparticipated/4.1-event1/","title":"AWS First Cloud Journey Community Day","tags":[],"description":"","content":"Báo cáo tổng hợp: “AWS First Cloud Journey Community Day” Mục tiêu sự kiện Thúc đẩy tầm nhìn cộng đồng AWS và kết nối các chuyên gia trong ngành. Trình diễn các ứng dụng thực tế của Generative AI trong khối Doanh nghiệp, Ngân hàng và Học thuật. Khám phá các kiến trúc tiên tiến bao gồm RAG (Retrieval-Augmented Generation) và Hệ thống Đa tác vụ (Multi-Agent Systems). Giới thiệu các giải pháp AI có khả năng mở rộng trên nền tảng Serverless. Diễn giả Nguyễn Gia Hưng – Head of Solutions Architect, AWS Phạm Tiến Thuận Phát, Lê Minh Nghĩa, Trần Đoàn Công Lý – Khối Phần mềm Doanh nghiệp Đinh Lê Hoàng Anh, Nguyễn Tài Minh Huy – Khối Học thuật Kiệt Lâm, Nguyễn Ngọc Quỳnh Mai – Khối Ngân hàng / CNTT Nội bộ Lê Phạm Ngọc Uyển, Phan Thị Thanh Thảo, Hồ Điền Đăng Khoa, Nguyễn Quang Nhật Linh – Khối Ngân hàng / Tự động hóa quy trình Việt Lý – AWS Partner / Cloud \u0026amp; AI Nội dung nổi bật 1. Tầm nhìn cộng đồng Phát biểu khai mạc: Ông Nguyễn Gia Hưng đã mở đầu sự kiện tại tháp Bitexco, chia sẻ về tầm nhìn của cộng đồng AWS và mục tiêu lan tỏa các kiến thức điện toán đám mây thực tiễn. 2. Doanh nghiệp \u0026amp; AI theo ngữ cảnh Enterprise Chatbot với MCP: Nhóm diễn giả đã trình bày về việc mở khóa ngữ cảnh sử dụng Model Context Protocol (MCP) trên AWS. Bài tham luận tập trung vào cách xây dựng chatbot xử lý ngữ cảnh doanh nghiệp phức tạp và các bài học kinh nghiệm xương máu. 3. Ứng dụng GenAI thực tế Hệ thống gợi ý công thức nấu ăn: Một dự án học thuật sử dụng GenAI để cá nhân hóa gợi ý món ăn. Phần này đi sâu vào thiết kế quy trình (workflow design) trên AWS. Internal Chatbot với RAG: Đi sâu vào việc xây dựng chatbot hỏi đáp nội bộ sử dụng RAG. Điểm nhấn là kiến trúc hoàn toàn Serverless, giúp tối ưu chi phí và vận hành. 4. Tự động hóa nâng cao trong Ngân hàng Hệ thống Multi-Agent: Phiên thảo luận nổi bật về việc áp dụng GenAI Multi-Agent Systems để tự động hóa các quy trình ngân hàng. Các diễn giả chia sẻ case study thực tế về cách các Agent phối hợp xử lý tác vụ thông qua serverless workflows. 5. Công cụ \u0026amp; Điều phối GenAI với Kiro IDE \u0026amp; Strands Agent: Khám phá ứng dụng GenAI trong cả môi trường Production và R\u0026amp;D. Phiên này tập trung vào điều phối quy trình (workflow orchestration) và demo trực tiếp mô hình multi-agent trên AWS. Bài học chính (Key Takeaways) Chuyển dịch kiến trúc Từ Chatbot sang Agent: Ngành công nghệ đang chuyển dịch từ các bot hỏi đáp đơn giản sang Hệ thống Multi-Agent có khả năng thực thi các tác vụ phức tạp, đặc biệt trong các ngành được quy định chặt chẽ như Ngân hàng. Serverless là nền tảng: Cả hệ thống RAG và Agent đều được demo chủ yếu trên hạ tầng AWS Serverless, khẳng định đây là tiêu chuẩn cho việc triển khai AI hiện đại. Triển khai thực tiễn Ngữ cảnh là then chốt: Để doanh nghiệp áp dụng thành công, việc xử lý ngữ cảnh (qua MCP hoặc RAG) là yếu tố quyết định độ chính xác. Sự cần thiết của Orchestration: Các công cụ như Kiro IDE đang nổi lên để giúp quản lý sự phức tạp của các luồng công việc AI. Ứng dụng vào công việc Đánh giá Multi-Agent: Nghiên cứu áp dụng phương pháp Multi-Agent cho các tác vụ tự động hóa nội bộ phức tạp thay vì dùng một mô hình đơn lẻ. Triển khai Serverless RAG: Rà soát các kho tri thức nội bộ hiện tại và xây dựng prototype giải pháp RAG trên nền tảng Serverless. Nghiên cứu MCP: Tìm hiểu Model Context Protocol để xem xét khả năng cải thiện khả năng ghi nhớ ngữ cảnh cho các ứng dụng chatbot hiện tại. Trải nghiệm sự kiện Sự kiện tại Bitexco Tower mang lại một buổi sáng dày đặc kiến thức chuyên môn. Các phiên song song cho phép đi sâu vào từng lĩnh vực cụ thể.\nKết nối (Networking): Thời gian \u0026ldquo;Welcome Coffee\u0026rdquo; và giải lao là cơ hội tuyệt vời để trao đổi với các AWS Solution Architect và đồng nghiệp trong ngành. Demo thực tế: Việc chứng kiến demo trực tiếp của hệ thống Multi-Agent trong ngân hàng và Gợi ý món ăn đã giúp thu hẹp khoảng cách giữa lý thuyết GenAI và sản phẩm thực tế. Một số hình ảnh sự kiện Thêm hình ảnh sự kiện của bạn tại đây\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Tự động xoay vòng OIDC client secret với Application Load Balancer *Bởi Kani Murugan, đăng ngày 16 tháng 9 năm 2025, thuộc các chuyên mục: Advanced 300, Security, Identity, \u0026amp; Compliance ,Technical How-to.\nElastic Load Balancing đơn giản hóa việc xác thực bằng cách chuyển giao công việc này cho các nhà cung cấp danh tính (IdP) tương thích với OpenID Connect (OIDC). Điều này cho phép các nhà phát triển tập trung vào logic ứng dụng trong khi vẫn sử dụng cơ chế quản lý danh tính mạnh mẽ.\nOIDC client secret là các thông tin đăng nhập bí mật được sử dụng trong các giao thức OAuth 2.0 và OIDC để xác thực client (ứng dụng). Tuy nhiên, việc quản lý thủ công OIDC client secret có thể tạo rủi ro bảo mật và gia tăng gánh nặng vận hành.\nNhư hình 1 minh họa, quản lý thủ công OIDC client secret bắt đầu bằng xác thực thông qua một IdP bên thứ ba.\nHình 1: Quản lý thủ công OIDC client secret\nCác rủi ro khi quản lý thủ công OIDC client secret bao gồm:\nLộ thông tin đăng nhập dạng plaintext\nCần can thiệp thủ công để điều chỉnh cấu hình Application Load Balancer (ALB) Thiếu giám sát chủ động đối với thay đổi của thông tin đăng nhập\nThiếu xác minh liên tục các thông tin xác thực\nKhông khả thi khi mở rộng cấu hình ALB với nhiều listener rules \\\nTrong bài viết này, tôi sẽ hướng dẫn cách tự động xoay vòng OIDC client secret bằng AWS Secrets Manager, AWS Lambda và AmazonEventBridge, giúp nâng cao bảo mật và tối ưu hóa vận hành. Tự động xoay vòng secret là một thực hành bảo mật quan trọng, giúp giảm thiểu rủi ro lộ thông tin đăng nhập và hỗ trợ tuân thủ liên tục.\nĐối với cấu hình ALB-OIDC authentication, xem hướng dẫn Authenticate, Users using an Application Load Balancer.\nTổng quan giải pháp Giải pháp này cung cấp khung linh hoạt để quản lý thông tin đăng nhập tự động trên nhiều nhà cung cấp OIDC (Auth0 làm ví dụ), với một triển khai cụ thể tích hợp với các dịch vụ AWS. Kiến trúc cốt lõi hỗ trợ: xoay vòng thông tin đăng nhập tự động, lưu trữ bí mật an toàn, thiết kế không phụ thuộc vào nhà cung cấp (provider-agnostic), triển khai mở rộng cho các workflow xác thực khác nhau. Các thành phần chính bao gồm:\nSecrets Manager: Lưu trữ và quản lý an toàn thông tin đăng nhập OIDC (Auth0).\nLambda: Thực thi logic xoay vòng secret theo lịch định sẵn.\nElastic Load Balancing: Chuyển giao việc xác thực bằng các OIDC listener rules.\nEventBridge (scheduled): Kích hoạt Lambda theo lịch đã định.\nCustom AWS CloudFormation resource: Tự động hóa toàn bộ stack và kiến trúc được sử dụng trong bài viết này.\nHình 2: Tự động xoay vòng OIDC client secret\nWorkflow xác thực, như minh họa trong Hình 2, bao gồm các bước:\nEventBridge kích hoạt Lambda handler** Auth0CredentialHandler **mỗi 15 phút.\nLambda handler ``uth0CredentialHandler** **kết nối đến domain quản lý Auth0 và lấy thông tin client hiện tại — auth0_current.\nLambda handler ``Auth0CredentialHandler** truy xuất thông tin đăng nhập hiện có **auth0/credentials/${Auth0-dev-domain} từ Secrets Manager và so sánh với thông tin ``auth0_current đã lấy ở bước trước.\nNếu secret không tìm thấy, handler sẽ thử lại 3 lần trong vòng 30 phút và sau đó ghi log cảnh báo vào AWS CloudWatch.\nGiả định rằng ARN của secret đã tồn tại trong Secrets Manager\nNếu thông tin đăng nhập khác nhau, Auth0CredentialHandler **cập nhật auth0/credentials/${Auth0-dev-domain} **với giá trị mới. Nếu thông tin đăng nhập giống nhau, không thực hiện hành động nào. CloudWatch alarms được cấu hình để kích hoạt khi cập nhật secret thành công hoặc thất bại.\nALB listener rule được cấu hình để lấy thông tin client credentials một cách động từ ARN của resource auth0/credentials/${Auth0-dev-domain}** **trong Secrets Manager.\nKhuyến nghị bảo mật\nCó một số biện pháp để nâng cao bảo mật hệ thống xác thực, bao gồm: triển khai quản lý secret tập trung với mã hóa dữ liệu khi lưu trữ (encryption at rest), cấu hình Lambda với quyền tối thiểu (least-privilege), chỉ giới hạn truy cập đến các resource cần thiết trong Secrets Manager và ALB listener, giúp giảm phạm vi rủi ro bảo mật (security blast radius).\nSử dụng CloudWatch alarms để giám sát các sự kiện quan trọng, bao gồm Cập nhật secret, Thất bại khi cập nhật secret, Các vấn đề liên quan đến credential của ALB và Sử dụng AWS Config để theo dõi cấu hình rule và thực hiện đánh giá bảo mật định kỳ.\nBằng cách Tạo secret riêng biệt cho từng ALB listener rule, cho phép kiểm soát truy cập chi tiết (granular access control) và thu hẹp phạm vi quyền hạn, giúp nâng cao bảo mật tổng thể của hệ thống.\nBằng cách tuân theo các thực hành này, bạn có thể thiết lập khung bảo mật vững chắc cho ứng dụng, đồng thời đảm bảo bảo vệ dữ liệu và quản lý truy cập đúng cách.\nYêu cầu tiên quyết\nGiải pháp này giả định rằng các điều kiện sau đã được đáp ứng trước khi triển khai:\nMột ALB hiện có được cấu hình với listener và target group, sử dụng làm Listenerarn và targetarn trong CloudFormation template.\nTài khoản OIDC IdP (ví dụ: Auth0) và ứng dụng client.\nThông tin đăng nhập client của ứng dụng Auth0 IdP đã được lưu trữ trong Secrets Manager.\n{ \u0026#34;domain\u0026#34;: \u0026#34;your-tenant.auth0.com\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;your-client-id\u0026#34;, \u0026#34;client_secret\u0026#34;: \u0026#34;your-client-secret\u0026#34; } Chi tiết triển khai\nLưu ý: Giải pháp này minh họa tự động xoay vòng OIDC client secret sử dụng Auth0 làm IdP. Mặc dù các nguyên tắc cốt lõi và mô hình kiến trúc có thể áp dụng rộng rãi, các chi tiết triển khai cụ thể có thể khác nhau tùy từng nhà cung cấp danh tính. Người dùng nên tham khảo tài liệu của IdP cụ thể để biết các bước cấu hình chính xác, cách tương tác API và các cơ chế xác thực tương thích với AWS.\nĐây là một phương pháp tự động, đơn giản và có thể mở rộng, sử dụng CloudFormation custom resource để tạo các resource được minh họa trong sơ đồ kiến trúc. CloudFormation template và AWS Lambda implementation được lưu trữ trong demo-stack.\nCác thành phần cốt lõi\nTrong phần này, tôi sẽ giải thích các thành phần chính của giải pháp.\nQuy tắc làm mới thông tin xác thực\nMột EventBridge rule được lên lịch để kích hoạt Lambda function Auth0CredentialHandler** **mỗi 15 phút, sử dụng LambdaInvokePermission của AWS Identity and Access Management (IAM) role.\nAuth0CredentialHandler Lambda function\nLambda function ``Auth0CredentialHandler chịu trách nhiệm quản lý client credentials một cách an toàn. Nó truy xuất cấu hình Auth0 từ Secrets Manager tại resource auth0/credentials/${Auth0-dev-domain}, thực hiện API call đến domain Auth0 để lấy token mới, quản lý cập nhật thông tin đăng nhập mới vào Secrets Manager. Lambda này cần quyền truy cập Secrets Manager, được cấp thông qua execution role.\nIAM role của Lambda có hai bộ quyền chính:\nAWS managed policy ``AWSLambdaBasicExecutionRole, cho phép Lambda tạo log trên CloudWatch. \\\nCustom policy, cấp quyền cụ thể trên Secrets Manager (``GetSecretValue``, ``CreateSecret``, ``UpdateSecret``) cho các secret dưới path auth0/credentials/${Auth0-dev-domain}.\nLambda sẽ thử lại 3 lần trong vòng 30 phút. Nếu tất cả các lần thử thất bại, CloudWatch sẽ ghi cảnh báo và tạo alarms.\nManagedPolicyArns: - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole Policies: - PolicyName: SecretsManagerAccess PolicyDocument: Version: \u0026#39;2012-10-17\u0026#39; Statement: - Effect: Allow Action: - secretsmanager:GetSecretValue - secretsmanager:CreateSecret - secretsmanager:UpdateSecret Resource: - !Sub arn:aws:secretsmanager:${AWS::Region}:${AWS::AccountId}:secret:auth0/* # Permission for Amazon EventBridge to invoke Lambda LambdaInvokePermission: Type: AWS::Lambda::Permission Properties: Action: lambda:InvokeFunction FunctionName: !Ref Auth0CredentialHandler Principal: events.amazonaws.com SourceArn: !GetAtt CredentialRefreshRule.Arn ALB Listener Rules\nCác resource listener rule của Elastic Load Balancing trong CloudFormation được cấu hình để lấy động thông tin client credentials từ Secrets Manager và chuyển tiếp các request đã xác thực đến target group cụ thể. Chúng tích hợp với thông tin đăng nhập Auth0, được Lambda** Auth0CredentialHandler **tự động làm mới định kỳ. Cấu hình này yêu cầu quyền đọc (read access) trên Secrets Manager để lấy Auth0 client credentials phục vụ quá trình xác thực.\n# ALB Listener Rules - replace the Oidc config with your endpoints. Only Client credentials are stored in SecretsManager ListenerRule1: Type: AWS::ElasticLoadBalancingV2::ListenerRule Properties: ListenerArn: arn:aws:elasticloadbalancing:region:account-id:listener/app/my-load-balancer/1234567890/abcdef Priority: 1 Actions: - Type: authenticate-oidc AuthenticateOidcConfig: ClientId: \u0026#39;{{resolve:secretsmanager:auth0/credentials/your-tenant.auth0.com:SecretString:client_id}}\u0026#39; ClientSecret: \u0026#39;{{resolve:secretsmanager:auth0/credentials/your-tenant.auth0.com:SecretString:client_secret}}\u0026#39; Issuer: https://idp1.example.com AuthorizationEndpoint: https://idp1.example.com/auth TokenEndpoint: https://idp1.example.com/token UserInfoEndpoint: https://idp1.example.com/userinfo OnUnauthenticatedRequest: authenticate - Type: forward TargetGroupArn: arn:aws:elasticloadbalancing:region:account-id:targetgroup/target-group-1/1234567890abc Conditions: - Field: path-pattern Values: - /app1/* Giám sát và cảnh báo với CloudWatch\nCloudFormation template được cung cấp được cấu hình để thiết lập giám sát bảo mật cho các cập nhật secret. Template này thực hiện Cấu hình cảnh báo cho cả cập nhật secret thành công và cập nhật thất bại, Tạo các CloudWatch metric filter sử dụng AWS CloudTrail logs, Thiết lập các alarm tương ứng với các ngưỡng đã định, Tạo một Amazon Simple Notification Service (Amazon SNS) topic để gửi cảnh báo tổng hợp. Khi triển khai, giải pháp hạ tầng như mã (infrastructure-as-code) này sẽ tự động phát hiện và thông báo các sự kiện bảo mật tiềm ẩn liên quan đến quản lý secret và các nỗ lực truy cập trái phép.\n# CloudWatch Log Group CloudTrailLogGroup: Type: AWS::Logs::LogGroup Properties: LogGroupName: secrets-manager-monitoring RetentionInDays: 14 # Combined Metric Filter for Both Success and Failed Updates SecretUpdateMetricFilter: Type: AWS::Logs::MetricFilter Properties: LogGroupName: !Ref CloudTrailLogGroup FilterPattern: !Sub \u0026#39;{ $.eventSource = secretsmanager.amazonaws.com \u0026amp;\u0026amp; ($.eventName = UpdateSecret || $.eventName = PutSecretValue) \u0026amp;\u0026amp; $.responseElements.ARN = \u0026#34;${MyCustomResource.SecretArn}\u0026#34; }\u0026#39; MetricTransformations: - MetricNamespace: \u0026#39;SecretsManager/Updates\u0026#39; MetricName: \u0026#39;SecretUpdates\u0026#39; MetricValue: \u0026#39;1\u0026#39; DefaultValue: 0 # Combined Alarm for Both Success and Failed Updates SecretUpdateAlarm: Type: AWS::CloudWatch::Alarm Properties: AlarmName: !Sub \u0026#39;${AWS::StackName}-secret-update\u0026#39; AlarmDescription: !Sub \u0026#39;Alarm for any updates (success or failure) to secret ${MyCustomResource.SecretArn}\u0026#39; MetricName: SecretUpdates Namespace: SecretsManager/Updates Statistic: Sum Period: 300 EvaluationPeriods: 1 Threshold: 0 ComparisonOperator: GreaterThanThreshold TreatMissingData: notBreaching AlarmActions: - !Ref SecretMonitoringTopic Để nâng cao độ tin cậy của quá trình xoay vòng secret, hãy triển khai giám sát toàn diện bằng cách: Tạo CloudWatch alarms để phát hiện thất bại khi Lambda thực hiện xoay vòng vượt quá ngưỡng và tỷ lệ lỗi xác thực cao, Giám sát các đột biến bất thường trong tỷ lệ lỗi HTTP 4xx và 5xx từ ALB, Sử dụng CloudTrail để theo dõi các API call và thay đổi cấu hình liên quan đến secrets trong Secrets Manager và các thiết lập load balancer. Bằng cách triển khai các alarm tùy chỉnh này cùng với các cấu hình mặc định, các sự cố bảo mật tiềm ẩn và nỗ lực truy cập trái phép có thể được phát hiện nhanh chóng trên toàn bộ tài nguyên AWS của bạn. Phương pháp nhiều lớp này giúp duy trì khả năng giám sát quá trình xoay vòng secret và nhanh chóng xác định, phản ứng với các vấn đề tiềm ẩn.\nXem hướng dẫn chi tiết tại Creating CloudWatch alarms for CloudTrail events: examples.\nQuy trình triển khai\nTriển khai CloudFormation template bằng AWS Command Line Interface (AWS CLI) hoặc AWS Management Console. Thay \u0026lt;your-region\u0026gt; bằng AWS Region mà bạn muốn triển khai giải pháp.\naws cloudformation deploy \\ --template-file template.yaml \\ --stack-name oidc-credential-manager-stack \\ --capabilities CAPABILITY_IAM \\ --region Lưu ý: Bạn có thể thêm các tham số bổ sung nếu được yêu cầu bởi cấu hình IdP của bạn.\nKiểm thử và xác minh\nTuyên bố: Khuyến nghị thử nghiệm trong môi trường riêng biệt, không quan trọng để đảm bảo mọi cài đặt cụ thể của khách hàng được xác minh đầy đủ trước khi triển khai vào môi trường sản xuất.\nĐối với cập nhật secret, hãy xác minh rằng các CloudWatch alarms đã được cấu hình được kích hoạt. Đối với xác thực ALB, kiểm tra ALB access logs để tìm các entry authentication_success và sự hiện diện của OIDC identity tokens.\nThiết lập CloudWatch metrics và alarms để giám sát quá trình xoay vòng secret và tỷ lệ xác thực thành công. Xác minh các trường hợp thất bại bằng cách sửa thủ công cấu hình ALB rule trỏ tới một secret ARN khác và xác nhận rằng CloudWatch alarm được kích hoạt. Dưới đây là một ví dụ về sự kiện CloudTrail cho một cập nhật Secrets Manager thành công.\n{ \u0026#34;source\u0026#34;: [\u0026#34;aws.secretsmanager\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;AWS API Call via CloudTrail\u0026#34;], \u0026#34;detail\u0026#34;: { \u0026#34;eventSource\u0026#34;: [\u0026#34;secretsmanager.amazonaws.com\u0026#34;], \u0026#34;eventName\u0026#34;: [\u0026#34;UpdateSecret\u0026#34;], \u0026#34;responseElements\u0026#34;: {\u0026#34;status\u0026#34;: \u0026#34;Success\u0026#34;} } } Sau đây là một ví dụ về nhật ký truy cập ALB:\n/aws/alb/\u0026lt;your-alb-name\u0026gt;: - Look for entries containing: \u0026#34;authentication_success\u0026#34; \u0026#34;id_token_authentication_successful\u0026#34; \u0026#34;x-amzn-oidc-identity\u0026#34; HTTP status code 200 - Example log pattern: timestamp elb_name client:port target:port request_processing_time target_processing_time response_processing_time status_code \u0026#34;authentication_success\u0026#34; \u0026#34;x-amzn-oidc-identity: [token]\u0026#34; Kịch bản nâng cao\nTrong phần này, bạn sẽ học cách giảm thời gian chờ và làm cho cập nhật Secrets Manager gần như đồng bộ (synchronous).\nTối ưu hóa đồng bộ Secrets Manager: Sử dụng EventBridge partner tích hợp để cấu hình EventBridge gọi Lambda function dựa trên các sự kiện nhận được từ IdP bên thứ ba. Xem hướng dẫn chi tiết tại Receiving events from a SaaS partner with Amazon EventBridge . \\\nXoay vòng client ID: Trong khi xoay vòng client secret là kịch bản phổ biến nhất, đôi khi cũng cần xoay vòng client ID. Trong hầu hết các IdP, điều này có nghĩa là tạo một client ứng dụng mới và di chuyển các resource. Để thực hiện, Lambda Auth0CredentialHandler cần quyền sửa đổi ALB listener rules (elasticloadbalancing``:``ModifyRule``, ``elasticloadbalancing``:DescribeListeners, ``elasticloadbalancing``:DescribeRules). Xoay vòng client ID có thể gây gián đoạn xác thực tạm thời, vì vậy thử nghiệm kỹ lưỡng là cần thiết. Sử dụng AWS Config để giám sát cấu hình ALB rule nhằm phát hiện các thay đổi bất ngờ. Tính năng này tăng cường bảo mật tổng thể, mặc dù có thể tăng độ phức tạp của giải pháp và đôi khi cần can thiệp thủ công. \\\nChiến lược đa nhà cung cấp (multi-provider): Nếu tổ chức của bạn quản lý nhiều IdP, hãy triển khai framework xoay vòng tập trung để trừu tượng hóa các khác biệt riêng của nhà cung cấp, tập trung vào các nguyên tắc bảo mật cốt lõi được nêu trong bài viết này. Các cân nhắc chính bao gồm: tạo giao diện độc lập với nhà cung cấp để hỗ trợ giám sát toàn diện và giảm thiểu chi phí cấu hình.\nKết luận\nTrong bài viết này, bạn đã khám phá cách tiếp cận toàn diện để tự động xoay vòng OIDC client secret sử dụng các dịch vụ của AWS. Bằng cách triển khai giải pháp này, bạn có thể: Nâng cao bảo mật ứng dụng, Giảm thiểu chi phí quản lý thủ công, Duy trì chiến lược xác thực vững chắc. Hãy cân nhắc khám phá các kỹ thuật quản lý danh tính nâng cao hoặc tích hợp xác thực đa yếu tố (MFA) với triển khai OIDC của bạn. Nếu bạn mới làm quen với tự động xoay vòng secrets, tham khảo bài viết Back to Basics: Secrets Management.\nKani Murugan là một kỹ sư bảo mật đã được bổ nhiệm biên chế (tenured) tại Amazon Security, nơi cô chuyên về bảo mật sản phẩm, tập trung vào bảo mật ứng dụng, mạng và dữ liệu. Với hơn 8 năm kinh nghiệm trong nhiều lĩnh vực bảo mật khác nhau, Kani mang đến cho công việc của mình một nền tảng kiến thức phong phú. Ngoài công việc, Kani là người đam mê anime và là một độc giả “không kén chọn”, đọc nhiều chủ đề đa dạng. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/2-proposal/","title":"Đề xuất","tags":[],"description":"","content":"MAPVIBE - Nền tảng Khám phá Vị trí Bản đồ Powered by AI (Khám phá các địa điểm ăn uống và các địa điểm khác tại Thành phố Hồ Chí Minh sử dụng các gợi ý ngôn ngữ tự nhiên và thông tin chi tiết theo ngữ cảnh)\n1. Tóm tắt Điều hành MapVibe là một nền tảng web driven by AI được ra mắt tại Thành phố Hồ Chí Minh để biến đổi việc khám phá địa điểm, cho phép người dùng tìm kiếm địa điểm thông qua các gợi ý ngôn ngữ tự nhiên (ví dụ: \u0026ldquo;tìm nhà hàng sang trọng trên tầng thượng có view thành phố mở cửa đến nửa đêm\u0026rdquo; hoặc \u0026ldquo;quán cà phê yên tĩnh gần sông có chỗ ngồi ngoài trời\u0026rdquo;). Nền tảng sử dụng Mô hình Ngôn ngữ Lớn (LLMs) của Amazon Bedrock để diễn giải ý định của người dùng, tích hợp các yếu tố ngữ cảnh theo thời gian thực như vị trí, thời gian và sở thích, và truy xuất dữ liệu từ cơ sở dữ liệu nội bộ DynamoDB. Xây dựng trên kiến trúc AWS serverless, MapVibe cung cấp độ trễ thấp (\u0026lt;10s), độ chính xác cao (≥85% sự hài lòng tương ứng), và hiệu quả chi phí (\u0026lt;$200 cho chu kỳ phát triển và demo 8 tuần ban đầu, hoàn thành vào ngày 22 tháng 10 năm 2025). Người dùng đã xác thực tận hưởng các đề xuất được cá nhân hóa, khả năng đóng góp đánh giá, và truy cập các công cụ kiểm duyệt, tất cả được nâng cao bởi công nghệ AI.\n2. Phát biểu Vấn đề Vấn đề là gì? Các nền tảng bản đồ truyền thống như Google Maps phụ thuộc vào tìm kiếm dựa trên từ khóa và bộ lọc tĩnh, gặp khó khăn trong việc diễn giải các truy vấn tinh tế, giàu ngữ cảnh (ví dụ: \u0026ldquo;quán cà phê yên tĩnh gần sông có chỗ ngồi ngoài trời\u0026rdquo;). Người dùng lãng phí thời gian điều hướng nhiều ứng dụng để tìm địa điểm ăn uống hoặc hoạt động phù hợp. Các giải pháp hiện tại thiếu giao diện trò chuyện và không kết hợp được các tín hiệu ngữ cảnh như thời gian, tâm trạng hoặc kích thước nhóm. Giải pháp MapVibe sử dụng AWS Bedrock LLMs để phân tích các gợi ý ngôn ngữ tự nhiên bằng tiếng Việt và tiếng Anh, chuyển đổi chúng thành các truy vấn có cấu trúc. Nó truy xuất và xếp hạng kết quả từ cơ sở dữ liệu nội bộ DynamoDB với dữ liệu địa điểm được lập chỉ mục địa lý, cung cấp giao diện kết hợp (tìm kiếm trò chuyện + bộ lọc danh mục). Nội dung do người dùng tạo (đánh giá, gợi ý địa điểm) được kiểm duyệt sử dụng AWS Rekognition, đảm bảo an toàn và chất lượng thông qua phân tích driven by AI tiên tiến.\nLợi ích và ROI Tốc độ: Giảm thời gian khám phá địa điểm từ vài phút xuống vài giây. Cá nhân hóa: Kết quả nhận biết ngữ cảnh dựa trên sở thích và hành vi của người dùng, powered by AI. Tự động hóa: Loại bỏ bộ lọc thủ công với phân tích ý định driven by AI. Khả năng mở rộng: Cơ sở hạ tầng AWS toàn cầu đảm bảo độ trễ thấp và khả năng phục hồi. Hiệu quả chi phí: Tối ưu hóa để phù hợp với ngân sách $200 cho chu kỳ 8 tuần ban đầu, hoàn thành vào ngày 22 tháng 10 năm 2025. Tiềm năng thương mại: Cơ hội hợp tác với các doanh nghiệp địa phương hoặc tích hợp với các hệ thống đặt phòng nội bộ. 3. Kiến trúc Giải pháp Tổng quan Gợi ý Người dùng + Ngữ cảnh → Phân tích Ý định Bedrock LLM → Truy vấn có Cấu trúc → Tìm kiếm DynamoDB → Xếp hạng \u0026amp; Bộ nhớ đệm → Hiển thị Web UI → Vòng lặp Phản hồi Người dùng.\nDịch vụ AWS được sử dụng Service Function Amazon Route 53 Định tuyến tên miền AWS Certificate Manager Chứng chỉ SSL/TLS AWS WAF Tường lửa ứng dụng web Amazon CloudFront CDN toàn cầu cho tài sản tĩnh Amazon API Gateway Điểm cuối API RESTful an toàn AWS Lambda Logic phân tích ý định, tìm kiếm và xếp hạng Amazon DynamoDB Dữ liệu địa điểm được lập chỉ mục địa lý và bộ nhớ đệm truy vấn Amazon S3 Lưu trữ ảnh, nhật ký và tài sản Amazon Cognito Xác thực và ủy quyền người dùng Amazon Bedrock LLM để phân tích ý định và tóm tắt Amazon Rekognition Kiểm duyệt nội dung driven by AI cho các tải lên của người dùng Amazon EventBridge Phân tích theo lịch và cập nhật huy hiệu Amazon CloudWatch Giám sát và ghi nhật ký Thiết kế Thành phần Frontend: Ứng dụng web responsive (Next.js, song ngữ VI/EN, UI tìm kiếm kết hợp). Tiếp nhận Dữ liệu: Gợi ý và ngữ cảnh được xử lý qua API Gateway; các tải lên của người dùng (đánh giá, ảnh) được kiểm duyệt bởi AI của Rekognition. Lưu trữ Dữ liệu: DynamoDB cho dữ liệu địa điểm và truy vấn được bộ nhớ đệm (TTL 24 giờ); S3 cho ảnh và nhật ký. Xử lý Dữ liệu: Microservices Lambda xử lý các cuộc gọi Bedrock LLM, thực thi truy vấn và xếp hạng kết quả. Quản lý Người dùng: Cognito cho xác thực dựa trên JWT (đăng nhập email/mạng xã hội); người dùng khách truy cập các tính năng hạn chế. Đầu ra: Hiển thị thẻ địa điểm với tóm tắt được tạo bởi AI, đánh giá, ảnh và CTA (ví dụ: Chỉ đường, Gọi). 4. Triển khai Kỹ thuật Các giai đoạn Triển khai Phase Description Duration 1 Xác định kiến trúc, schema gợi ý Bedrock và schema DynamoDB 2 tuần 2 Ước tính chi phí và tối ưu hóa chiến lược bộ nhớ đệm 1 tuần 3 Xây dựng backend (Lambda, DynamoDB, Bedrock, Rekognition) 3 tuần 4 Phát triển frontend (Next.js, song ngữ, UI responsive) 3 tuần 5 Kiểm tra và tối ưu hóa cho độ trễ \u0026lt;10s và khả năng mở rộng 2 tuần 6 Ra mắt MVP, triển khai qua CI/CD, thu thập phản hồi 2 tuần Yêu cầu Kỹ thuật Thiết bị Edge: Trình duyệt hiện đại (Chrome, Safari, Firefox) với UI responsive sẵn sàng PWA. Cloud: AWS Route 53, ACM, WAF, CloudFront, API Gateway, Lambda, DynamoDB, S3, Cognito, Bedrock, Rekognition, EventBridge, CloudWatch. Công cụ \u0026amp; Framework: Next.js (App Router), TypeScript, AWS CDK cho infrastructure-as-code, GitHub Actions cho CI/CD. 5. Lịch trình \u0026amp; Cột mốc Period Activities Trước khi Phát triển (Tháng 0 - 9/2025) Nghiên cứu các bộ dữ liệu địa điểm tại Thành phố Hồ Chí Minh cho DynamoDB Tháng 1 (10/2025) Xây dựng backend MVP với Bedrock LLM và DynamoDB Tháng 2 (11/2025) Triển khai bộ nhớ đệm, phát triển tích hợp frontend Tháng 3 (11/2025) Ra mắt beta công khai, tối ưu hóa hiệu suất, thu thập phản hồi Sau khi Ra mắt (12/2025) Thêm các tính năng nâng cao (ví dụ: xếp hạng dựa trên ML, chế độ ngoại tuyến) 6. Ước tính Ngân sách Chi phí Cơ sở hạ tầng Đám mây AWS Service Cost/Month (USD) Description Lambda 15 API + LLM logic DynamoDB 10 Cached query store S3 5 Logs, static files API Gateway 10 Request routing Cognito 5 Auth MAU CloudFront 10 Hosting/CDN Bedrock (LLM tokens) 15 Prompt parsing Rekognition 5 Batch image moderation CloudWatch 5 Error-only logging Total ≈ 80/tháng ≈ 160/8 tuần Biện pháp Tối ưu hóa Chi phí Sử dụng Free-Tier: Tận dụng các miễn phí của AWS cho Lambda, DynamoDB, S3, CloudFront, Rekognition và Cognito để giảm thiểu chi phí. Bộ nhớ đệm Aggressive cho Bedrock: Đạt tỷ lệ truy cập bộ nhớ đệm 95% để giảm chi phí token AI từ $120 xuống \u0026lt;$15/tháng. Xử lý Batch Rekognition: Các kiểm tra hình ảnh không theo thời gian thực tiết kiệm ~$80 trong 8 tuần. Kiểm tra Tải được Đơn giản hóa: Kịch bản 100 người dùng × 10 phút thay vì 300 × 30 phút giảm chi phí tính toán. Giảm ghi nhật ký CloudWatch: Chỉ ghi nhật ký lỗi tiết kiệm $50+ trong 8 tuần. Không có Đồng thời được Cung cấp: Tránh chi phí Lambda nhàn rỗi. Biến môi trường: Sử dụng thay vì Secrets Manager để loại bỏ phí lưu trữ bí mật. Chế độ On-Demand DynamoDB: Tất cả đọc/ghi miễn phí theo cấp. Vô hiệu hóa Origin Shield: Tiết kiệm chi phí CloudFront. Bộ nhớ đệm Tài sản Tĩnh: Tối thiểu hóa chi phí truyền dữ liệu đi ra. Kịch bản Ngân sách Đề xuất Để đảm bảo nền tảng MapVibe hoạt động hiệu quả trong ngân sách AWS $200 trong chu kỳ phát triển và demo 8 tuần ban đầu (hoàn thành vào ngày 22 tháng 10 năm 2025), chúng tôi đề xuất các kịch bản sau dựa trên các mức độ tối ưu hóa và sử dụng tài nguyên khác nhau:\nKịch bản Tối thiểu: Tập trung vào các tính năng thiết yếu với sự phụ thuộc tối đa vào các miễn phí. Điều này bao gồm vô hiệu hóa các dịch vụ không quan trọng như WAF nếu không cần thiết, giới hạn các cuộc gọi Bedrock chỉ cho các truy vấn được bộ nhớ đệm (nhắm đến tỷ lệ truy cập bộ nhớ đệm 98%+), và không thực hiện kiểm tra tải. Chi phí ước tính: \u0026lt;$50 trong 8 tuần. Phù hợp cho prototyping ban đầu nhưng có thể ảnh hưởng đến độ tin cậy của demo do các vấn đề về khả năng mở rộng chưa được kiểm tra.\nKịch bản Đề xuất: Cân bằng chi phí và độ tin cậy bằng cách kết hợp tất cả các biện pháp tối ưu hóa chính được liệt kê ở trên. Kịch bản này sử dụng bộ nhớ đệm aggressive (tỷ lệ truy cập 95% cho Bedrock), xử lý batch cho Rekognition, kiểm tra tải đơn giản hóa (100 người dùng × 10 phút), và chỉ ghi nhật ký lỗi trong CloudWatch. Nó đảm bảo độ trễ thấp và khả năng phục hồi trong khi vẫn nằm dưới ngân sách. Chi phí ước tính: ~$100-150 trong 8 tuần. Lý tưởng cho demo MVP ra mắt vào ngày 22 tháng 10 năm 2025, cung cấp trải nghiệm mạnh mẽ mà không có chi phí không cần thiết.\nKịch bản Nâng cao: Bao gồm các điều khoản bổ sung cho việc sử dụng cao hơn sau khi ra mắt, chẳng hạn như đồng thời được cung cấp cho Lambda trong giờ cao điểm và ghi nhật ký đầy đủ trong CloudWatch để gỡ lỗi chi tiết. Điều này làm tăng chi phí một chút nhưng nâng cao giám sát hiệu suất và kiểm tra khả năng mở rộng (ví dụ: tải 300 người dùng × 30 phút). Chi phí ước tính: ~$180-200 trong 8 tuần. Được đề xuất cho các hoạt động liên tục sau ngày 22 tháng 10 năm 2025, nếu dự kiến có các demo mở rộng hoặc lưu lượng truy cập cao hơn, vẫn nằm trong giới hạn ngân sách tổng thể.\nĐề xuất: Kịch bản Đề xuất đã được triển khai thành công cho việc ra mắt MVP vào ngày 22 tháng 10 năm 2025, đảm bảo độ tin cậy demo tối ưu, khả năng mở rộng và kiểm soát chi phí trong ngân sách $200. Đối với các hoạt động liên tục, hãy xem xét chuyển sang Kịch bản Nâng cao khi cần thiết.\nKiểm soát \u0026amp; Giám sát Chi phí Tạo cảnh báo thanh toán và bật AWS Cost Explorer. Gắn thẻ tất cả tài nguyên (Project=MapVibe, Environment=Dev). Xem xét hàng tuần: Dữ liệu CloudFront \u0026gt; 50 GB/tuần Tỷ lệ truy cập bộ nhớ đệm Bedrock \u0026lt; 90% Các cuộc gọi Lambda \u0026gt; 100K/tuần Tổng chi phí \u0026gt; $15/tuần 7. Đánh giá Rủi ro Risk Impact Probability Mitigation Dữ liệu DynamoDB không nhất quán High Medium Xác thực và sao lưu dữ liệu thường xuyên Phân tích LLM không chính xác (VN/EN) Medium Low Mẫu gợi ý được xác định trước, xác thực Khả năng mở rộng dưới tải cao Medium Medium Tự động mở rộng serverless, bộ nhớ đệm Mối quan tâm về quyền riêng tư (dữ liệu vị trí) High Low Sự đồng ý rõ ràng của người dùng, các truy vấn ẩn danh Kế hoạch dự phòng: Sử dụng kết quả DynamoDB được bộ nhớ đệm hoặc dự phòng JSON cục bộ cho các demo. Triển khai giới hạn tốc độ dựa trên IP cho người dùng chưa xác thực.\n8. Kết quả Dự kiến Cải tiến Kỹ thuật Tìm kiếm Trò chuyện: Hỗ trợ ngôn ngữ tự nhiên cho tiếng Việt và tiếng Anh với độ trễ \u0026lt;10s, powered by Bedrock LLMs. Tóm tắt AI: Tổng quan địa điểm được tạo bởi Bedrock, làm mới mỗi 7 ngày hoặc sau 10 đánh giá mới. Khả năng mở rộng: Kiến trúc serverless với phân phối CDN toàn cầu qua CloudFront. Kiểm duyệt: AI của Rekognition đảm bảo nội dung do người dùng tạo an toàn (đánh giá, ảnh). Giá trị Dài hạn Cá nhân hóa: Xếp hạng lại dựa trên ML và phân tích hành vi người dùng. Hỗ trợ Ngoại tuyến: PWA để liệt kê các địa điểm ngoại tuyến. Khả năng mở rộng: Tiềm năng tích hợp với các hệ thống đặt phòng nội bộ. Mở rộng Ngữ cảnh: Đề xuất dựa trên thời tiết, sự kiện hoặc xu hướng xã hội. Tài liệu đính kèm / Tham khảo AWS Pricing Calculator GitHub Repository 9. QUAN TRỌNG: Đọc SRS để biết thêm về dự án của chúng tôi Software Requirement Specification Related Documents "},{"uri":"https://datngo196.github.io/Internship_Report/vi/4-eventparticipated/4.2-event2/","title":"AI-Driven Development Life Cycle","tags":[],"description":"","content":"Báo cáo tổng hợp: “AI-Driven Development Life Cycle” Event Objectives Hiểu tổng quan về vòng đời phát triển phần mềm định hướng AI (AI-Driven SDLC) Tiếp cận và xem demo thực tế công cụ Amazon Q Developer Tìm hiểu sâu về công cụ Kiro và ứng dụng trong quy trình phát triển Cập nhật các công cụ hỗ trợ lập trình viên mới nhất để tăng năng suất Speakers Toan Huynh – Diễn giả chuyên đề AI-Driven SDLC \u0026amp; Amazon Q My Nguyen – Diễn giả chuyên đề Kiro Demonstration Key Highlights AI-Driven Development Life Cycle (SDLC) Shift in Paradigm: Chuyển dịch từ quy trình phát triển truyền thống sang quy trình có sự hỗ trợ tích hợp của AI ở mọi khâu. Automation: Tự động hóa các tác vụ lặp đi lặp lại trong vòng đời phát triển, từ viết code, test đến deploy. Efficiency: Tối ưu hóa thời gian và nguồn lực nhờ sự hỗ trợ của các trợ lý AI thông minh. Amazon Q Developer Demonstration Coding Assistant: Demo khả năng gợi ý code, giải thích logic code và tạo unit test tự động. Troubleshooting: Sử dụng Amazon Q để debug và tìm giải pháp cho các lỗi kỹ thuật trong thời gian thực. Integration: Cách tích hợp Amazon Q vào môi trường phát triển (IDE) và quy trình làm việc hàng ngày. Kiro Demonstration Tool Capabilities: Giới thiệu các tính năng cốt lõi của Kiro (có liên hệ với Kiro IDE/Agent). Practical Use Cases: Demo trực tiếp cách sử dụng Kiro để giải quyết các bài toán lập trình cụ thể. Developer Experience: Cải thiện trải nghiệm lập trình viên thông qua giao diện và tính năng thông minh của Kiro. Key Takeaways Tooling Landscape Amazon Q Developer không chỉ là công cụ chat mà là trợ lý toàn diện cho SDLC. Kiro mang đến những cách tiếp cận mới trong việc hỗ trợ môi trường phát triển (IDE/Agent). Productivity Focus Việc áp dụng AI-Driven SDLC giúp giảm thiểu các tác vụ thủ công, cho phép lập trình viên tập trung vào logic nghiệp vụ phức tạp. Cần chủ động làm quen với các công cụ này để không bị tụt hậu trong xu hướng công nghệ mới. Applying to Work Tích hợp Amazon Q: Cài đặt và sử dụng thử nghiệm Amazon Q Developer trong dự án hiện tại để hỗ trợ review code và viết test. Khám phá Kiro: Dành thời gian tìm hiểu sâu hơn về Kiro sau buổi demo để xem xét khả năng áp dụng vào quy trình của team. Review quy trình SDLC: Đánh giá lại quy trình phát triển hiện tại của team và xác định các điểm nghẽn có thể giải quyết bằng AI. Event Experience Buổi workshop chiều tập trung sâu vào demo kỹ thuật, mang lại cái nhìn trực quan về sức mạnh của các công cụ hỗ trợ lập trình hiện đại.\nHands-on Insight Phần trình bày của Toan Huynh giúp tôi hình dung rõ ràng về một quy trình SDLC được \u0026ldquo;AI hóa\u0026rdquo; sẽ trông như thế nào. Phần demo của My Nguyen về Kiro rất thực tế, cho thấy tiềm năng của các công cụ mới nổi bên cạnh các ông lớn như AWS. Impact on Workflow Nhận thấy rõ ràng rằng AI đang thay đổi cách chúng ta viết phần mềm: nhanh hơn, chính xác hơn và ít lỗi hơn. Sự kiện ngắn gọn nhưng súc tích, đi thẳng vào các công cụ thực chiến mà lập trình viên quan tâm. Some event photos Add your event photos here\nOverall, buổi chiều là sự bổ sung hoàn hảo về mặt công cụ (Tools) cho các kiến thức về kiến trúc (Architecture) đã học được, giúp hoàn thiện bức tranh về phát triển phần mềm hiện đại.\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Đi sâu vào các dịch vụ mạng quan trọng trên nền tảng AWS. Thiết lập và cấu hình một môi trường Mạng ảo riêng tư (VPC) an toàn trên AWS, bao gồm việc tạo các Subnet Public và Private rải đều trên nhiều Availability Zone (AZ) để đảm bảo độ sẵn sàng cao (High-Availability). Nắm vững cơ chế kết nối internet cho các tài nguyên trong VPC, phân biệt vai trò của Internet Gateway (IGW) và NAT Gateway. Hiểu và triển khai các lớp bảo mật mạng của AWS: Network Access Control List (NACL) ở cấp độ Subnet và Security Group (SG) ở cấp độ Elastic Network Interface (ENI). Nghiên cứu các giải pháp kết nối mạng quy mô lớn giữa nhiều VPC, cụ thể là VPC Peering và Transit Gateway. Làm quen với các loại Elastic Load Balancer (ELB), tập trung vào khả năng định tuyến Layer 7 (ALB) và hiệu năng Layer 4 (NLB). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thiết lập kiến trúc VPC cơ bản (Multi-AZ): Tạo VPC với dải CIDR cụ thể. Tạo ít nhất 4 Subnet (Public/Private trên 2 AZ khác nhau) để đảm bảo kiến trúc sẵn sàng cao. Hiểu về quy tắc 5 địa chỉ IP bị AWS giữ lại trong mỗi Subnet.\n09/08/2025 09/08/2025 3 - Cấu hình Internet Gateway (IGW): Tạo và gắn IGW vào VPC. Tạo Route Table tùy chỉnh (Custom Route Table) cho Public Subnet. Định tuyến lưu lượng Internet (0.0.0.0/0) ra ngoài qua IGW. Liên kết Route Table này với các Public Subnet 09/09/2025 09/09/2025 4 - Triển khai NAT Gateway: Phân biệt NAT Gateway và NAT Instance. Cấp phát Elastic IP. Triển khai NAT Gateway vào một Public Subnet. Cấu hình Route Table cho Private Subnet, định tuyến lưu lượng Internet (0.0.0.0/0) qua NAT Gateway, chỉ cho phép kết nối một chiều đi ra. 09/10/2025 09/10/2025 5 - Cấu hình Bảo mật và Triển khai EC2: Nghiên cứu và phân biệt Security Group (stateful, ENI level, chỉ ALLOW) và NACL (stateless, Subnet level, ALLOW/DENY). Tạo Security Group cho máy chủ công cộng và riêng tư. Triển khai EC2 trong Public và Private Subnet. Kiểm tra kết nối giữa các Subnet và ra Internet (sử dụng Bastion Host/Jump Host concept để SSH vào Private EC2). 09/11/2025 09/11/2025 6 - Nghiên cứu Kết nối quy mô lớn và ELB: Tìm hiểu về VPC Peering (kết nối 1:1, không hỗ trợ transitive routing) và Transit Gateway (Hub trung tâm, kết nối số lượng lớn VPC). Khám phá Elastic Load Balancing (ELB), tập trung vào ALB (Layer 7, path-based routing) và NLB (Layer 4, hiệu năng cực cao, hỗ trợ IP tĩnh). 09/12/2025 09/12/2025 Kết quả đạt được tuần 2: Thiết lập hoàn chỉnh một VPC: Đã tạo thành công VPC và chia các Subnet thành các tầng Public/Private trên nhiều Vùng khả dụng (AZs), đảm bảo kiến trúc High Availability (tính sẵn sàng cao). Nắm vững cơ chế truy cập Internet Inbound/Outbound: Đã cấu hình Internet Gateway (IGW) để cho phép truy cập Internet công cộng cho các Public Subnet. Bảo mật truy cập Internet cho Private Subnet: Đã triển khai NAT Gateway (đặt trong Public Subnet) và cấu hình Route Table tương ứng, cho phép các Instance trong Private Subnet chỉ có thể truy cập Internet theo chiều outbound (ra ngoài). Áp dụng bảo mật ở tầng mạng: Phân biệt và cấu hình Security Groups (có trạng thái – Stateful, áp dụng cho ENI) và NACLs (không trạng thái – Stateless, áp dụng cho Subnet). Triển khai thành công EC2 Instances trong cả Public và Private Subnets, đồng thời xác minh kết nối nội bộ và bên ngoài bằng Bastion Host (jump host). Nghiên cứu kết nối quy mô lớn: Hiểu rõ sự khác biệt chức năng giữa VPC Peering (kết nối 1:1) và Transit Gateway (mô hình Hub-and-Spoke, có khả năng mở rộng cao). Làm quen với các loại Elastic Load Balancer: ALB (Application Load Balancer) dùng cho định tuyến tầng 7 (Layer 7). NLB (Network Load Balancer) dùng cho hiệu năng tầng 4 (Layer 4) cực cao, cùng với các tính năng cốt lõi của chúng. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Sử dụng Raspberry Pi 5 như các nút lai (Hybrid Nodes) của Amazon EKS cho các khối tải (workload) tại biên (edge) *Bởi Alberto Crescini, Gladwin Neo, và Utkarsh Pundir, đăng ngày 17 tháng 9 năm 2025, thuộc các chuyên mục:Amazon Elastic Kubernetes Service **, Manufacturing *, Technical How-to.\nKể từ khi ra mắt, Amazon Elastic Kubernetes Service (Amazon EKS) đã vận hành hàng chục triệu cụm (cluster), giúp người dùng tăng tốc triển khai ứng dụng, tối ưu chi phí, và tận dụng tính linh hoạt của Amazon Web Services (AWS) trong việc lưu trữ và vận hành các ứng dụng container hóa. Amazon EKS loại bỏ những phức tạp trong việc duy trì hạ tầng control plane của Kubernetes, đồng thời tích hợp liền mạch với các tài nguyên và hạ tầng AWS.\nTuy nhiên, một số khối tải (workload) cần được chạy tại biên (edge) để xử lý theo thời gian thực, chẳng hạn như các ứng dụng nhạy cảm với độ trễ (latency-sensitive) hoặc tạo ra lượng dữ liệu khổng lồ cần xử lý nhanh tại chỗ.\nTrong những tình huống như vậy, khi có kết nối Internet ổn định, người dùng thường muốn duy trì lợi ích của việc tích hợp đám mây, đồng thời vẫn sử dụng phần cứng tại chỗ (on-premises). Chính vì thế, tại AWS re:Invent 2024, chúng tôi đã giới thiệu Amazon EKS Hybrid Nodes — một giải pháp cho phép người dùng mở rộng mặt dữ liệu (data plane) của Kubernetes ra biên, trong khi giữ control plane chạy trong AWS Region. Amazon EKS Hybrid Nodes giúp thống nhất việc quản lý Kubernetes trên môi trường đám mây, tại chỗ và tại biên, bằng cách cho phép người dùng sử dụng hạ tầng tại chỗ như các node trong cụm EKS, bên cạnh Amazon Elastic Compute Cloud (Amazon EC2).\nĐể minh họa cách sử dụng Amazon EKS Hybrid Nodes, chúng tôi trình bày một kịch bản thực tế trong lĩnh vực sản xuất (manufacturing) — nơi các hệ thống thường phụ thuộc vào dữ liệu thời gian thực từ các cảm biến số (digital sensors), cần được xử lý cục bộ do yêu cầu về độ trễ và độ tin cậy, trong khi vẫn tận dụng đám mây để phân tích và lưu trữ dài hạn.\nTrong ví dụ này, hệ thống đọc các giá trị khoảng cách từ cảm biến siêu âm (ultrasonic sensor), xử lý dữ liệu trực tiếp trên thiết bị biên (edge device) đang hoạt động như một Hybrid Node, và sau đó lưu trữ dữ liệu vào Amazon DynamoDB trên AWS.\nTrong bài viết này, chúng tôi sẽ hướng dẫn cách triển khai Amazon EKS Hybrid Nodes sử dụng Raspberry Pi 5, một nền tảng phổ biến cho tính toán biên (edge computing). Bài viết bao gồm:\nThiết lập cụm EKS kết nối liền mạch giữa hạ tầng đám mây và hạ tầng biên\nBảo mật kết nối bằng WireGuard VPN để thiết lập truyền thông site-to-site\nKích hoạt mạng container bằng Cilium cho các triển khai sử dụng Hybrid Nodes\nTrình bày một ứng dụng Internet of Things (IoT) thực tế nhằm minh họa sức mạnh của sự tích hợp giữa điện toán biên và điện toán đám mây (edge–cloud integration)\nVì sao chọn Raspberry Pi 5? Raspberry Pi 5 có thiết kế nhỏ gọn và có thể triển khai tại biên (edge), cho phép xử lý dữ liệu trước khi truyền lên đám mây. Tận dụng ưu điểm này, chúng tôi xây dựng một ứng dụng kiến trúc microservices, trong đó một phần chạy tại biên trên Raspberry Pi 5 và một phần chạy trên AWS trong môi trường đám mây. Ở phía biên, Raspberry Pi cục bộ được kết nối với cảm biến siêu âm (ultrasonic sensor) để thu nhận dữ liệu khoảng cách theo thời gian thực. Dữ liệu này sau đó được xử lý và tải lên cơ sở dữ liệu DynamoDB trên AWS. Tiếp theo, dữ liệu được hiển thị thông qua một bảng điều khiển (dashboard) chạy như một triển khai độc lập trong cụm (cluster deployment). Với cách triển khai này, bạn có thể tiền xử lý dữ liệu tại chỗ, từ đó giảm lượng dữ liệu cần truyền lên AWS, giúp tối ưu băng thông và chi phí, đồng thời tăng hiệu quả xử lý cục bộ cho các ứng dụng biên.\nTổng quan kiến trúc Trong môi trường đám mây, chúng tôi triển khai một Amazon Virtual Private Cloud (Amazon VPC) chứa cụm Amazon EKS. Bên trong VPC này, một phiên bản Amazon EC2 đóng vai trò cổng kết nối (gateway) giữa môi trường đám mây và mạng biên (edge network) tại cơ sở. Phiên bản EC2 này thiết lập một đường hầm VPN bảo mật site-to-site sử dụng WireGuard, kết nối với Raspberry Pi 5, thiết bị đóng vai trò là Hybrid Node của chúng tôi. Khi đường hầm VPN được thiết lập, lưu lượng dữ liệu giữa Raspberry Pi và đám mây sẽ được định tuyến thông qua máy chủ WireGuard đang chạy trên Amazon EC2, giúp mở rộng cụm EKS ra đến vùng biên. Từ góc nhìn của cụm EKS, Raspberry Pi hoạt động giống như bất kỳ node nào khác, mặc dù nó nằm ngoài phạm vi của VPC. Kiến trúc tổng thể được thể hiện trong hình minh họa bên dưới.\nMặt điều khiển Kubernetes (control plane) được quản lý hoàn toàn bởi AWS, bao gồm API server, etcd datastore, scheduler và controller manager. Trong phần hướng dẫn này, chúng tôi cấu hình control plane của Kubernetes với điểm truy cập công khai (public endpoint), cho phép các node Raspberry Pi có thể giao tiếp với control plane thông qua Internet. AWS đảm nhận toàn bộ sự phức tạp trong việc bảo mật và mở rộng control plane của Kubernetes để đảm bảo tính sẵn sàng cao (high availability), giúp bạn có thể tập trung vào phát triển và triển khai ứng dụng của mình.\nChúng tôi sử dụng một phiên bản EC2 chuyên dụng chạy WireGuard, đóng vai trò cổng VPN (VPN gateway), tạo đường hầm bảo mật giữa AWS và hạ tầng biên (edge infrastructure). Máy chủ này hoạt động như trung tâm (hub) trong mô hình hub-and-spoke, cho phép trao đổi dữ liệu giữa control plane của Amazon EKS và các node Raspberry Pi, phục vụ cho các thao tác như kubectl exec, truy xuất log, và xử lý webhook.\nCác thiết bị Raspberry Pi chạy các thành phần node tiêu chuẩn của Kubernetes gồm kubelet, kube-proxy, và container runtime, cùng với công cụ dòng lệnh Amazon EKS Hybrid Nodes CLI (nodeadm). Các node này đăng ký với cụm EKS thông qua AWS Systems Manager, và hiển thị trong cụm như những worker node tiêu chuẩn, mặc dù được vận hành trên phần cứng do người dùng tự quản lý.\nCác node Raspberry Pi chủ động thiết lập kết nối với control plane của Amazon EKS thông qua Internet công cộng. Quá trình này bao gồm giao tiếp với API server để đăng ký node, cập nhật trạng thái pod, và gửi yêu cầu tài nguyên (resource requests). Phương thức public endpoint này giúp đơn giản hóa việc kết nối, đồng thời vẫn duy trì mức độ bảo mật cao nhờ xác thực qua AWS Identity and Access Management (IAM) và mã hóa TLS.\nBắt đầu thiết lập Để kết nối mạng giữa thiết bị Raspberry Pi và cụm EKS đang chạy trên đám mây, trước tiên chúng ta cấu hình một máy chủ WireGuard nhẹ trên một phiên bản EC2. Máy chủ này chỉ hoạt động như một cổng mạng (network gateway), vì vậy phiên bản EC2 t4g.nano tiết kiệm chi phí là đủ cho hầu hết các trường hợp sử dụng.\nSau khi máy chủ WireGuard được khởi động, chúng ta cài đặt client WireGuard trên Raspberry Pi để thiết lập kết nối liên tục (persistent connection), đồng thời cấu hình định tuyến phù hợp (routing) để cho phép trao đổi lưu lượng giữa Raspberry Pi và VPC mà cụm EKS đang sử dụng.\nTiếp theo, chúng ta thêm node lai (hybrid node) vào cụm EKS, cấu hình CNI (Container Network Interface), và cuối cùng cài đặt ứng dụng để hoàn thiện quá trình triển khai.\nYêu cầu:\nRaspberry Pi 5, chạy Ubuntu 24.10, bật SSH\nKết nối Ethernet có dây (khuyến nghị để đảm bảo ổn định)\nAWS Command Line Interface (AWS CLI)\nkubectl\nHelm\nBước 1: Tạo cụm EKS Bắt đầu bằng việc tạo một Amazon VPC trong Region AWS mà bạn chọn, với ít nhất một subnet công khai và một subnet riêng tư. Các subnet này sẽ chứa các worker node trên đám mây và các giao diện mạng cần thiết để giao tiếp với control plane. Khi thiết lập cụm EKS, hãy đảm bảo rằng các tham số mạng từ xa (remote networking parameters) được cấu hình để control plane có thể kết nối với các hybrid node và pod nằm ngoài VPC.\nĐể đơn giản hóa quá trình này, AWS cung cấp bộ Template Terraform trên AWS Samples GitHub repository. Các template này tự động hóa nhiều phần cấu hình mạng và Amazon EKS, chẳng hạn như kích hoạt hybrid networking và chuẩn bị các chính sách IAM và CNI cần thiết.\nNếu bạn mới làm quen với Amazon EKS Hybrid Nodes hoặc muốn tìm hiểu sâu hơn về quá trình cấu hình, hãy tham khảo tài liệu chính thức của AWS về việc kích hoạt cụm EKS cho Hybrid Nodes.\nBước 2: Thiết lập máy chủ VPN Amazon EKS Hybrid Nodes cần kết nối ổn định và mạng riêng giữa môi trường tại chỗ/biên và VPC của bạn. Điều này đòi hỏi thiết lập VPN hoặc giải pháp mạng riêng bảo mật tương tự. Có nhiều tùy chọn được AWS tài liệu hóa, chẳng hạn nhưAWS Site-to-Site VPN, AWS Direct Connect, hoặc kết nối VPN tự triển khai. Ở đây, chúng tôi sử dụng WireGuard, một phần mềm mã nguồn mở cho kết nối VPN nhanh và bảo mật.\n2.1 Cài đặt WireGuard Chúng tôi cài đặt WireGuard bằng cách triển khai máy chủ trên một EC2 instance trong tài khoản AWS của mình. Bạn có thể tham khảo bất kỳ hướng dẫn cài đặt WireGuard chuẩn nào để cấu hình máy chủ trên EC2, đảm bảo mở cổng UDP/51820 từ IP cục bộ tới security group của EC2. Bắt đầu bằng cách cài đặt WireGuard thông qua APT.\nsudo apt update \u0026amp;\u0026amp; sudo apt install -y wireguard sudo mkdir -p /etc/wireguard 2.2 Tạo cấu hình WireGuard\nTiếp theo, sử dụng trình soạn thảo mà bạn ưa thích để thêm cấu hình sau, thay thế các giá trị giữ chỗ (placeholders) bằng Public Key và Private Key của máy chủ WireGuard của bạn.\nsudo nano /etc/wireguard/wg0.conf Thêm cấu hình sau (thay thế các giá trị giữ chỗ):\n[Interface] PrivateKey = \u0026lt;client-private.key\u0026gt; Address = 10.200.0.2/24 [Peer] # Public key from AWS server (/etc/wireguard/public.key) PublicKey = \u0026lt;public.key\u0026gt; # Your EC2 instance\u0026#39;s public IP Endpoint = \u0026lt;ec2-public-ip\u0026gt;:51820 # WireGuard server network, AWS VPC CIDR \u0026amp; EKS Service CIDR AllowedIPs = 10.200.0.1/24,10.0.0.0/24,172.16.0.0/16 PersistentKeepalive = 25 Sau đó, kích hoạt dịch vụ WireGuard và xác minh rằng kết nối đã được thiết lập với máy chủ Amazon EC2.\nsudo systemctl enable wg-quick@wg0 sudo systemctl start wg-quick@wg0 sudo wg show Bạn sẽ thấy kết quả tương tự như sau:\ninterface: wg0 public key: zH6sK7s93lF4ZkPoe8L7TtyOe0e0zFqUYrqUJo1hXVA= private key: (hidden) listening port: 51820 peer: 8N3e1FzEJmGaJ8t6C2Zh1n3oA2uNfz8MZp4nCzHn3XA= endpoint: 52.14.123.45:51820 allowed ips: 10.0.0.0/16 latest handshake: 23 seconds ago transfer: 1.47 MiB received, 1.21 MiB sent persistent keepalive: every 25 seconds Như bước đầu tiên cho việc cấu hình mạng, cần bật IPv4 forwarding trên instance để nó có thể định tuyến các gói dữ liệu giữa các giao diện mạng:\necho \u0026#34;net.ipv4.ip_forward = 1\u0026#34; | sudo tee -a /etc/sysctl.conf sudo sysctl -p Tiếp theo, để cho phép EC2 instance chuyển tiếp lưu lượng giữa mạng WireGuard và VPC của bạn, hãy cấu hình iptables để thực hiện Network Address Translation (NAT) và cho phép chuyển tiếp gói dữ liệu (packet forwarding).\n# Enable masquerading for outgoing traffic via Wireguard interface iptables -t nat -A POSTROUTING -o wg0 -j MASQUERADE # Allow packets from VPC interface to be forwarded to Wireguard iptables -A FORWARD -i eth0 -o wg0 -j ACCEPT # Allow return traffic from Wireguard back into VPC for established connections iptables -A FORWARD -i wg0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT Lệnh đầu tiên báo cho kernel ghi lại địa chỉ IP nguồn (source IP) của các gói dữ liệu đi qua giao diện WireGuard (wg0) thành địa chỉ IP của EC2 instance, điều này cần thiết để định tuyến lưu lượng trả về. Quy tắc thứ hai cho phép các gói từ giao diện VPC (eth0) được chuyển tiếp tới WireGuard. Quy tắc thứ ba cho phép lưu lượng trả về từ WireGuard quay lại VPC, nhưng chỉ áp dụng cho các kết nối đã được thiết lập trước đó.\nTiếp theo, để đảm bảo các quy tắc này được giữ nguyên sau khi khởi động lại (persist across reboots), hãy cài đặt và cấu hình gói iptables-persistent:\nsudo apt update sudo apt install iptables-persistent sudo netfilter-persistent save sudo systemctl enable netfilter-persistent Điều này lưu các quy tắc hiện tại vào/etc/iptables/rules.v4** và **/etc/iptables/rules.v6 và đảm bảo chúng được áp dụng tự động sau mỗi lần khởi động lại.\nỞ bước cuối cùng, hãy tắt tính năng kiểm tra source/destination (source/destination check) trên giao diện của instance. Theo mặc định, AWS bật kiểm tra source/destination để đảm bảo một instance chỉ xử lý lưu lượng được gửi đến hoặc đi từ chính nó. Tuy nhiên, vì instance của chúng ta đóng vai trò là gateway, định tuyến gói dữ liệu thay cho các thiết bị khác trong mạng, nên cần tắt giới hạn này.\nThêm Raspberry Pi vào cụm như một node từ xa** **Khi mạng đã được cấu hình và cụm EKS đã được tạo, bước tiếp theo là thêm node vào cụm để Kubernetes có thể bắt đầu lập lịch (scheduling) pod trên node này.\nTrước tiên, đảm bảo node có thể xác thực với cụm. Amazon EKS Hybrid Nodes xác thực với cụm EKS thông qua IAM, do đó cần gán IAM role cho các máy tại chỗ (on-premises). Điều này yêu cầu thiết lập cơ chế xác thực bằng Systems Manager hoặc IAM Roles Anywhere. Hướng dẫn trên GitHub sử dụng Systems Manager Hybrid Activations cho mục đích này. Bạn có thể theo hướng dẫn để tạo AmazonEKSHybridNodesRole bằng một trong hai tùy chọn. Sau đó, đăng ký node bằng nodeadm. Hãy theo dõi các hướng dẫn trong chỉ dẫn và chắc chắn chỉ định role mà bạn đã tạo ở bước trước.\nThiết lập Container Network Interface (CNI)\nSau khi cụm EKS và các hybrid node được tạo và cấu hình thành công, node của chúng ta vẫn hiển thị trạng thái Not Ready. Nguyên nhân là Container Network Interface (CNI) chưa được cài đặt. CNI là thành phần quan trọng chịu trách nhiệm thiết lập các giao diện mạng bên trong container, cấp phát địa chỉ IP, và cấu hình định tuyến để pod có thể giao tiếp liền mạch trong cụm và với mạng bên ngoài. Nếu không có CNI, các node Kubernetes không thể cung cấp kết nối mạng cần thiết cho pod, từ đó ngăn cản triển khai workload. Vì vậy, cần cài đặt CNI trước khi hybrid node sẵn sàng. Cilium là giải pháp mã nguồn mở, cloud-native để cung cấp, bảo mật và quan sát kết nối mạng giữa các workload, và được hỗ trợ chính thức cho Amazon EKS Hybrid Nodes\nBước 1: Cài đặt Cilium\nSau khi cài đặt Helm, chúng ta thêm Cilium Helm chart và cài đặt Cilium vào cụm EKS.\nTạo file cilium-values.yaml:\naffinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: eks.amazonaws.com/compute-type operator: In values: - hybrid ipam: mode: cluster-pool operator: clusterPoolIPv4MaskSize: 25 clusterPoolIPv4PodCIDRList: - 172.16.0.0/24 operator: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: eks.amazonaws.com/compute-type operator: In values: - hybrid unmanagedPodWatcher: restart: false envoy: enabled: false Sau đó chúng ta có thể cài đặt Cilium bằng Helm:\n[ec2-user@ip-10-0-6-175 terraform]$ helm repo add cilium https://helm.cilium.io/ \u0026gt; helm install cilium cilium/cilium \\ \u0026gt; --version 1.16.6 \\ \u0026gt; --namespace kube-system \\ \u0026gt; --values cilium-values.yaml NAME: cilium LAST DEPLOYED: Mon Apr 28 03:50:01 2025 NAMESPACE: kube-system STATUS: deployed REVISION: 1 TEST SUITE: None Bạn đã cài đặt Cilium thành công, bây giờ hãy đợi cho đến khi cả hai pod đều sẵn sàng:\n[ec2-user@ip-10-0-6-175 terraform]$ kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system cilium-gzvhm 1/1 Running 0 4m50s kube-system cilium-operator-9c54b46b8-whgn9 1/1 Running 0 4m50s kube-system coredns-6d87fdb75-95wn2 1/1 Running 0 35s kube-system coredns-6d87fdb75-b2xf5 1/1 Running 0 35s kube-system kube-proxy-w48jx 1/1 Running 0 9m31s Bước 2: Xác minh các nút lai đang chạy\nChúng ta có thể kiểm tra xem tất cả các nút trong cụm EKS của mình có đang chạy thành công hay không. Chúng ta có thể kiểm tra trạng thái nút:\nkubectl get nodes Nút này hiện được đánh dấu là Sẵn sàng.\n[ec2-user@ip-10-0-6-175 terraform]$ kubectl get nodes NAME STATUS ROLES AGE VERSION ip-10-0-6-175.ec2.internal Ready \u0026lt;none\u0026gt; 9m31s v1.30.9-eks-5d632ec Khi cụm của chúng ta hoạt động và mạng lưới container hoạt động như mong đợi, chúng ta sẽ thấy nút ở trạng thái Sẵn sàng trên Bảng thông tin tổng quan về nút Amazon EKS, như minh họa trong hình sau.\nTriển khai ứng dụng mẫu trên Amazon EKS Hybrid Nodes với tích hợp edge\nỨng dụng bao gồm hai deployment Kubernetes:\nUltrasonic: Đọc các giá trị đo từ cảm biến siêu âm và ghi vào DynamoDB. \\\nDashboard: Đọc dữ liệu từ DynamoDB và hiển thị trên giao diện tương tác (UI).\nChúng tôi sử dụng cảm biến siêu âm HC-SR04, thiết bị phát sóng âm và đo thời gian hồi âm để tính khoảng cách. Loại cảm biến này phổ biến trong các ngành sản xuất và ô tô, ví dụ:\nPhát hiện sự hiện diện hoặc vắng mặt của vật thể trên dây chuyền lắp ráp\nĐo mực chất lỏng trong các thùng chứa\nGiám sát tình trạng chỗ đỗ xe\nTrong một thiết lập nâng cao hơn, pipeline này có thể mở rộng để chạy mô hình nhận diện vật thể (object detection) tại chỗ và kích hoạt sự kiện, ví dụ gửi thông tin lên hàng đợi Amazon Simple Queue Service (Amazon SQS) dựa trên các điều kiện được phát hiện.\nTuy nhiên, trong demo này, chúng tôi ưu tiên tính rõ ràng và minh bạch. Node sẽ phát hiện khoảng cách của một vật thể đặt trước Raspberry Pi và đẩy giá trị này vào bảng DynamoDB mỗi 10 giây.\nBước 1: Yêu cầu phần cứng và thiết lập Cảm biến siêu âm HC-SR04:\nĐiện trở 1kΩ và 2kΩ (dùng trong mạch chia điện áp)\nDây nối (Jumper Wires)\nBreadboard\nChúng tôi sử dụng breadboard để nhanh chóng thử nghiệm mà không cần hàn. Breadboard giúp tối ưu hóa việc đi dây, hỗ trợ lặp nhanh, và đặt cảm biến HC-SR04 theo chiều đứng để tối ưu vị trí đo. Mỗi hàng trên breadboard chia sẻ điện liên tục, giúp đơn giản hóa kết nối.\nKết nối HC-SR04 với GPIO của Raspberry Pi\nKết nối chân 3.3V và GND của Raspberry Pi với đường nguồn (power rails) của breadboard.\nCắm cảm biến HC-SR04 vào breadboard. Sau đó kết nối:\nVCC → Breadboard + rail (dây đỏ)\nGND → Breadboard – rail (dây đen)\nTRIG → Raspberry Pi GPIO 4 (dây cam)\nECHO → Voltage divider → GPIO 17 (dây xanh)\nMạch chia điện áp sử dụng điện trở 1kΩ và 2kΩ mắc nối tiếp, giúp giảm tín hiệu 5V từ chân ECHO của cảm biến xuống khoảng 3.3V, an toàn cho GPIO của Raspberry Pi.\nSơ đồ minh họa được cung cấp để làm rõ cách bố trí này.\nBản đồ GPIO này sau này có thể được trừu tượng hóa và quản lý động qua Kubernetes ConfigMaps, giúp linh hoạt trong việc xử lý cấu hình phần cứng cho các deployment khác nhau. Chúng tôi sẽ trình bày chi tiết ở phần sau.\nBước 2: Triển khai bảng DynamoDB Chúng tôi lưu dữ liệu vào bảng DynamoDB có tên eks-timeseries, được tạo trong Region eu-west-1 . Bảng sử dụng schema như sau:\nPartition Key: yyyymmdd \\\nSort Key: hhmmss\nSchema này cho phép truy vấn theo thời gian một cách hiệu quả và phù hợp với các mô hình dữ liệu dạng time series, nơi dữ liệu được truy xuất theo ngày và sắp xếp theo dấu thời gian (timestamp).\nAWS CloudFormation template:\nResources: TimeSeriesTable: Type: AWS::DynamoDB::Table Properties: TableName: eks-timeseries AttributeDefinitions: - AttributeName: yyyymmdd AttributeType: S - AttributeName: hhmmss AttributeType: S KeySchema: - AttributeName: yyyymmdd KeyType: HASH - AttributeName: hhmmss KeyType: RANGE BillingMode: PAY_PER_REQUEST Tags: - Key: Environment Value: EdgeDemo Bước 3: Triển khai ứng dụng cảm biến Trong repository GitHub, có thư mục examples chứa dự án ultrasonic-demo. Thư mục này bao gồm:\nCác file manifest Kubernetes\nMã nguồn Python\nDockerfile để build image container\nBắt đầu bằng việc build Docker image từ thư mục ultrasonic-demo và đẩy lên container registry của bạn, ví dụ Amazon Elastic Container Registry (Amazon ECR).\nHãy chú ý phần ConfigMap trong manifest, vì nó định nghĩa các biến môi trường mà script Python cần để truy cập GPIO và DynamoDB, đồng thời cấu hình AWS CLI.\nĐể triển khai ứng dụng, chạy lệnh:\nkubectl apply -f manifest.yaml Sau khi triển khai, xác minh rằng pod ultrasonic-sensor đang chạy:\nkubectl get pods Tiếp theo, kiểm tra logs để giám sát dữ liệu từ cảm biến và các ghi chép vào DynamoDB:\nkubectl logs \u0026lt;pod-name\u0026gt; Bạn sẽ thấy các giá trị khoảng cách xuất hiện trong logs, và các kết quả tương tự cũng sẽ hiển thị trên bảng DynamoDB.\nBước 4: Triển khai frontend dashboard Để trực quan hóa dữ liệu từ cảm biến, chúng tôi xây dựng một frontend dashboard truy vấn dữ liệu trực tiếp từ DynamoDB và hiển thị dưới dạng biểu đồ cập nhật theo thời gian thực (live-updating chart).\nBất kỳ người dùng dữ liệu đã xác thực, kể cả các ứng dụng bên ngoài, đều có thể truy vấn DynamoDB trực tiếp.\nChúng tôi muốn tất cả ứng dụng đều được container hóa, do đó quyết định triển khai dashboard thông qua một deployment trong cụm.\nXem lại thư mục frontend trong repository để hiểu cấu trúc.\nBuild Docker image cho frontend và đẩy lên container registry, tương tự như cách đã làm với backend. Sau đó, cập nhật manifest Kubernetes được cung cấp.\nĐể triển khai ứng dụng, chạy lệnh:\nkubectl apply -f manifest.yaml Sau đó, bạn có thể thiết lập port-forwarding cho service trên máy local:\nkubectl port-forward svc/pi-dashboard 8080:80 Truy cập dashboard từ trình duyệt bằng cách mở http://localhost:8080.\nBạn sẽ thấy biểu đồ trực tiếp (live chart) cập nhật các giá trị khoảng cách theo thời gian thực, được truy xuất trực tiếp từ bảng DynamoDB.\nKết luận\nVậy là xong! Bạn vừa biến Raspberry Pi 5 thành một node của cụm Amazon EKS, hoạt động ngoài Amazon VPC, đọc dữ liệu thực từ cảm biến thông qua GPIO, và đẩy dữ liệu một cách an toàn lên đám mây bằng Amazon DynamoDB. Chúng tôi hy vọng ví dụ này với Raspberry Pi có thể làm minh họa thực tế cho cách kiến trúc Kubernetes lai (hybrid Kubernetes) kết nối các môi trường vật lý với đám mây, bất kể bạn đang làm việc với: Cảm biến trong nhà máy, Server tại cửa hàng bán lẻ, Engine xử lý inference trong bệnh viện hoặc sàn giao dịch. Đối với các tổ chức muốn hiện đại hóa hạ tầng phân tán, Amazon EKS Hybrid Nodes cung cấp một hướng đi thực tiễn. Bạn có thể build một lần và chạy trên đám mây, tại biên (edge), hoặc trên máy chủ bare metal của mình. Với sự linh hoạt và mạnh mẽ của phương pháp này, hiện tại là thời điểm lý tưởng để bắt đầu proof of concept và khám phá các khả năng cho tổ chức của bạn.\nMuốn tự thử nghiệm? Hãy tham khảo repository GitHub, clone ví dụ, và bắt đầu xây dựng. Ngoài ra, hãy xem hướng dẫn chính thức về Amazon EKS Hybrid Nodes, và liên hệ đội ngũ AWS của bạn nếu có thắc mắc khi bắt đầu.\n—\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\nVề các tác giả\nAlberto Crescini là Enterprise Solutions Architect tại AWS, hỗ trợ các công ty năng lượng và tiện ích ở Vương quốc Anh xây dựng hạ tầng cho quá trình chuyển đổi năng lượng. Anh hỗ trợ khách hàng trong các dự án như cân bằng lưới điện (grid balancing) và sản xuất năng lượng linh hoạt (flexible generation), đồng thời hướng dẫn họ hiện đại hóa hệ thống và nền tảng hyperscale thông qua lĩnh vực tập trung AWS Containers. Utkarsh Pundir là Containers Specialist Solutions Architect tại AWS, nơi anh hỗ trợ khách hàng xây dựng các giải pháp trên EKS. Các lĩnh vực trọng tâm của anh bao gồm kiến trúc lai (hybrid architecture) và triển khai workload Generative AI trên EKS như một phần của các sáng kiến go-to-market của AWS. Gladwin Neo là Containers Specialist Solutions Architect tại AWS, nơi anh hỗ trợ khách hàng di chuyển và hiện đại hóa các workload để triển khai trên Amazon Elastic Kubernetes Service (EKS) hoặc Amazon Elastic Container Service (ECS). "},{"uri":"https://datngo196.github.io/Internship_Report/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Tại đây sẽ là phần liệt kê, giới thiệu các blogs mà tôi đã dịch:\nBlog 1 - Chứng nhận ISO năm 2025 và CSA STAR hiện đã khả dụng cùng với hai dịch vụ bổ sung Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - Tự động xoay vòng OIDC client secret với Application Load Balancer Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - Sử dụng Raspberry Pi 5 như các nút lai (Hybrid Nodes) của Amazon EKS cho các khối tải (workload) tại biên (edge) Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/4-eventparticipated/4.3-event3/","title":"AWS AI/ML &amp; GenAI Workshop","tags":[],"description":"","content":"Báo cáo tổng hợp: “AWS AI/ML \u0026amp; GenAI Workshop” Event Objectives Cung cấp cái nhìn tổng quan về thị trường và xu hướng AI/ML tại Việt Nam Hướng dẫn thực hành trên nền tảng Amazon SageMaker để xây dựng mô hình ML toàn diện (End-to-end) Giới thiệu chuyên sâu về Generative AI với Amazon Bedrock (Foundation Models, Agents, Guardrails) Trang bị kỹ năng Prompt Engineering và xây dựng ứng dụng RAG (Retrieval-Augmented Generation) Speakers Đội ngũ chuyên gia AWS (AWS Experts) (Danh sách diễn giả cụ thể chưa được cập nhật trong lịch trình, nhưng nội dung tập trung vào kỹ thuật sâu) Key Highlights Welcome \u0026amp; Introduction Landscape Overview: Cập nhật bức tranh toàn cảnh về trí tuệ nhân tạo và máy học (AI/ML) tại thị trường Việt Nam. Networking: Hoạt động kết nối và khởi động (Ice-breaker) để tạo không khí cởi mở cho buổi workshop. AWS AI/ML Services Overview (SageMaker) End-to-end ML Platform: Tìm hiểu quy trình làm việc trên Amazon SageMaker từ chuẩn bị dữ liệu (Data preparation), gán nhãn (Labeling) đến huấn luyện (Training) và tinh chỉnh mô hình (Tuning). MLOps Integration: Tích hợp các quy trình vận hành máy học (MLOps) để tự động hóa việc triển khai. SageMaker Studio Demo: Trực tiếp trải nghiệm giao diện và các tính năng của SageMaker Studio thông qua phần demo sống động. Generative AI with Amazon Bedrock Foundation Models Selection: So sánh và hướng dẫn lựa chọn các mô hình nền tảng phù hợp như Claude, Llama, Titan. Prompt Engineering: Các kỹ thuật tối ưu hóa câu lệnh: Chain-of-Thought, Few-shot learning. RAG Architecture: Kiến trúc \u0026ldquo;Retrieval-Augmented Generation\u0026rdquo; và cách tích hợp cơ sở tri thức (Knowledge Base) để tăng độ chính xác cho AI. Advanced Features: Sử dụng Bedrock Agents cho các luồng công việc đa bước (Multi-step workflows) và Guardrails để đảm bảo an toàn nội dung. Live Demo: Xây dựng một GenAI Chatbot hoàn chỉnh sử dụng Amazon Bedrock ngay tại lớp. Key Takeaways Platform Capabilities SageMaker là công cụ mạnh mẽ cho các tác vụ Machine Learning truyền thống, giúp chuẩn hóa quy trình từ dữ liệu đến model. Bedrock cung cấp lối tắt nhanh nhất để tiếp cận Generative AI thông qua API mà không cần quản lý hạ tầng phức tạp. Strategic Implementation RAG \u0026amp; Agents là hai mũi nhọn công nghệ giúp ứng dụng GenAI giải quyết các bài toán nghiệp vụ phức tạp thay vì chỉ chat thông thường. Guardrails là thành phần không thể thiếu để đảm bảo AI hoạt động trong khuôn khổ an toàn và tuân thủ quy định doanh nghiệp. Applying to Work Triển khai MLOps: Áp dụng quy trình chuẩn trên SageMaker để quản lý vòng đời mô hình tại dự án hiện tại. Xây dựng RAG: Thử nghiệm tích hợp tài liệu nội bộ (Internal Docs) vào Bedrock Knowledge Base để tạo trợ lý tra cứu thông tin. Tối ưu Prompt: Áp dụng kỹ thuật Chain-of-Thought để cải thiện chất lượng câu trả lời của các chatbot hiện có. Đánh giá Model: Sử dụng tiêu chí đã học để chọn model (Claude vs Llama) phù hợp nhất về chi phí và hiệu năng cho từng use-case. Event Experience Buổi workshop là sự kết hợp cân bằng giữa Machine Learning truyền thống và Generative AI hiện đại, mang lại kiến thức nền tảng vững chắc.\nHands-on \u0026amp; Demo Phần SageMaker Studio walkthrough giúp tôi hình dung rõ ràng về một môi trường làm việc chuyên nghiệp cho Data Scientist. Demo xây dựng Chatbot với Bedrock là điểm nhấn, chứng minh việc tạo ra ứng dụng GenAI đã trở nên dễ dàng và nhanh chóng hơn bao giờ hết. Market Insight Phần giới thiệu về thị trường AI tại Việt Nam giúp tôi định vị được vị trí của doanh nghiệp mình trong xu hướng chung và nhận diện các cơ hội tiềm năng. Some event photos Add your event photos here\nOverall, sự kiện này đã trang bị cho tôi \u0026ldquo;bộ công cụ\u0026rdquo; đầy đủ: từ SageMaker cho các mô hình dự đoán (Predictive) đến Bedrock cho các mô hình tạo sinh (Generative), sẵn sàng cho các dự án AI sắp tới.\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Xây dựng thành công kiến trúc mạng Hybrid DNS nhằm tích hợp hệ thống DNS On-Premise (mô phỏng bằng AWS Managed Microsoft Active Directory) với dịch vụ DNS của Amazon Route 53. Cấu hình thành công Inbound Endpoint (cho phép truy vấn từ On-Premise đến AWS), Outbound Endpoint (cho phép truy vấn từ Route 53 Resolver ra ngoài), và Resolver Rules để định tuyến các truy vấn DNS cho các tên miền cụ thể. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Chuẩn bị và Khởi tạo hạ tầng mạng: Xem giới thiệu về Route 53 Resolver. Tạo Key Pair (ví dụ: hr-dns-key, kiểu RSA) để truy cập Remote Desktop vào EC2 Windows. Khởi tạo CloudFormation Template (ví dụ: hr-dns-vpc-stack) để xây dựng hạ tầng mạng cơ sở (VPC, Subnets, Gateway) có tính sẵn sàng cao và bảo mật. 09/15/2025 09/15/2025 3 - Hoàn tất hạ tầng và Kết nối RDGW Host: Theo dõi và đợi CloudFormation hoàn thành (khoảng 15-20 phút). Cấu hình lại Security Group trong VPC: xóa cổng không sử dụng (3391, 443) và giữ lại giao thức ICMP (IPv4) và Remote Desktop Protocol (cổng 3389). Kết nối đến Remote Desktop Gateway (RDGW) Host bằng cách tải file RDP, upload Key Pair để giải mã và lấy mật khẩu Administrator.\n09/16/2025 09/16/2025 4 - Thiết lập Route 53 Outbound Endpoint: Tạo Outbound Endpoint Route 53 Resolver (mũi tên đỏ) cho phép Route 53 chuyển tiếp truy vấn DNS tới hệ thống ngoài (AD). Chọn đúng VPC và Security Group. Cấu hình địa chỉ IP tự động trong hai Availability Zone (AZ). Chờ Endpoint chuyển sang trạng thái thành công 09/17/2025 09/17/2025 5 - Thiết lập Resolver Rules và Inbound Endpoint: Tạo Resolver Rule (loại Forward) để chuyển tiếp truy vấn DNS cho tên miền cụ thể (ví dụ: onprem.example.com) tới địa chỉ IP của AWS Managed Microsoft AD DNS. Tạo Inbound Endpoint Route 53 Resolver (mũi tên xanh) cho phép hệ thống DNS On-Premise (AD) truy vấn Route 53 resolver, cấu hình trong subnets riêng tư. 09/18/2025 09/18/2025 6 - Kiểm tra và Dọn dẹp Tài nguyên: Thử nghiệm kết quả bằng cách sử dụng lệnh nslookup onprem.example.com trên RDGW host để xác minh phân giải DNS. Kiểm tra truy vấn được định tuyến qua IP DNS Resolver của VPC (ví dụ: 10.0.0.2) và thực hiện ping tới domain môi trường truyền thống. Dọn dẹp tài nguyên: Xóa Inbound/Outbound Endpoint. Hủy liên kết (Disassociate) VPC khỏi Resolver Rule trước khi xóa Rule. Xóa AWS Managed Microsoft Active Directory, sau đó xóa CloudFormation Stacks. 09/19/2025 09/19/2025 Kết quả đạt được tuần 3: Thiết lập thành công kiến trúc DNS lai (Hybrid DNS) sử dụng Route 53 Resolver. Đã cấu hình Outbound Endpoint để Route 53 Resolver có thể chuyển tiếp truy vấn DNS tới hệ thống ngoài (AWS Managed AD). Đã tạo Inbound Endpoint cho phép hệ thống DNS On-Premise (AD) truy vấn Route 53 Resolver. Các Resolver Rule (loại Forward) đã được tạo để định tuyến truy vấn cho tên miền onprem.example.com tới địa chỉ IP của AWS Managed Microsoft AD DNS. Thử nghiệm đã xác nhận khả năng phân giải DNS hai chiều bằng lệnh nslookup trên RDGW host. Đã xác minh rằng truy vấn được định tuyến chính xác qua địa chỉ IP DNS Resolver của VPC (ví dụ: 10.0.0.2, theo mặc định là VPC CIDR + 2). Đã hoàn tất dọn dẹp tài nguyên để tránh phát sinh chi phí "},{"uri":"https://datngo196.github.io/Internship_Report/vi/4-eventparticipated/4.4-event4/","title":"AWS DevOps &amp; Modern Operations","tags":[],"description":"","content":"Báo cáo tổng hợp: “AWS DevOps \u0026amp; Modern Operations” Event Objectives Xây dựng tư duy DevOps và nắm vững các chỉ số đo lường hiệu quả (DORA metrics) Thiết lập quy trình CI/CD hoàn chỉnh sử dụng bộ công cụ AWS Developer Tools Hiện đại hóa quản lý hạ tầng bằng mã (Infrastructure as Code) với CloudFormation và CDK Triển khai ứng dụng container hóa (Docker) trên ECS, EKS và App Runner Thiết lập hệ thống giám sát toàn diện (Observability) cho ứng dụng phân tán Speakers Đội ngũ chuyên gia AWS (AWS Experts) (Các chuyên gia về DevOps, Container và Observability) Key Highlights DevOps Mindset \u0026amp; CI/CD DORA Metrics: Hiểu tầm quan trọng của các chỉ số: Tần suất triển khai, Thời gian thay đổi (Lead time), MTTR. Git Strategies: So sánh chiến lược GitFlow và Trunk-based development. Pipeline Automation: Demo quy trình CI/CD đầy đủ từ CodeCommit (lưu trữ), CodeBuild (build/test) đến CodeDeploy (triển khai) được điều phối bởi CodePipeline. Deployment Strategies: Các kỹ thuật triển khai an toàn: Blue/Green, Canary, và Rolling updates. Infrastructure as Code (IaC) CloudFormation: Quản lý hạ tầng bằng template, khái niệm Stacks và phát hiện sai lệch (Drift detection). AWS CDK: Sử dụng ngôn ngữ lập trình quen thuộc để định nghĩa hạ tầng, tận dụng các \u0026ldquo;Constructs\u0026rdquo; và mẫu tái sử dụng. IaC Choice: Thảo luận về tiêu chí lựa chọn giữa CloudFormation và CDK tùy theo dự án. Container Services Spectrum of Compute: Từ quản lý image (ECR) đến các lựa chọn điều phối: ECS (đơn giản), EKS (Kubernetes chuẩn) và App Runner (đơn giản hóa tối đa). Microservices Deployment: So sánh và demo triển khai microservices trên các nền tảng khác nhau. Monitoring \u0026amp; Observability Full-stack Observability: Kết hợp CloudWatch (Metrics, Logs, Alarms) và X-Ray (Distributed Tracing) để có cái nhìn toàn diện về sức khỏe hệ thống. Best Practices: Thiết lập Dashboard giám sát và quy trình trực chiến (On-call) hiệu quả. Key Takeaways Automation First CI/CD không chỉ là công cụ mà là văn hóa giúp giảm thiểu lỗi con người và tăng tốc độ phát hành. IaC là tiêu chuẩn bắt buộc cho hạ tầng hiện đại, giúp môi trường Dev/Test/Prod đồng nhất. Operational Excellence Observability (Khả năng quan sát) quan trọng hơn Monitoring (Giám sát) đơn thuần, đặc biệt trong kiến trúc Microservices để truy vết lỗi (tracing). Việc chọn đúng chiến lược triển khai (như Blue/Green) giúp giảm thiểu Downtime xuống bằng 0. Applying to Work Refactor Pipeline: Chuyển đổi các quy trình build thủ công hiện tại sang AWS CodePipeline với các bước test tự động. Adopt CDK: Bắt đầu sử dụng AWS CDK để định nghĩa hạ tầng cho các dự án mới thay vì thao tác trên Console. Containerization: Đóng gói ứng dụng vào Docker và thử nghiệm triển khai lên AWS App Runner cho các service nhỏ. Setup Tracing: Tích hợp AWS X-Ray vào ứng dụng để theo dõi độ trễ (latency) giữa các microservices. Event Experience Sự kiện kéo dài cả ngày nhưng nội dung rất liền mạch, đi từ tư duy (Mindset) đến công cụ (Tools) và vận hành (Operations).\nIntegrated Workflow Phần Demo \u0026ldquo;Full CI/CD pipeline walkthrough\u0026rdquo; rất ấn tượng, cho thấy bức tranh toàn cảnh code di chuyển từ máy lập trình viên lên môi trường Production như thế nào. Hiểu rõ sự khác biệt và trường hợp sử dụng cụ thể của ECS vs EKS, giúp tôi tự tin hơn khi đề xuất giải pháp cho công ty. Practical Focus Các bài học về Deployment strategies (Feature flags, Canary) rất thực tế để giải quyết bài toán \u0026ldquo;sợ deploy\u0026rdquo; của team. Phần Career roadmap cuối giờ cung cấp định hướng rõ ràng cho lộ trình phát triển kỹ năng DevOps. Some event photos Add your event photos here\nOverall, buổi workshop đã hệ thống hóa lại toàn bộ kiến thức về vận hành hiện đại, giúp tôi hiểu rõ mối liên kết chặt chẽ giữa Code, Hạ tầng và Giám sát.\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Nắm vững dịch vụ Compute (EC2), các tùy chọn lưu trữ và khả năng mở rộng (Auto Scaling). Triển khai giải pháp bảo vệ dữ liệu sử dụng AWS Backup. Cấu hình lưu trữ đám mây lai (Hybrid Cloud) với AWS Storage Gateway. Làm chủ Amazon S3 để host website tĩnh, phân phối nội dung (CloudFront) và quản lý dữ liệu. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu các kiến thức cốt lõi về EC2 như Instance types, AMI, Key Pair, phân biệt EBS/Instance Store và thực hành khởi tạo máy ảo kèm cấu hình User Data. 09/22/2025 09/22/2025 3 - Học về EC2 Auto Scaling và các tùy chọn giá (Pricing), sau đó thực hiện Lab 13 để triển khai hạ tầng AWS Backup, tạo Backup plan và kiểm thử khôi phục dữ liệu. 09/23/2025 09/23/2025 4 - Hoàn thành Lab 24 bằng cách tạo EC2 cho Storage Gateway, kích hoạt Gateway và tạo File Shares. Bắt đầu Lab 57 với việc tạo S3 Bucket và tải dữ liệu mẫu lên. 09/24/2025 09/24/2025 5 - Tiếp tục Lab 57: Bật tính năng Static Website Hosting trên S3, cấu hình quyền truy cập công khai và thiết lập Amazon CloudFront để phân phối nội dung website. 09/25/2025 09/25/2025 6 Hoàn tất Lab 57 với các tính năng nâng cao như Bucket Versioning, Lifecycle rules (di chuyển đối tượng), Sao chép đa vùng (Replication) và dọn dẹp toàn bộ tài nguyên Lab. volume 09/26/2025 09/26/2025 Kết quả đạt được tuần 4: Compute (EC2): Hiểu rõ sự khác biệt giữa EBS và Instance Store. Biết cách sử dụng User Data để cấu hình instance khi khởi động. Cấu hình được EC2 Auto Scaling và nắm được các mô hình giá của AWS. Data Protection: Đã triển khai thành công AWS Backup để tự động hóa quy trình sao lưu và khôi phục hệ thống. Hybrid Storage: Đã tạo và cấu hình AWS Storage Gateway để kết nối file share với cloud storage. Storage \u0026amp; CDN (S3 \u0026amp; CloudFront): Triển khai thành công website tĩnh (Static Website) trên Amazon S3. Tích hợp Amazon CloudFront để tăng tốc phân phối nội dung. Thực hiện được các kỹ thuật quản lý dữ liệu: Versioning, Cross-Region Replication và Lifecycle rules. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong kỳ thực tập của mình, tôi đã tham gia năm sự kiện. Mỗi sự kiện là một trải nghiệm đáng nhớ, mang lại những kiến thức mới mẻ, thú vị và hữu ích, cùng với những món quà và khoảnh khắc tuyệt vời.\nSự kiện 1 Tên sự kiện: AWS First Cloud Journey Community Day\nThời gian: 09:00, Ngày 30 tháng 08 năm 2025\nĐịa điểm: Tầng 26, Tháp Bitexco, 02 Hải Triều, Phường Bến Nghé, Quận 1, TP.HCM\nVai trò: Người tham dự\nSự kiện 2 Tên sự kiện: AI-Driven Development Workshop\nThời gian: 09:00, Ngày 03 tháng 10 năm 2025\nĐịa điểm: Tháp Bitexco (Tầng 26 \u0026amp; 36), 02 Hải Triều, Phường Bến Nghé, Quận 1, TP.HCM\nVai trò: Người tham dự\nSự kiện 3 Tên sự kiện: AWS AI/ML \u0026amp; GenAI Workshop\nThời gian: 08:30, Ngày 15 tháng 11 năm 2025\nĐịa điểm: Tháp Bitexco, 02 Hải Triều, Phường Bến Nghé, Quận 1, TP.HCM\nVai trò: Người tham dự\nSự kiện 4 Tên sự kiện: AWS DevOps \u0026amp; Modern Operations\nThời gian: 08:30, Ngày 17 tháng 11 năm 2025\nĐịa điểm: Tháp Bitexco, 02 Hải Triều, Phường Bến Nghé, Quận 1, TP.HCM\nVai trò: Người tham dự\nSự kiện 5 Tên sự kiện: AWS Security Specialty Workshop\nThời gian: 08:30, Ngày 29 tháng 11 năm 2025\nĐịa điểm: Tháp Bitexco, 02 Hải Triều, Phường Bến Nghé, Quận 1, TP.HCM\nVai trò: Người tham dự\nSự kiện 6 Tên sự kiện: Workshop: Data Science on AWS\nThời gian: 09:30, Ngày 16 tháng 10 năm 2025\nĐịa điểm: Hall Academic – Trường ĐH FPT, TP.HCM\nVai trò: Người tham dự\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/4-eventparticipated/4.5-event5/","title":"AWS Security Specialty Workshop","tags":[],"description":"","content":"Báo cáo tổng hợp: “AWS Security Specialty Workshop” Event Objectives Hiểu sâu về vai trò của Security Pillar trong khung kiến trúc Well-Architected Nắm vững 5 trụ cột bảo mật: IAM, Detection, Infrastructure, Data Protection, Incident Response Cập nhật các mối đe dọa an ninh hàng đầu tại thị trường Cloud Việt Nam Thực hành rà soát quyền hạn (IAM) và xây dựng quy trình phản ứng sự cố (IR Playbook) Speakers Đội ngũ chuyên gia bảo mật AWS (AWS Security Experts) (Chuyên sâu về kiến trúc bảo mật và tuân thủ) Key Highlights Foundation \u0026amp; Identity (Pillar 1) Core Principles: Áp dụng triệt để nguyên tắc đặc quyền tối thiểu (Least Privilege), Zero Trust và bảo mật nhiều lớp (Defense in Depth). Modern IAM: Chuyển dịch từ việc dùng IAM Users (long-term credentials) sang IAM Roles và AWS Identity Center (SSO) để quản lý tập trung. Access Control: Sử dụng Service Control Policies (SCP) và Permission Boundaries để giới hạn phạm vi quyền hạn trong môi trường multi-account. Mini Demo: Thực hành xác thực (Validate) IAM Policy và mô phỏng quyền truy cập để phát hiện lỗi bảo mật. Detection \u0026amp; Infrastructure (Pillar 2 \u0026amp; 3) Continuous Monitoring: Kích hoạt CloudTrail (toàn tổ chức), GuardDuty và Security Hub để giám sát liên tục. Logging Strategy: Ghi nhật ký tại mọi tầng: VPC Flow Logs (mạng), ALB logs (ứng dụng), S3 logs (lưu trữ). Network Security: Phân đoạn mạng (Segmentation) với VPC, kết hợp Security Groups và NACLs. Bảo vệ biên với WAF, Shield và Network Firewall. Data Protection \u0026amp; Incident Response (Pillar 4 \u0026amp; 5) Encryption: Mã hóa dữ liệu đường truyền (in-transit) và dữ liệu lưu trữ (at-rest) trên S3, EBS, RDS sử dụng KMS. Secrets Management: Loại bỏ hard-code credentials bằng cách sử dụng Secrets Manager và Parameter Store với cơ chế xoay vòng (rotation). IR Automation: Xây dựng kịch bản phản ứng (Playbook) cho các sự cố phổ biến (lộ key, malware) và tự động hóa quy trình cô lập bằng Lambda/Step Functions. Key Takeaways Zero Trust Mindset Identity is the new perimeter: Trong môi trường Cloud, định danh (Identity) là hàng rào bảo vệ quan trọng nhất, không phải địa chỉ IP. Không bao giờ tin tưởng mặc định, luôn xác thực và cấp quyền tối thiểu. Automation is Key Bảo mật thủ công không thể theo kịp tốc độ của Cloud. Cần áp dụng Detection-as-Code và Auto-remediation (tự động khắc phục) để giảm thiểu rủi ro con người. Applying to Work Review IAM: Rà soát lại toàn bộ IAM User, xóa các key cũ và chuyển sang dùng IAM Role cho các ứng dụng. Enable GuardDuty: Bật GuardDuty trên tất cả các region/account để phát hiện các hành vi bất thường. Implement Secrets Manager: Thay thế các config file chứa mật khẩu DB bằng việc gọi API tới Secrets Manager. Draft IR Playbook: Viết quy trình xử lý sự cố cho tình huống \u0026ldquo;IAM Key bị lộ\u0026rdquo; và diễn tập với team. Event Experience Buổi workshop đi sâu vào chi tiết kỹ thuật, bao phủ toàn diện các khía cạnh bảo mật mà một kỹ sư Cloud cần nắm vững.\nComprehensive Framework Việc chia nội dung theo 5 Pillars giúp tôi hệ thống hóa lại kiến thức bảo mật rời rạc trước đây thành một khung chuẩn chỉnh. Phần nói về Top threats tại Việt Nam rất thực tế, giúp nhận diện các rủi ro cụ thể với bối cảnh trong nước. Practical Demos Demo về Access Analyzer và Validate IAM Policy rất hữu ích, giải quyết được nỗi đau đầu khi debug quyền hạn (permissions) hàng ngày. Phần Incident Response giúp tôi hiểu rằng \u0026ldquo;phát hiện\u0026rdquo; (detection) chỉ là một nửa câu chuyện, \u0026ldquo;phản ứng\u0026rdquo; (response) tự động mới là đích đến. Some event photos Add your event photos here\nOverall, sự kiện khẳng định rằng bảo mật không phải là nút chặn (blocker) mà là yếu tố cho phép doanh nghiệp vận hành nhanh và an toàn hơn (enabler).\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Làm chủ các tính năng nâng cao của Amazon S3 (Storage Classes, Lifecycle, Access Points) và Glacier. Hiểu về giải pháp Hybrid Cloud sử dụng AWS Storage Gateway và Snow Family. Thực hiện di chuyển máy ảo từ on-premise lên AWS (VM Import/Export). Triển khai và quản lý hệ thống tệp Windows File Server (FSx) với cấu hình Multi-AZ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Xem các video lý thuyết Module 04 về S3 Storage Classes, Access Point, Static Website, CORS và Snow Family, sau đó bắt đầu Lab 13 bằng việc tạo S3 bucket và triển khai hạ tầng backup. 09/29/2025 09/29/2025 3 - Hoàn thành Lab 13 với việc cài đặt thông báo (notification) và test khôi phục dữ liệu, sau đó chuyển sang Lab 14: chuẩn bị VMWare Workstation và xuất máy ảo từ môi trường local. 09/30/2025 09/30/2025 4 - TTiếp tục Lab 14: Upload máy ảo lên AWS, import thành AMI và khởi chạy instance; tiến hành làm Lab 24 để khởi tạo dịch vụ Storage Gateway. 10/01/2025 10/01/2025 5 - Hoàn tất Lab 24 bằng cách tạo File Shares và mount ổ đĩa xuống máy local, sau đó bắt đầu Lab 25 để tạo hệ thống file SSD và HDD Multi-AZ (FSx). 10/02/2025 10/02/2025 6 - Hoàn thành việc thiết lập hệ thống file Multi-AZ trong Lab 25, ôn tập lại toàn bộ kiến thức lưu trữ trong tuần và dọn dẹp sạch sẽ tài nguyên (S3, Gateway, File System) để tránh phát sinh phí. 10/03/2025 10/03/2025 Kết quả đạt được tuần 5: Lưu trữ nâng cao: Hiểu sâu về hiệu năng S3, bảo mật (CORS/ACL) và chiến lược lưu trữ lâu dài với Glacier. Nắm được quy trình chuyển dữ liệu offline với AWS Snow Family. Backup \u0026amp; Di chuyển: Cấu hình thành công thông báo cho AWS Backup và kiểm thử quy trình khôi phục. Thực hiện thành công việc di chuyển máy ảo VMWare từ dưới hạ tầng local lên AWS EC2. Hybrid \u0026amp; File Systems: Kết nối lưu trữ giữa on-premise và cloud thông qua AWS Storage Gateway. Triển khai hệ thống file Windows (FSx) với độ sẵn sàng cao (Multi-AZ) trên cả SSD và HDD. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "},{"uri":"https://datngo196.github.io/Internship_Report/vi/4-eventparticipated/4.6-event6/","title":"Workshop: Data Science on AWS","tags":[],"description":"","content":"Báo cáo tổng hợp: “Workshop: Data Science on AWS” Mục tiêu sự kiện Khám phá toàn bộ hành trình xây dựng một hệ thống Data Science hiện đại từ lý thuyết đến thực hành. Nắm vững quy trình Data Science Pipeline trên AWS (từ S3, Glue đến SageMaker). Thực hành xử lý dữ liệu thực tế (dataset IMDb) và triển khai mô hình học máy (Sentiment Analysis). Phân tích bài toán chi phí và hiệu năng giữa nền tảng Cloud và hạ tầng On-premise. Diễn giả Anh Văn Hoàng Kha – Cloud Solutions Architect, AWS Community Builder Anh Bạch Doãn Vương – Cloud DevOps Engineer, AWS Community Builder Nội dung nổi bật 1. Tầm quan trọng của Cloud và Tổng quan Pipeline Vai trò của Cloud: Thảo luận về lý do tại sao Data Science hiện đại cần dựa vào Cloud để đạt được khả năng mở rộng và tích hợp, thay vì bị giới hạn bởi phần cứng on-premise. AWS Data Science Pipeline: Lưu trữ: Sử dụng Amazon S3 làm nền tảng Data Lake. ETL/Xử lý: Sử dụng AWS Glue để tích hợp và làm sạch dữ liệu serverless. [cite_start]Mô hình hóa: Tận dụng Amazon SageMaker làm trung tâm để xây dựng, huấn luyện và triển khai mô hình[cite: 132]. [cite_start]Tổng quan về bộ công cụ AWS AI/ML stack bao gồm các AI Services, ML Services và hạ tầng cơ sở[cite: 121]. 2. Demo thực hành (Hands-on) Demo 1: Xử lý dữ liệu với AWS Glue: Kịch bản: Xử lý và làm sạch dữ liệu thô từ dataset IMDb. Kỹ thuật: Minh họa cách thực hiện Feature Engineering. [cite_start]Workshop cũng giới thiệu các tùy chọn khác nhau từ Low-code (SageMaker Canvas) [cite: 129] [cite_start]đến Code-first (Numpy/Pandas)[cite: 130]. Demo 2: Phân tích cảm xúc (Sentiment Analysis) với SageMaker: Kịch bản: Huấn luyện và triển khai mô hình AI để phân tích cảm xúc văn bản. Quy trình: Thực hiện vòng đời \u0026ldquo;Train, Tune, Deploy\u0026rdquo; trên SageMaker Studio. [cite_start]Buổi demo cũng đề cập đến khái niệm \u0026ldquo;Bring Your Own Model\u0026rdquo; (BYOM), cho phép chạy các framework như TensorFlow và PyTorch trên hạ tầng AWS[cite: 133]. 3. Thảo luận chuyên sâu Cloud vs. On-premise: Phân tích sâu về tối ưu hóa chi phí và các chỉ số hiệu năng. Sự linh hoạt của Cloud cho phép thử nghiệm các tác vụ nặng mà không cần đầu tư vốn lớn (CAPEX) ban đầu. Dự án củng cố: Hướng dẫn thực hiện dự án nhỏ sau workshop để người tham dự tự thực hành lại quy trình. Bài học chính (Key Takeaways) Quy trình kỹ thuật Pipeline thống nhất: Một quy trình Data Science hiệu quả đòi hỏi sự tích hợp mượt mà giữa lưu trữ (S3), làm sạch (Glue) và mô hình hóa (SageMaker). [cite_start]Lựa chọn công cụ: Hiểu rõ khi nào nên dùng các dịch vụ có sẵn (Managed Services như Rekognition, Polly) [cite: 124, 126] và khi nào cần xây dựng mô hình tùy chỉnh trên SageMaker. Ứng dụng thực tế Kết nối đào tạo - doanh nghiệp: Sự chuyển dịch từ lý thuyết hàn lâm sang ứng dụng thực tế nằm ở khả năng tự động hóa và mở rộng của hệ thống. Tư duy chi phí: Các dự án dữ liệu thành công phải cân bằng được giữa độ chính xác của mô hình và chi phí tính toán. Ứng dụng vào công việc Áp dụng AWS Glue: Chuyển đổi các script ETL cục bộ sang AWS Glue để tự động hóa việc làm sạch dữ liệu quy mô lớn. Triển khai SageMaker: Di chuyển các mô hình thử nghiệm từ Jupyter notebook cá nhân lên SageMaker Studio để chuẩn hóa quy trình huấn luyện. Thực hiện dự án: Hoàn thành dự án nhỏ được hướng dẫn để nắm chắc quy trình xử lý dataset IMDb. Trải nghiệm sự kiện Workshop “Data Science on AWS” thực sự là cầu nối giữa kiến thức sinh viên và thực tế doanh nghiệp.\nKết nối trực tiếp: Sự kiện giúp tôi thấy được cách các doanh nghiệp hàng đầu vận hành hệ thống phân tích dữ liệu. Thực tế hóa lý thuyết: Việc tận mắt xem demo xử lý dataset IMDb và triển khai mô hình Sentiment Analysis giúp giải mã sự phức tạp của AI trên nền tảng đám mây. Chia sẻ từ chuyên gia: Phần thảo luận với các AWS Community Builder mang lại góc nhìn chiến lược về bài toán \u0026ldquo;Cloud vs On-premise\u0026rdquo;, giúp tôi hiểu giá trị của Cloud không chỉ nằm ở công nghệ mà còn ở hiệu quả kinh tế. Một số hình ảnh sự kiện Thêm hình ảnh sự kiện của bạn tại đây\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Làm chủ quản trị nâng cao Amazon FSx for Windows File Server (Hiệu năng, Chống trùng lặp, Hạn ngạch). Triển khai website tĩnh toàn cầu sử dụng Amazon S3 và Amazon CloudFront. Thực hiện các chiến lược bảo vệ dữ liệu trên S3 (Versioning, Replication, Lifecycle). Hiểu nền tảng về Bảo mật AWS, Định danh và Quản lý truy cập (IAM \u0026amp; Cognito). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Đi sâu vào các tính năng nâng cao của Lab 25 bao gồm tạo file shares, kiểm tra và giám sát hiệu năng, bật tính năng chống trùng lặp dữ liệu (deduplication), shadow copies, quản lý phiên người dùng và hạn ngạch lưu trữ. 10/06/2025 10/06/2025 3 - Hoàn tất Lab 25 bằng việc thực hành mở rộng băng thông (throughput) và dung lượng lưu trữ, sau đó xóa môi trường. Bắt đầu Lab 57: tạo S3 bucket, tải dữ liệu và bật tính năng Static Website Hosting.\n10/07/2025 10/07/2025 4 - Tiếp tục Lab 57: Cấu hình chặn truy cập công khai và các đối tượng công khai, sau đó thiết lập và kiểm thử Amazon CloudFront để phân phối nội dung website với độ trễ thấp.\n10/08/2025 10/08/2025 5 - Hoàn thành Lab 57 với các tác vụ quản lý dữ liệu: bật Bucket Versioning, di chuyển đối tượng theo Lifecycle rules, cấu hình sao chép đa vùng (Multi-Region Replication) và dọn dẹp tài nguyên. 10/09/2025 10/09/2025 6 - *Bắt đầu Module 05: Nghiên cứu Mô hình Trách nhiệm Chia sẻ (Shared Responsibility Model), tìm hiểu các khái niệm cốt lõi của AWS IAM và tổng quan về Amazon Cognito. 10/10/2025 10/10/2025 Kết quả đạt được tuần 6: Lưu trữ tệp nâng cao (FSx): Đã cấu hình các tính năng tối ưu lưu trữ như Data Deduplication và Shadow Copies. Quản lý kiểm soát truy cập thông qua user sessions và storage quotas. Thực hiện thành công việc mở rộng băng thông và dung lượng lưu trữ. Phân phối nội dung \u0026amp; S3: Host thành công website tĩnh trên S3 và tăng tốc truy cập bằng CloudFront CDN. Triển khai các chiến lược vòng đời và bảo vệ dữ liệu (Versioning, Replication). Nền tảng bảo mật: Nắm vững Mô hình Trách nhiệm Chia sẻ giữa AWS và khách hàng. Hiểu vai trò của IAM trong kiểm soát truy cập và Cognito trong quản lý định danh người dùng. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại Công ty TNHH Amazon Web Services Việt Nam từ 08/09/2025 đến 19/12/2025, tôi đã có cơ hội học tập, thực hành và áp dụng những kiến thức đã học ở trường vào môi trường làm việc thực tế. Tôi đã tham gia chương trình FCJ Cloud Intern, qua đó tôi đã cải thiện các kỹ năng về kiến trúc Điện toán đám mây, Cơ sở hạ tầng dưới dạng mã (AWS CDK), quy trình DevOps, ứng dụng Generative AI và giao tiếp chuyên nghiệp.\nVề thái độ làm việc, tôi luôn nỗ lực hoàn thành tốt nhiệm vụ, tuân thủ quy định nơi làm việc và tích cực tương tác với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể nhìn lại quá trình thực tập một cách khách quan, tôi xin tự đánh giá bản thân dựa trên các tiêu chí sau:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ☐ ✅ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ✅ ☐ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Hiểu cấu trúc bảo mật doanh nghiệp với AWS Organizations và Identity Center. Triển khai quản lý tư thế bảo mật với AWS Security Hub và mã hóa với KMS. Xây dựng quy trình tự động hóa phản ứng sự cố sử dụng AWS Lambda tích hợp với Slack. Làm chủ việc tổ chức và quản lý tài nguyên thông qua chiến lược Gắn thẻ (Tagging) và Resource Groups. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Xem các video lý thuyết về AWS Organizations, Identity Center, KMS và Security Hub. Hoàn thành Lab 18 bằng cách bật Security Hub để đánh giá điểm bảo mật và dọn dẹp tài nguyên.\n10/13/2025 10/13/2025 3 - Bắt đầu Lab 22 để xây dựng hệ thống phản hồi tự động. Thiết lập hạ tầng mạng (VPC, Security Groups), khởi chạy EC2 instance và cấu hình Incoming Webhook để tích hợp Slack. 10/14/2025 10/14/2025 4 - Hoàn tất Lab 22 bằng cách tạo IAM Role cho Lambda, triển khai các hàm (functions) để tự động dừng/chạy instance và kiểm tra kết quả thông báo qua Slack trước khi dọn dẹp. 10/15/2025 10/15/2025 5 - Thực hiện Lab 27 tập trung vào quản lý tài nguyên. Thực hành khởi chạy EC2 kèm thẻ (tags), quản lý thẻ thông qua giao diện Console lẫn dòng lệnh CLI và lọc tài nguyên hiệu quả.\n10/16/2025 10/16/2025 6 - Hoàn thành Lab 27 bằng việc tạo Resource Groups dựa trên thẻ và dọn dẹp tài nguyên. Bắt đầu Lab 28 với việc học cách tạo và cấu hình một IAM User an toàn. 10/17/2025 10/17/2025 Kết quả đạt được tuần 7: Quản trị bảo mật: Hiểu cách quản lý môi trường đa tài khoản với AWS Organizations và Identity Center. Sử dụng AWS Security Hub để giám sát tuân thủ và các tiêu chuẩn bảo mật. Tự động hóa \u0026amp; Tích hợp: Xây dựng thành công quy trình tự động hóa serverless sử dụng AWS Lambda để quản lý trạng thái EC2. Tích hợp dịch vụ AWS với công cụ bên thứ ba (Slack) để giám sát thời gian thực. Quản lý tài nguyên: Áp dụng các chiến lược gắn thẻ (tagging) nâng cao để tổ chức tài nguyên đám mây. Sử dụng Resource Groups và lệnh CLI để quản lý tài nguyên số lượng lớn hiệu quả. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/4-eventparticipated/4.7-event7/","title":"Vietnam Cloud Day","tags":[],"description":"","content":"Báo cáo tổng hợp: “Vietnam Cloud Day” Mục tiêu sự kiện Cung cấp chiến lược cho lãnh đạo cấp cao về cách điều hướng cuộc cách mạng Generative AI. Chia sẻ các phương pháp tốt nhất để xây dựng nền tảng dữ liệu thống nhất và có khả năng mở rộng trên AWS. Giới thiệu Vòng đời Phát triển định hướng AI (AI-DLC) và tác động của nó đối với việc triển khai phần mềm. Khám phá các nguyên tắc cơ bản về bảo mật cho GenAI và tương lai của các AI Agent. Diễn giả Eric Yeo – Giám đốc Quốc gia, Việt Nam, Campuchia, Lào \u0026amp; Myanmar, AWS Dr. Jens Lottner – CEO, Techcombank Ms. Trang Phung – CEO \u0026amp; Đồng sáng lập, U2U Network Jaime Valles – Phó Chủ tịch \u0026amp; Tổng Giám đốc khu vực APJ, AWS Jeff Johnson, Vu Van (ELSA), Nguyen Hoa Binh (Nexttech), Dieter Botha (TymeX) – Các diễn giả tọa đàm Kien Nguyen, Jun Kai Loke, Tamelly Lim, Binh Tran, Taiki Dang, Michael Armentano – Các chuyên gia AWS Nội dung nổi bật 1. Chiến lược \u0026amp; Tầm nhìn Lãnh đạo Keynotes: Các lãnh đạo từ AWS, Techcombank và U2U Network chia sẻ tầm nhìn về việc áp dụng đám mây và AI trong khu vực. Tọa đàm Lãnh đạo: Thảo luận về chủ đề \u0026ldquo;Điều hướng Cách mạng GenAI\u0026rdquo;, tập trung vào việc nuôi dưỡng văn hóa đổi mới, gắn kết sáng kiến AI với mục tiêu kinh doanh và quản lý thay đổi tổ chức. 2. Nền tảng Dữ liệu \u0026amp; Lộ trình Nền tảng Dữ liệu Thống nhất: Phiên này trình bày cách xây dựng hạ tầng xử lý việc thu thập, lưu trữ, xử lý và quản trị dữ liệu—điều kiện tiên quyết cho các tải công việc AI và phân tích nâng cao. Lộ trình GenAI: AWS trình bày tầm nhìn toàn diện và các xu hướng mới nổi nhằm trao quyền cho các tổ chức tận dụng GenAI để tăng hiệu quả. 3. Tương lai của Phát triển Phần mềm AI-Driven Development Lifecycle (AI-DLC): Một cách tiếp cận chuyển đổi nơi AI không chỉ là trợ lý mà là cộng sự trung tâm. Nó tích hợp việc thực thi bằng AI với sự giám sát của con người để cải thiện tốc độ và chất lượng, vượt xa các phương pháp truyền thống. 4. Bảo mật \u0026amp; Tự động hóa Nâng cao Bảo mật GenAI: Đề cập đến bảo mật ở ba lớp: hạ tầng, mô hình và ứng dụng. Nhấn mạnh các biện pháp tích hợp sẵn như mã hóa, kiến trúc zero-trust và kiểm soát truy cập chi tiết. AI Agents: Phiên bế mạc làm nổi bật sự chuyển dịch từ tự động hóa cơ bản sang Tác nhân Thông minh (Intelligent Agents)—những thực thể có khả năng học hỏi, thích nghi và thực thi các tác vụ phức tạp một cách tự chủ. Bài học chính (Key Takeaways) Chuyển dịch Văn hóa AI-DLC: Phát triển phần mềm đang chuyển từ \u0026ldquo;con người làm chính với sự hỗ trợ của AI\u0026rdquo; sang \u0026ldquo;hợp tác lấy AI làm trung tâm\u0026rdquo;, đòi hỏi sự thay đổi trong cách tiếp cận coding. Agents vs. Automation: Có sự khác biệt rõ rệt giữa các kịch bản tự động hóa tĩnh và các AI Agent năng động có thể ra quyết định dựa trên dữ liệu đầu vào thay đổi. Trụ cột Kỹ thuật Dữ liệu là Tiên quyết: Không thể triển khai GenAI thành công nếu thiếu một nền tảng dữ liệu thống nhất và được quản trị tốt. Bảo mật từ Thiết kế: Bảo mật cho GenAI phải liên tục và nhiều lớp, đảm bảo tính toàn vẹn dữ liệu trong suốt vòng đời AI. Ứng dụng vào công việc Đánh giá Hạ tầng Dữ liệu: Rà soát lại kiến trúc dữ liệu AWS hiện tại để đảm bảo đáp ứng yêu cầu về quy mô và quản trị cho GenAI (dựa trên phiên Unified Data Foundation). Nghiên cứu AI Agents: Xác định các quy trình vận hành thủ công phức tạp có thể chuyển giao cho các AI Agent tự chủ thay vì chỉ viết script đơn giản. Áp dụng AI-DLC: Thử nghiệm tích hợp sâu hơn các công cụ AI vào quy trình phát triển để AI đóng vai trò cộng sự thay vì chỉ gợi ý code. Trải nghiệm sự kiện Hội nghị mang lại cái nhìn toàn diện về bức tranh GenAI, cân bằng giữa chiến lược cấp cao và kiến thức kỹ thuật chuyên sâu.\nGóc nhìn Chiến lược: Phiên tọa đàm với các lãnh đạo từ ELSA, Nexttech và TymeX cung cấp góc nhìn thực tế về việc quản lý thay đổi văn hóa doanh nghiệp do AI mang lại. Chiều sâu Kỹ thuật: Các phiên buổi chiều rất hữu ích, đặc biệt là phần chuyên sâu về AI-DLC và Bảo mật GenAI, đây là những mối quan tâm trực tiếp cho lộ trình kỹ thuật sắp tới của chúng tôi. Một số hình ảnh sự kiện Thêm hình ảnh sự kiện của bạn tại đây\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc: Môi trường tại FCJ mang đậm tính chuyên nghiệp và khuyến khích tư duy \u0026ldquo;Builder\u0026rdquo;. Không gian làm việc luôn tràn đầy năng lượng tích cực không chỉ thoải mái mà còn tạo cảm hứng sáng tạo. Mình đặc biệt thích cách mọi người tranh luận với nhau một cách thẳng thắn và xây dựng, không ngại va chạm để tìm ra phương án tối ưu nhất. Ngoài ra thực tập sinh như mình có thể ngồi cùng bàn và thảo luận trực tiếp với các anh chị mentor mà không gặp rào cản về cấp bậc. Không gian mở là yếu tố giúp mình duy trì được sự hứng khởi mỗi ngày khi đến văn phòng.\n2. Sự hỗ trợ của mentor / team admin: Mentor của mình không chỉ đóng vai trò là người hướng dẫn kỹ thuật mà còn là người định hướng tư duy giải quyết vấn đề. Thay vì chỉ đưa ra đáp án \u0026ldquo;đúng hay sai\u0026rdquo;, anh thường đặt câu hỏi \u0026ldquo;tại sao em chọn cách này?\u0026rdquo; hoặc \u0026ldquo;nếu lượng user tăng gấp 10 lần thì cách này còn chạy không?\u0026rdquo;. Chính phương pháp coaching này đã giúp mình rèn luyện tư duy phản biện và cẩn trọng hơn trong từng dòng code. Sự hỗ trợ từ admin team rất nhanh chóng, đặc biệt là trong việc cấp quyền truy cập tài nguyên Cloud và các công cụ trả phí cần thiết cho công việc.\n3. Sự phù hợp giữa công việc và chuyên ngành học: Những kiến thức về Hệ điều hành, Mạng máy tính hay Cấu trúc dữ liệu học ở trường là nền tảng tốt, nhưng khi áp dụng vào công việc thực tế tại đây, mình thấy chúng được nâng lên một tầm cao mới. Mình được tiếp xúc với các bài toán thực tế về Cloud Computing, Microservices và DevOps – những mảng mà trường học thường chỉ dừng lại ở lý thuyết. Tuy nhiên, đây chính là điểm mình thích nhất vì nó ép mình phải áp dụng kiến thức nền tảng vào các bài toán production thực tế, giúp thu hẹp khoảng cách giữa sinh viên và kỹ sư chuyên nghiệp.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng: Kỳ thực tập này giống như một khóa học cấp tốc về kỹ năng nghề nghiệp. Về mặt kỹ thuật (Hard skills), mình đã thành thạo hơn trong việc sử dụng Git flow, viết Infrastructure as Code (IaC) và debug hệ thống phân tán. Về kỹ năng mềm (Soft skills), mình học được cách làm việc theo quy trình Agile/Scrum, cách viết tài liệu kỹ thuật sao cho người khác dễ hiểu, và quan trọng nhất là kỹ năng giao tiếp – biết cách đặt câu hỏi đúng người, đúng thời điểm để giải quyết vấn đề nhanh nhất.\n5. Văn hóa \u0026amp; tinh thần đồng đội: Văn hóa công ty đề cao sự minh bạch và tinh thần \u0026ldquo;Chia sẻ tri thức\u0026rdquo; (Knowledge Sharing). Khi có sự cố xảy ra, thay vì tìm người chịu trách nhiệm để chỉ trích, cả team cùng nhau ngồi lại phân tích nguyên nhân gốc rễ (Root Cause Analysis) để đảm bảo lỗi đó không lặp lại. Tinh thần đồng đội (Teamwork) cũng rất tuyệt vời; mình chưa bao giờ cảm thấy đơn độc khi gặp khó khăn vì luôn có các đồng nghiệp sẵn sàng support, chia sẻ tài liệu hoặc pair-programming để cùng mình gỡ rối. Các buổi Tech Talk là cơ hội tuyệt vời để gắn kết và học hỏi lẫn nhau.\n6. Chính sách / phúc lợi cho thực tập sinh: Việc được hỗ trợ tài khoản AWS để thực hành thoải mái (sandbox environment) là một phúc lợi tuyệt vời cho dân kỹ thuật. Ngoài ra, các chính sách hỗ trợ thi chứng chỉ quốc tế cũng là động lực lớn để mình phấn đấu.\nMột số câu hỏi khác Điều bạn hài lòng nhất: Mình được tham gia vào các dự án thật, deploy code lên môi trường thật và thấy được tác động thực tế của những tính năng mình làm ra.\nĐiều cần cải thiện: Quy trình onboarding tài liệu kỹ thuật ban đầu còn hơi rời rạc, mất khá nhiều thời gian để tự tổng hợp lại.\nCó giới thiệu cho bạn bè không: Chắc chắn là CÓ. Đây là môi trường lý tưởng cho những bạn đam mê Cloud, đam mê công nghệ và muốn trải nghiệm áp lực làm việc thực tế.\nĐề xuất \u0026amp; mong muốn Đề xuất: Nên tổ chức thêm các buổi \u0026ldquo;Code Review\u0026rdquo; chéo giữa các nhóm thực tập sinh khác nhau để học hỏi thêm về coding style và tư duy của nhau.\nMong muốn tương lai: Mình rất mong muốn có cơ hội trở thành nhân viên chính thức (Fresher/Junior) để tiếp tục đóng góp cho các dự án đang dang dở và phát triển sâu hơn nữa các kỹ năng mình vừa mới bắt đầu nắm bắt.\nGóp ý khác: Cảm ơn công ty đã tạo ra một sân chơi thực sự chất lượng cho sinh viên.\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Làm chủ các khái niệm IAM nâng cao: Truy cập đa vùng, Chuyển đổi vai trò (Switch Role) và Kiểm soát truy cập dựa trên thuộc tính (ABAC - Tags). Triển khai các chính sách bảo mật hạn chế (Restriction Policies) và kiểm thử giới hạn của IAM User. Triển khai bảo mật dữ liệu toàn diện và kiểm toán (auditing) sử dụng KMS, CloudTrail và Amazon Athena. Mô phỏng các kịch bản quản lý danh tính thực tế với IAM Groups và Admin Roles. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Hoàn thành Lab 28: Tạo IAM Policy/Role, thực hành Switch Roles để truy cập tài nguyên khác vùng (Tokyo/N. Virginia) dựa trên Tag. Thực hiện Lab 30 để tạo chính sách hạn chế và test giới hạn người dùng. 10/20/2025 10/20/2025 3 - Bắt đầu Lab 33 về kiểm toán và mã hóa. Tạo các Policy, Role, Group, User cần thiết, sau đó khởi tạo khóa KMS (Key Management Service) và chuẩn bị S3 bucket để upload dữ liệu bảo mật. 10/21/2025 10/21/2025 4 - Hoàn tất Lab 33: Cấu hình CloudTrail để ghi log sự kiện, thiết lập Amazon Athena để truy vấn log, và kiểm thử việc chia sẻ dữ liệu đã mã hóa bằng KMS trên S3 trước khi dọn dẹp.\n10/22/2025 10/22/2025 5 - Bắt đầu Lab 44 để củng cố kiến thức cấu trúc IAM. Tạo các IAM Group và User, sau đó thực hiện kiểm tra quyền (permission checks) chi tiết để hiểu cách policy tác động đến quyền truy cập. 10/23/2025 10/23/2025 6 - Hoàn thành Lab 44 bằng việc tạo Admin IAM Role và cấu hình cơ chế Switch Role để nâng quyền quản trị. Ôn tập lại toàn bộ kiến thức bảo mật và dọn dẹp tài nguyên. 10/24/2025 10/24/2025 Kết quả đạt được tuần 8: Quản lý danh tính nâng cao: Thực hiện thành công cơ chế Switch Role để truy cập an toàn giữa các vai trò. Thực thi kiểm soát truy cập dựa trên thẻ tài nguyên (Tag) xuyên suốt các vùng AWS. Quản lý quyền hạn người dùng hiệu quả thông qua Group và các chính sách hạn chế. Bảo mật \u0026amp; Tuân thủ: Bảo vệ dữ liệu lưu trữ bằng mã hóa AWS KMS. Thiết lập vết kiểm toán (audit trail) với AWS CloudTrail và phân tích log bằng truy vấn SQL trên Amazon Athena. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/4-eventparticipated/4.8-event8/","title":"Workshop: Data Science on AWS","tags":[],"description":"","content":"Báo cáo tổng hợp: “Kick-off AWS First Cloud Journey Workforce OJT FALL 2025” Mục tiêu sự kiện Chính thức khởi động chương trình thực tập AWS First Cloud Journey (FCJ) Workforce OJT mùa Thu 2025. Kết nối sinh viên với các lãnh đạo doanh nghiệp từ AWS, VNG, và G-Asia Pacific. Định hướng nghề nghiệp trong các lĩnh vực Cloud Computing, DevOps và GenAI. Chia sẻ câu chuyện thành công từ cựu sinh viên và thúc đẩy sự đa dạng với chủ đề \u0026ldquo;She in Tech\u0026rdquo;. Diễn giả Thầy Nguyễn Trần Phước Bảo – Trưởng phòng Quan hệ Doanh nghiệp (Đại diện Nhà trường) Anh Nguyễn Gia Hưng – Head of Solutions Architect, AWS Vietnam Anh Đỗ Huy Thắng – DevOps Lead, VNG Anh Danh Hoàng Hiếu Nghị – GenAI Engineer, Renova Chị Bùi Hồ Linh Nhi – AI Engineer, SoftwareOne Anh Phạm Nguyễn Hải Anh – Cloud Engineer, G-Asia Pacific Anh Nguyễn Đồng Thanh Hiệp – Principal Cloud Engineer, G-Asia Pacific Nội dung nổi bật 1. Khai mạc \u0026amp; Tầm nhìn Hợp tác Đào tạo: Thầy Nguyễn Trần Phước Bảo phát biểu khai mạc, nhấn mạnh mối quan hệ chiến lược giữa nhà trường và doanh nghiệp nhằm thu hẹp khoảng cách giữa lý thuyết và thực tiễn. Định hướng Tương lai: Anh Nguyễn Gia Hưng (AWS) trình bày tầm nhìn của \u0026ldquo;First Cloud Journey\u0026rdquo;, khẳng định vai trò của chương trình OJT này như một bệ phóng cho các kiến trúc sư đám mây tương lai tại Việt Nam. 2. Lộ trình Sự nghiệp: DevOps \u0026amp; GenAI Thực tế nghề DevOps: Anh Đỗ Huy Thắng từ VNG chia sẻ cái nhìn thực tế về con đường sự nghiệp DevOps, nêu bật các kỹ năng cốt lõi cần thiết để tồn tại và phát triển trong các tập đoàn công nghệ lớn. Từ FCJ đến GenAI: Các cựu sinh viên Danh Hoàng Hiếu Nghị và Bùi Hồ Linh Nhi đã minh chứng hiệu quả của chương trình qua hành trình chuyển mình nhanh chóng từ thực tập sinh FCJ thành các kỹ sư AI/GenAI chuyên nghiệp. 3. Đa dạng \u0026amp; Đời sống Nghề nghiệp She in Tech: Phần chia sẻ của chị Linh Nhi làm nổi bật vai trò ngày càng quan trọng của nữ giới trong công nghệ, khuyến khích các bạn nữ theo đuổi lĩnh vực Cloud và AI. Một ngày làm Cloud Engineer: Các diễn giả từ G-Asia Pacific (Anh Hải Anh \u0026amp; Anh Hiệp) đã mang đến cái nhìn chân thực về công việc hàng ngày, từ các tác vụ của kỹ sư mới vào nghề đến các quyết định của cấp Principal. Bài học chính (Key Takeaways) Bản đồ Nghề nghiệp Đa dạng hướng đi: Ngành Cloud mở ra nhiều ngã rẽ—từ hạ tầng thuần túy (Cloud Engineer), tự động hóa (DevOps) đến đổi mới sáng tạo (GenAI). Nền tảng là then chốt: Thành công ở các vị trí chuyên sâu như GenAI bắt nguồn từ nền tảng vững chắc về Cloud Computing tích lũy được trong kỳ OJT này. Tư duy Chuyên nghiệp Sự thích nghi: Chuyển từ môi trường đại học sang doanh nghiệp đòi hỏi sự thay đổi tư duy—sự chủ động và tinh thần học hỏi liên tục là bắt buộc. Cộng đồng: Việc kết nối (networking) với mentor và cựu sinh viên tạo ra hệ thống hỗ trợ quan trọng cho sự phát triển sự nghiệp. Ứng dụng vào công việc Đặt mục tiêu OJT: Xác định các cột mốc kỹ thuật cụ thể (ví dụ: đạt chứng chỉ, thành thạo dịch vụ AWS cụ thể) cho kỳ thực tập sắp tới dựa trên lời khuyên của diễn giả. Kết nối Mentor: Chủ động tương tác với các diễn giả và mentor đã gặp trong phần networking. Tìm hiểu GenAI: Dành thời gian trong kỳ OJT để nghiên cứu các dịch vụ Generative AI trên AWS như gợi ý từ các cựu sinh viên. Trải nghiệm sự kiện Được tổ chức tại Bitexco Financial Tower, sự kiện Kick-off mang lại không khí chuyên nghiệp và đầy cảm hứng.\nKhông khí: Sự kiện tràn đầy năng lượng với sự gắn kết mạnh mẽ giữa khóa sinh viên mới, cựu sinh viên và các chuyên gia trong ngành. Cảm hứng: Nghe những người đi trước chia sẻ câu chuyện thành công (\u0026ldquo;Từ FCJ đến GenAI Engineer\u0026rdquo;) giúp mục tiêu nghề nghiệp trở nên rõ ràng và khả thi hơn bao giờ hết. Một số hình ảnh sự kiện Thêm hình ảnh sự kiện của bạn tại đây\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/4-eventparticipated/4.9-event9/","title":"CloudThinker: Agentic AI &amp; Orchestration trên AWS","tags":[],"description":"","content":"Báo cáo tổng hợp: “CloudThinker: Agentic AI \u0026amp; Orchestration trên AWS” Mục tiêu sự kiện Tìm hiểu chuyên sâu về AWS Bedrock Agent Core và các khả năng của nó. Khám phá các trường hợp sử dụng thực tế (Use Case) để xây dựng Quy trình làm việc của Tác nhân (Agentic Workflows). Nắm vững các khái niệm nâng cao như Điều phối Tác nhân (Agentic Orchestration) và Tối ưu hóa Ngữ cảnh (Context Optimization) ở cấp độ kỹ thuật L300. Thực hành trực tiếp thông qua workshop CloudThinker Hack. Diễn giả Anh Nguyễn Gia Hưng – Head of Solutions Architect, AWS Anh Kiên Nguyễn – Solutions Architect, AWS Anh Việt Phạm – Founder \u0026amp; CEO Anh Thắng Tôn – Co-founder \u0026amp; COO, CloudThinker Anh Henry Bùi – Head of Engineering, CloudThinker Anh Kha Văn – Điều phối Workshop Nội dung nổi bật 1. Nền tảng AWS Khai mạc: Anh Nguyễn Gia Hưng mở đầu sự kiện, nhấn mạnh tầm quan trọng của Agentic AI trong bối cảnh công nghệ đám mây hiện nay. Bedrock Agent Core: Anh Kiên Nguyễn cung cấp cái nhìn tổng quan về kỹ thuật của AWS Bedrock Agent Core, giải thích cách dịch vụ này đơn giản hóa việc tạo ra các Agent có khả năng lập kế hoạch và thực thi nhiệm vụ thông qua gọi API. 2. Ứng dụng Thực tế Xây dựng Agentic Workflow: Anh Việt Phạm trình diễn một use case cụ thể, minh họa quy trình từ đầu đến cuối để thiết kế và triển khai một luồng công việc tác nhân trên AWS. Giới thiệu CloudThinker: Anh Thắng Tôn giới thiệu về hệ sinh thái CloudThinker và tầm nhìn của họ về các giải pháp đám mây tích hợp AI. 3. Chuyên sâu (Level 300) Agentic Orchestration \u0026amp; Context Optimization: Đây là phần trọng tâm kỹ thuật của buổi sáng. Anh Henry Bùi thảo luận về các chiến lược nâng cao để điều phối nhiều tác nhân và tối ưu hóa ngữ cảnh trong Amazon Bedrock, đảm bảo độ chính xác cao trong các tương tác phức tạp. 4. Thực hành (Hands-on) CloudThinker Hack: Dưới sự hướng dẫn của anh Kha Văn, phiên thực hành kéo dài 60 phút cho phép người tham dự áp dụng ngay các kiến thức vừa học để xây dựng một prototype agent sử dụng framework của CloudThinker và dịch vụ AWS. Bài học chính (Key Takeaways) Sự tiến hóa của AI Từ Chat sang Hành động: Ngành công nghệ đang chuyển dịch từ chatbot thụ động sang các Agent chủ động có thể thực hiện điều phối phức tạp và gọi API. Ngữ cảnh là then chốt: Khi quy trình làm việc trở nên phức tạp, cửa sổ ngữ cảnh (context window) tiêu chuẩn là không đủ. Các chiến lược \u0026ldquo;Tối ưu hóa ngữ cảnh\u0026rdquo; là thiết yếu để giảm chi phí và tăng độ chính xác. Kiến trúc Mô hình Điều phối: Việc quản lý nhiều agent đòi hỏi một lớp điều phối (orchestration layer) mạnh mẽ để quyết định agent nào sẽ xử lý phần nào của yêu cầu người dùng. Ứng dụng vào công việc Prototype Agent: Sử dụng AWS Bedrock Agent để xây dựng một công cụ nội bộ đơn giản kết nối với API công ty (ví dụ: kiểm tra ngày phép hoặc trạng thái server). Nghiên cứu mô hình Ngữ cảnh: Tìm hiểu kỹ thuật tối ưu hóa ngữ cảnh được chia sẻ bởi anh Henry Bùi để áp dụng vào các hệ thống RAG hiện tại. Tham gia Hackathon: Khuyến khích team tham gia các buổi hackathon thực tế tương tự để cập nhật nhanh nhất các tính năng mới của AWS. Trải nghiệm sự kiện Sự kiện mang tính kỹ thuật cao và tập trung.\nChiều sâu kỹ thuật: Phiên L300 về Orchestration đặc biệt có giá trị để hiểu cách mở rộng ứng dụng AI vượt ra ngoài các bản demo đơn giản. Tính tương tác: Phần \u0026ldquo;CloudThinker Hack\u0026rdquo; giúp củng cố ngay lập tức kiến thức lý thuyết, biến đây thành một trong những buổi học hiệu quả nhất. Một số hình ảnh sự kiện Thêm hình ảnh sự kiện của bạn tại đây\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Hoàn thiện các thực hành tốt nhất về IAM bằng cách so sánh Access Keys và IAM Roles. Hiểu các dịch vụ cơ sở dữ liệu AWS (RDS, Aurora, Redshift, ElastiCache) và các khái niệm DB cơ bản. Triển khai ứng dụng web kiến trúc 2 tầng (2-tier) sử dụng Amazon EC2 và Amazon RDS. Thực hiện các vận hành cơ sở dữ liệu bao gồm sao lưu, khôi phục và kết nối qua RDP. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Hoàn thành Lab 44 với việc giới hạn Switch Role theo IP/Thời gian. Chuyển sang Lab 48 để thực hành tạo IAM Access Key so với việc dùng IAM Role cho EC2, qua đó hiểu tại sao Role an toàn hơn. 10/27/2025 10/27/2025 3 - Học lý thuyết Module 06 về các khái niệm cơ sở dữ liệu (OLTP/OLAP), kiến trúc Amazon RDS \u0026amp; Aurora, và tổng quan về các DB chuyên dụng như Redshift và ElastiCache. 10/28/2025 10/28/2025 4 - Bắt đầu Lab 05 (Triển khai Web App với RDS) bằng việc thiết lập nền tảng mạng: tạo VPC, cấu hình Security Group cho EC2 và RDS, tạo DB Subnet Group và khởi chạy EC2 instance.\n10/29/2025 10/29/2025 5 - Tiếp tục Lab 05: Khởi tạo RDS database instance, cấu hình ứng dụng trên EC2 để kết nối tới database và kiểm tra việc triển khai ứng dụng web thành công. 10/30/2025 10/30/2025 6 - Hoàn tất Lab 05 bằng cách thực hiện sao lưu (backup) và khôi phục (restore) dữ liệu, sau đó dọn dẹp tài nguyên. Bắt đầu Lab 43 với việc học cách kết nối tới Windows instance dùng RDP Client. 10/31/2025 10/31/2025 Kết quả đạt được tuần 9: Thành thạo bảo mật IAM: Đã triển khai các chính sách truy cập có điều kiện (dựa trên IP/Ngày giờ). Chứng minh được lợi ích bảo mật của việc sử dụng IAM Roles thay vì Access Keys dài hạn. Triển khai Cơ sở dữ liệu: Nắm vững sự khác biệt giữa các dịch vụ database của AWS (Quan hệ, Key-value, Kho dữ liệu). Triển khai thành công Cơ sở dữ liệu quan hệ được quản lý (RDS) trong môi trường VPC. Triển khai Ứng dụng: Kết nối thành công ứng dụng web trên EC2 với backend RDS instance. Thực hiện các tác vụ bảo trì quan trọng như tạo bản chụp (snapshot) và khôi phục dữ liệu. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Thực hiện di chuyển cơ sở dữ liệu đa dạng (SQL Server/Oracle sang Aurora MySQL) sử dụng AWS SCT và DMS. Xử lý sự cố trong các kịch bản di chuyển phức tạp liên quan đến chuyển đổi cấu trúc, áp lực bộ nhớ và lỗi bảng. Xây dựng đường ống phân tích dữ liệu Serverless sử dụng Amazon Kinesis, Glue và Athena. Trực quan hóa dữ liệu kinh doanh (BI) sử dụng Amazon QuickSight. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Bắt đầu Lab 43: Kết nối thông qua EC2 Fleet Manager, cấu hình cơ sở dữ liệu Nguồn (SQL Server/Oracle), xử lý các ràng buộc (constraints) và chuẩn bị môi trường Đích Aurora MySQL.\n11/03/2025 11/03/2025 3 - Tiếp tục Lab 43: Sử dụng công cụ Schema Conversion Tool (SCT) để chuyển đổi cấu trúc bảng, tạo các Migration Task, Endpoint và khởi chạy quy trình Serverless Migration. 11/04/2025 11/04/2025 4 - Hoàn tất Lab 43 bằng cách giám sát log, xử lý lỗi (troubleshoot) các kịch bản test như Tràn bộ nhớ (Memory Pressure), Lỗi bảng, kiểm tra dữ liệu và dọn dẹp tài nguyên. 11/05/2025 11/05/2025 5 - Bắt đầu Module 07 (Lab 35): Thiết lập lớp thu thập dữ liệu bằng cách tạo S3 Bucket, cấu hình Kinesis Data Firehose Delivery Stream và tạo dữ liệu mẫu để phân tích. 11/06/2025 11/06/2025 6 - Hoàn thành Lab 35: Cấu hình AWS Glue Crawler để tạo danh mục dữ liệu, thực hiện truy vấn SQL với Amazon Athena, trực quan hóa dữ liệu trên QuickSight và dọn dẹp tài nguyên. 11/07/2025 11/07/2025 Kết quả đạt được tuần 10: Di chuyển Cơ sở dữ liệu (Migration): Thực hiện thành công việc di chuyển dữ liệu từ các nguồn khác nhau (SQL Server, Oracle) sang AWS Aurora MySQL. Sử dụng thành thạo AWS Schema Conversion Tool (SCT) và Database Migration Service (DMS). Có kinh nghiệm xử lý sự cố khi migration thất bại (lỗi bộ nhớ, lỗi ánh xạ bảng). Đường ống Phân tích dữ liệu (Analytics): Xây dựng thành công pipeline dữ liệu serverless: Thu thập (Kinesis) -\u0026gt; Lưu trữ (S3) -\u0026gt; Danh mục hóa (Glue). Phân tích tập dữ liệu lớn bằng truy vấn SQL trên Amazon Athena mà không cần quản lý máy chủ. Business Intelligence: Kết nối Amazon QuickSight với nguồn dữ liệu để tạo các báo cáo trực quan tương tác. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Làm chủ thiết kế và vận hành cơ sở dữ liệu NoSQL với Amazon DynamoDB (Sao lưu, Global Tables). Triển khai chiến lược phân bổ chi phí sử dụng Tagging và các công cụ quản lý chi phí. Sử dụng các công cụ lập trình AWS (CloudShell, SDK) để quản lý tài nguyên bằng mã lệnh. Thực hiện chuẩn bị, hồ sơ hóa (profiling) và làm sạch dữ liệu trực quan với AWS Glue DataBrew. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Đi sâu vào Amazon DynamoDB (Lab 39): Khám phá giao diện console, thực hiện sao lưu/khôi phục và nghiên cứu các mẫu thiết kế nâng cao cho ứng dụng serverless toàn cầu. 11/10/2025 11/10/2025 3 - Hoàn thành Lab 40 về Phân bổ chi phí: Xây dựng cơ sở dữ liệu, nạp dữ liệu, áp dụng chiến lược gắn thẻ (tagging) để theo dõi mức sử dụng và truy vấn chi phí. 11/11/2025 11/11/2025 4 - Thực hiện Lab 60 để thực hành quản lý tài nguyên AWS thông qua giao diện dòng lệnh: Amazon CloudShell và AWS SDK, hiểu rõ sự khác biệt giữa thao tác trên Console và qua code.\n11/12/2025 11/12/2025 5 - Bắt đầu Lab 70 về chuẩn bị dữ liệu: Khởi tạo môi trường Cloud9, tải và upload dataset lên S3, thiết lập AWS Glue DataBrew và chạy profiling để đánh giá chất lượng dữ liệu. 11/13/2025 11/13/2025 6 - Hoàn tất Lab 70 bằng việc làm sạch và chuyển đổi dữ liệu với DataBrew recipes. Tiếp tục Lab 72 để thu thập, lưu trữ và tạo danh mục dữ liệu (Catalog) trên AWS Glue, sau đó dọn dẹp tài nguyên. 11/14/2025 11/14/2025 Kết quả đạt được tuần 11: Cơ sở dữ liệu Serverless (NoSQL): Thành thạo các khái niệm cốt lõi của DynamoDB và kiến trúc hướng sự kiện. Triển khai được chiến lược sao lưu cho dữ liệu NoSQL. Quản lý \u0026amp; Chi phí: Áp dụng hiệu quả chiến lược gắn thẻ (tagging) để theo dõi chi phí chi tiết. Chứng minh khả năng tương tác với AWS thông qua CLI/SDK trên CloudShell. Kỹ thuật dữ liệu (Data Engineering): Sử dụng AWS Glue DataBrew để chuẩn hóa và làm sạch dữ liệu thô mà không cần viết code. Xây dựng được danh mục dữ liệu nền tảng cho các quy trình phân tích. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Làm chủ quy trình ETL (Trích xuất, Chuyển đổi, Tải) nâng cao sử dụng AWS Glue, DataBrew và Amazon EMR. Triển khai phân tích thời gian thực với Kinesis và kho dữ liệu (Data Warehousing) với Amazon Redshift. Xây dựng các bảng điều khiển thông minh (BI Dashboards) tương tác chuyên nghiệp bằng Amazon QuickSight. Tổng ôn: Rà soát kiến thức toàn bộ Module 1-7 và hoàn thiện Worklog cuối kỳ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thực hiện các tác vụ chuyển đổi dữ liệu nâng cao trong Lab 72 sử dụng nhiều phương thức của AWS Glue (Interactive Sessions, GUI, DataBrew) và xử lý dữ liệu lớn với Amazon EMR. 11/17/2025 11/17/2025 3 - Tiếp tục Lab 72: Chạy truy vấn SQL với Amazon Athena, thực hiện phân tích dữ liệu thời gian thực bằng Kinesis Data Analytics và tạo các biểu đồ trực quan ban đầu trên QuickSight. 11/18/2025 11/18/2025 4 - Hoàn tất Lab 72 bằng việc tự động hóa cung cấp dữ liệu qua AWS Lambda và thiết lập Kho dữ liệu mạnh mẽ sử dụng Amazon Redshift để xử lý các truy vấn phức tạp. 11/19/2025 11/19/2025 5 - Hoàn thành Lab 73: Xây dựng, cải tiến và xuất bản các bảng điều khiển tương tác (Interactive Dashboards) trên Amazon QuickSight để trực quan hóa các chỉ số quan trọng. 11/20/2025 11/20/2025 6 - Tổng ôn tập: Rà soát lại các khái niệm cốt lõi từ Module 1 đến Module 7, kiểm tra và xóa toàn bộ tài nguyên cloud để tránh phát sinh chi phí, hoàn thiện Worklog cuối kỳ để nộp. 11/21/2025 11/21/2025 Kết quả đạt được tuần 12: Kỹ thuật dữ liệu nâng cao: Thực hiện chuyển đổi dữ liệu phức tạp sử dụng cả dịch vụ Serverless (Glue) và Cluster (EMR). Xây dựng hạ tầng Kho dữ liệu (Data Warehouse) sử dụng Amazon Redshift. Phân tích \u0026amp; BI: Triển khai xử lý luồng dữ liệu thời gian thực với Kinesis. Thiết kế và triển khai các Dashboard tương tác trên Amazon QuickSight hỗ trợ ra quyết định. Hoàn thành khóa học: Đã tổng hợp và rà soát lại toàn bộ hành trình lên mây (Compute, Storage, Database, Security, Analytics). Hoàn thiện Worklog tổng kết và dọn dẹp sạch sẽ môi trường AWS. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.1-workshop-overview/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Giới thiệu\u0026rdquo; date: 2025-09-09 weight : 1 chapter : false pre : \u0026quot; 5.1. \u0026quot;\nGiới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.2-prerequiste/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Các bước chuẩn bị\u0026rdquo; date: 2025-09-09 weight : 2 chapter : false pre : \u0026quot; 5.2. \u0026quot;\nIAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Tạo một Gateway Endpoint\u0026rdquo; date: 2025-09-09 weight : 1 chapter : false pre : \u0026quot; 5.3.1 \u0026quot;\nMở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Kiểm tra Gateway Endpoint\u0026rdquo; date: 2025-09-09 weight : 2 chapter : false pre : \u0026quot; 5.3.2 \u0026quot;\nTạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.3-s3-vpc/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Truy cập S3 từ VPC\u0026rdquo; date: 2025-09-09 weight : 3 chapter : false pre : \u0026quot; 5.3. \u0026quot;\nSử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Chuẩn bị tài nguyên\u0026rdquo; date: 2025-09-09 weight : 1 chapter : false pre : \u0026quot; 5.4.1 \u0026quot;\nĐể chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Tạo một S3 Interface endpoint\u0026rdquo; date: 2025-09-09 weight : 2 chapter : false pre : \u0026quot; 5.4.2 \u0026quot;\nTrong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Kiểm tra Interface Endpoint\u0026rdquo; date: 2025-09-09 weight : 3 chapter : false pre : \u0026quot; 5.4.3 \u0026quot;\nLấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Mô phỏng On-premises DNS \u0026quot; date: 2025-09-09 weight : 4 chapter : false pre : \u0026quot; 5.4.4 \u0026quot;\nAWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.4-s3-onprem/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Truy cập S3 từ môi trường truyền thống\u0026rdquo; date: 2025-09-09 weight : 4 chapter : false pre : \u0026quot; 5.4. \u0026quot;\nTổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.5-policy/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;VPC Endpoint Policies\u0026rdquo; date: 2025-09-09 weight : 5 chapter : false pre : \u0026quot; 5.5 \u0026quot;\nKhi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"},{"uri":"https://datngo196.github.io/Internship_Report/vi/5-workshop/5.6-cleanup/","title":"","tags":[],"description":"","content":"title : \u0026ldquo;Dọn dẹp tài nguyên\u0026rdquo; date: 2025-09-09 weight : 6 chapter : false pre : \u0026quot; 5.6. \u0026quot;\nDọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://datngo196.github.io/Internship_Report/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://datngo196.github.io/Internship_Report/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]