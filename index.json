[{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/","title":"Worklog","tags":[],"description":"","content":"On this page, I will introduce my Worklog. It details how I approached and completed the tasks, the specific duration of the internship program, and a summary of what I accomplished and learned throughout this period :\nWeek 1: Getting familiar with Cloud Computing, IAM, and Cost Management (AWS Budgets)\nWeek 2: Building Network Infrastructure: Multi-AZ VPC, Security, and Load Balancing\nWeek 3: Implementing Hybrid DNS Architecture with Route 53 Resolver\nWeek 4: Getting started with AWS Console/CLI, EC2, and Basic Storage (S3, Storage Gateway)\nWeek 5: Advanced Storage (S3 Glacier/Snow Family), VM Import, and Windows File Server (FSx)\nWeek 6: Advanced FSx Administration, Content Delivery (CloudFront), and IAM Fundamentals\nWeek 7: Enterprise Security Governance (Organizations, Security Hub) and Automation with Lambda\nWeek 8: Advanced Identity Management (IAM), Encryption (KMS), and System Auditing (CloudTrail/Athena)\nWeek 9: IAM Security Optimization and Web Application Deployment with Relational Database (RDS)\nWeek 10: Database Migration (DMS/SCT) and Building Serverless Data Analytics Pipelines\nWeek 11: NoSQL Databases (DynamoDB), Cost Management, and Data Preparation with Glue DataBrew\nWeek 12: Big Data Analytics (EMR, Redshift), Visualization (QuickSight), and Course Wrap-up\n"},{"uri":"https://datngo196.github.io/Internship_Report/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Chứng nhận ISO năm 2025 và CSA STAR hiện đã khả dụng cùng với hai dịch vụ bổ sung *Bởi Chinmaee Parulekar, đăng ngày 17 tháng 9 năm 2025, thuộc chuyên mục Announcements, Foundational (100), *Security, Identity \u0026amp; Compliance\nAmazon Web Services (AWS) đã hoàn tất thành công cuộc kiểm toán mở rộng mà không có bất kỳ phát hiện sai sót nào cho các tiêu chuẩn ISO 9001:2015, 27001:2022, 27017:2015, 27018:2019, 27701:2019, 20000-1:2018, 22301:2019 và Tiêu chuẩn Cloud Security Alliance (CSA) STAR Cloud Controls Matrix (CCM) v4.0. Cuộc kiểm toán được thực hiện bởi EY CertifyPoint, và các chứng chỉ đã được cấp lại vào ngày 13 tháng 8 năm 2025. Mục tiêu của cuộc kiểm toán là giúp AWS mở rộng phạm vi các chứng nhận ISO và CSA STAR để bao gồm thêm hai dịch vụ AWS Resource Explorer và AWS Incident Response. Các tiêu chuẩn ISO này bao phủ các lĩnh vực như quản lý chất lượng, an ninh thông tin, bảo mật đám mây, bảo vệ quyền riêng tư, quản lý dịch vụ và duy trì hoạt động kinh doanh liên tục. Việc đạt được các chứng nhận này thể hiện cam kết của AWS trong việc duy trì các biện pháp kiểm soát an ninh mạnh mẽ và bảo vệ dữ liệu khách hàng trên toàn bộ các dịch vụ của mình.\nTrong cuộc kiểm toán mở rộng này, chúng tôi đã bổ sung thêm hai dịch vụ AWS mới vào phạm vi chứng nhận kể từ lần cấp chứng chỉ gần nhất vào ngày 26 tháng 5 năm 2025. Hai dịch vụ được bổ sung bao gồm:\nAWS Resource Explorer\nAWS Security Incident Response\nĐể xem danh sách đầy đủ các dịch vụ AWS đã được chứng nhận theo tiêu chuẩn ISO và CSA STAR, vui lòng truy cập trang AWS ISO and CSA STAR Certified. Khách hàng cũng có thể truy cập các chứng chỉ này trực tiếp trong AWS Management Console thông qua AWS Artifact.\nChinmaee Parulekar là Quản lý Chương trình Tuân thủ (Compliance Program Manager) tại AWS, với 6 năm kinh nghiệm trong lĩnh vực an ninh thông tin. Cô sở hữu bằng Thạc sĩ Khoa học (Master of Science) chuyên ngành Hệ thống Thông tin Quản lý (Management Information Systems), cùng các chứng chỉ nghề nghiệp như CISA và HITRUST CCSF Practitioner. "},{"uri":"https://datngo196.github.io/Internship_Report/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Ngo Huu Dat\nPhone Number: 0911449689\nEmail: datngo2005@gmail.com\nUniversity: FPT University\nMajor: Artificial Intelligence\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 08/09/2025 to 12/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.1-workshop-overview/","title":"Introduction","tags":[],"description":"","content":"About MapVibe MapVibe is an AI-powered location discovery platform that helps users find dining and activity locations in Ho Chi Minh City using natural language queries. Instead of traditional keyword searches, users can express their needs in conversational language, such as \u0026ldquo;I\u0026rsquo;m feeling sad today, is there any drink place that can help me relieve my sadness?\u0026rdquo;\nThe platform leverages AWS AI services including:\nAWS Bedrock - For natural language processing using Titan embedding model and Claude LLM Amazon Rekognition - For content moderation of user-uploaded images Amazon Textract - For extracting text from menu images and signs Workshop overview In this workshop, you will learn how to build and deploy MapVibe, a full-stack application using:\nMonorepo Architecture - Using TurboRepo and Bun for efficient development Frontend Applications: apps/web - Main user-facing web application (React 19, Vite, TailwindCSS) apps/admin - Admin dashboard for content management Backend Services: apps/api - Main API Lambda function handling REST endpoints Multiple specialized Lambda functions for embeddings, RAG, OCR, Rekognition, and review aggregation Infrastructure: Terraform modules for AWS services (VPC, RDS, Lambda, API Gateway, CloudFront, Cognito, etc.) Infrastructure as Code approach for reproducible deployments Architecture Overview The MapVibe architecture follows a serverless-first approach:\nFrontend: React applications deployed to S3 and served via CloudFront CDN API Layer: API Gateway routes requests to Lambda functions Data Layer: PostgreSQL RDS database for structured data storage AI Services: Bedrock for embeddings and LLM, Rekognition for image analysis Storage: S3 buckets for photos and static assets Authentication: AWS Cognito for user management Security: WAF for protection, Route53 and ACM for custom domains "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Monorepo Setup","tags":[],"description":"","content":"Clone the Repository First, clone the MapVibe repository:\ngit clone \u0026lt;repository-url\u0026gt; cd mapvibe Install Dependencies Install all dependencies using Bun:\nbun install This will install dependencies for all workspaces in the monorepo.\nWorkspace Configuration The project uses Bun workspaces defined in package.json:\n{ \u0026#34;workspaces\u0026#34;: [ \u0026#34;apps/*\u0026#34;, \u0026#34;packages/*\u0026#34;, \u0026#34;infrastructure\u0026#34; ] } TurboRepo Configuration TurboRepo is configured in turbo.json to manage build pipelines:\nbuild - Builds all packages and apps dev - Runs development servers lint - Lints all code type-check - Type checks TypeScript deploy - Deploys applications Development Scripts Common scripts available at the root:\n# Start all development servers bun run dev # Build all packages and apps bun run build # Lint all code bun run lint # Type check bun run type-check # Format code bun run format Environment Variables Create .env files as needed:\nRoot .env - For infrastructure variables apps/web/.env - For frontend configuration apps/admin/.env - For admin dashboard Contact the project maintainer for required environment variables.\nVerify Setup Verify your setup by running:\n# Check Bun version bun --version # Install dependencies bun install # Run type check bun run type-check If all commands succeed, your monorepo is ready for development!\n"},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Terraform Setup","tags":[],"description":"","content":"Prerequisites Before deploying infrastructure, ensure you have:\nTerraform installed (\u0026gt;= 1.0) AWS CLI configured with appropriate credentials AWS account with necessary permissions Configure Terraform Variables Navigate to the infrastructure directory:\ncd infrastructure/terraform Create a terraform.tfvars file (or use environment variables):\naws_region = \u0026#34;ap-southeast-1\u0026#34; environment = \u0026#34;mvp\u0026#34; project_name = \u0026#34;mapvibe\u0026#34; db_name = \u0026#34;mapvibe\u0026#34; # Optional: Google OAuth google_client_id = \u0026#34;\u0026#34; google_client_secret = \u0026#34;\u0026#34; Initialize Terraform Initialize Terraform to download providers:\nterraform init This will:\nDownload the AWS provider Set up the backend (if configured) Initialize modules Review Terraform Plan Before applying, review what will be created:\nterraform plan This shows:\nResources to be created Resources to be modified Resources to be destroyed Important Notes Cost: This infrastructure will create billable AWS resources Region: Default is ap-southeast-1 (Singapore) WAF: Requires us-east-1 for CloudFront (handled automatically) Database: RDS instance will be created (db.t3.micro for MVP) Domain: You\u0026rsquo;ll need a domain name for Route53 (e.g., mapvibe.site) Next Steps Once Terraform is initialized and configured, proceed to deploy the infrastructure.\n"},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Objectives: Master the core concepts of Cloud Computing as defined by AWS Understand the AWS Global Infrastructure, including Regions, Availability Zones (AZs), and Edge Locations Familiarize with fundamental management tools (Console, IAM) and initial cost optimization methods on AWS Complete initial account setup, implementing security (MFA, IAM User), and budget management (AWS Budget) Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Research Cloud definition, payment models, core benefits (cost optimization, elasticity, global scaling). Research AWS Global Infrastructure (Data Center, AZ, Region, Edge Locations) 09/01/2025 09/01/2025 3 - Hands-on practice creating an AWS account (including email/phone/payment verification). Set up a Virtual MFA Device for the Root User for security 09/02/2025 09/02/2025 4 - Study AWS management tools (Console, Root/IAM User, CLI, SDK). Practice creating an IAM Admin Group and an IAM Admin User 09/03/2025 09/03/2025 5 - Research discounted payment options (On-Demand, RI, Saving Plans, Spot Instances) and the Serverless model. Practice creating an AWS Budget using a Template (monthly) 09/04/2025 09/04/2025 6 - Practice creating a Custom Cost Budget and a Usage Budget (e.g., limiting EC2 hours). Research AWS Support packages (Basic, Developer, Business, Enterprise). Clean up resources (Clean Up Budgets) 09/05/2025 09/05/2025 Week 1 Achievements: Understood the Cloud definition: On-demand delivery of IT resources over the Internet with pay-as-you-go pricing. Mastered core benefits, including cost optimization and the ability to elastically scale resources. Understood Global Infrastructure: Availability Zones (AZs) are key for fault isolation, and deploying across a minimum of 2 AZs is recommended for high availability. Completed account creation and security setup: MFA was successfully configured for the Root User. Created the IAM Admin Group and User, adhering to the security best practice of restricting Root User access. Familiarized with cost models: On-Demand (highest cost), Long-term commitment (RI/Saving Plans), and Temporary/Spare capacity (Spot Instances, up to 90% discount). Successfully set up AWS Budgets to monitor costs (Cost Budget) and track resource consumption limits (Usage Budget). Differentiated the 4 main AWS Support tiers (Basic free tier, Developer, Business, Enterprise) "},{"uri":"https://datngo196.github.io/Internship_Report/4-eventparticipated/4.1-event1/","title":"AWS First Cloud Journey Community Day","tags":[],"description":"","content":"Summary Report: “AWS First Cloud Journey Community Day” Event Objectives Foster the AWS community vision and connect industry professionals. Demonstrate practical applications of Generative AI in Enterprise, Banking, and Academic sectors. Explore advanced architectures including RAG (Retrieval-Augmented Generation) and Multi-Agent Systems. Showcase serverless implementations for scalable AI solutions. Speakers Nguyễn Gia Hưng – Head of Solutions Architect, AWS Phạm Tiến Thuận Phát, Lê Minh Nghĩa, Trần Đoàn Công Lý – Enterprise Software Đinh Lê Hoàng Anh, Nguyễn Tài Minh Huy – Academic Sector Kiệt Lâm, Nguyễn Ngọc Quỳnh Mai – Banking / Internal IT Lê Phạm Ngọc Uyển, Phan Thị Thanh Thảo, Hồ Điền Đăng Khoa, Nguyễn Quang Nhật Linh – Banking / Process Automation Việt Lý – AWS Partner / Cloud \u0026amp; AI Key Highlights 1. Community Vision Opening Remarks: Mr. Nguyễn Gia Hưng kicked off the event at Bitexco Tower, outlining the vision for the AWS community and the objectives of sharing practical, hands-on cloud knowledge. 2. Enterprise \u0026amp; Contextual AI Enterprise Chatbot with MCP: The team presented on unlocking context using the Model Context Protocol (MCP) on AWS. They demonstrated how to build chatbots that handle complex enterprise context effectively, sharing lessons learned from actual implementation. 3. Real-World GenAI Applications Kitchen Recipe Recommendation: An academic showcase featuring a personalized system powered by GenAI. The session detailed the AWS workflow design used to tailor recipes to user preferences. Internal Chatbot with RAG: A deep dive into building an FAQ and knowledge base bot using Retrieval-Augmented Generation (RAG). The key takeaway was the fully serverless architecture, ensuring cost-effectiveness and scalability. 4. Advanced Automation in Banking Multi-Agent Systems: A highlight session on applying GenAI Multi-Agent Systems to automate complex banking processes. The speakers shared real-world case studies demonstrating how multiple agents coordinate to handle specific banking tasks using serverless workflows. 5. Tools \u0026amp; Orchestration GenAI with Kiro IDE \u0026amp; Strands Agent: Explored the application of GenAI in both Production and R\u0026amp;D environments. The session focused on workflow orchestration and featured a live multi-agent demo on AWS. Key Takeaways Architectural Shift From Chatbots to Agents: The industry is moving beyond simple Q\u0026amp;A bots towards Multi-Agent Systems that can execute complex tasks and workflows, especially in regulated sectors like Banking. Serverless is Key: Both RAG and Agent systems were heavily demonstrated on Serverless AWS infrastructure, highlighting it as the standard for modern AI deployment. Practical Implementation Context is King: For enterprise adoption, handling context (via MCP or RAG) is crucial for relevance and accuracy. Orchestration: Tools like Kiro IDE and Strands Agent are emerging to help manage the complexity of AI workflows. Applying to Work Evaluate Multi-Agent Systems: Investigate using a multi-agent approach for complex internal automation tasks rather than a single monolithic model. Adopt Serverless RAG: Review current internal knowledge bases and prototype a Serverless RAG solution to improve information retrieval. Explore MCP: Research the Model Context Protocol to see if it improves context retention in our current chatbot applications. Event Experience The event at Bitexco Tower provided a dense morning of technical insights. The parallel sessions allowed for a deep dive into specific industry verticals.\nNetworking: The \u0026ldquo;Welcome Coffee\u0026rdquo; and \u0026ldquo;Buffer\u0026rdquo; sessions provided excellent opportunities to connect with AWS Solution Architects and industry peers. Practical Demos: Seeing live demos of Multi-Agent systems in banking and Recipe Recommendations bridged the gap between GenAI theory and tangible product delivery. Some event photos Add your event photos here\n"},{"uri":"https://datngo196.github.io/Internship_Report/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Tự động xoay vòng OIDC client secret với Application Load Balancer *Bởi Kani Murugan, đăng ngày 16 tháng 9 năm 2025, thuộc các chuyên mục: Advanced 300, Security, Identity, \u0026amp; Compliance ,Technical How-to.\nElastic Load Balancing đơn giản hóa việc xác thực bằng cách chuyển giao công việc này cho các nhà cung cấp danh tính (IdP) tương thích với OpenID Connect (OIDC). Điều này cho phép các nhà phát triển tập trung vào logic ứng dụng trong khi vẫn sử dụng cơ chế quản lý danh tính mạnh mẽ.\nOIDC client secret là các thông tin đăng nhập bí mật được sử dụng trong các giao thức OAuth 2.0 và OIDC để xác thực client (ứng dụng). Tuy nhiên, việc quản lý thủ công OIDC client secret có thể tạo rủi ro bảo mật và gia tăng gánh nặng vận hành.\nNhư hình 1 minh họa, quản lý thủ công OIDC client secret bắt đầu bằng xác thực thông qua một IdP bên thứ ba.\nHình 1: Quản lý thủ công OIDC client secret\nCác rủi ro khi quản lý thủ công OIDC client secret bao gồm:\nLộ thông tin đăng nhập dạng plaintext\nCần can thiệp thủ công để điều chỉnh cấu hình Application Load Balancer (ALB) Thiếu giám sát chủ động đối với thay đổi của thông tin đăng nhập\nThiếu xác minh liên tục các thông tin xác thực\nKhông khả thi khi mở rộng cấu hình ALB với nhiều listener rules \\\nTrong bài viết này, tôi sẽ hướng dẫn cách tự động xoay vòng OIDC client secret bằng AWS Secrets Manager, AWS Lambda và AmazonEventBridge, giúp nâng cao bảo mật và tối ưu hóa vận hành. Tự động xoay vòng secret là một thực hành bảo mật quan trọng, giúp giảm thiểu rủi ro lộ thông tin đăng nhập và hỗ trợ tuân thủ liên tục.\nĐối với cấu hình ALB-OIDC authentication, xem hướng dẫn Authenticate, Users using an Application Load Balancer.\nTổng quan giải pháp Giải pháp này cung cấp khung linh hoạt để quản lý thông tin đăng nhập tự động trên nhiều nhà cung cấp OIDC (Auth0 làm ví dụ), với một triển khai cụ thể tích hợp với các dịch vụ AWS. Kiến trúc cốt lõi hỗ trợ: xoay vòng thông tin đăng nhập tự động, lưu trữ bí mật an toàn, thiết kế không phụ thuộc vào nhà cung cấp (provider-agnostic), triển khai mở rộng cho các workflow xác thực khác nhau. Các thành phần chính bao gồm:\nSecrets Manager: Lưu trữ và quản lý an toàn thông tin đăng nhập OIDC (Auth0).\nLambda: Thực thi logic xoay vòng secret theo lịch định sẵn.\nElastic Load Balancing: Chuyển giao việc xác thực bằng các OIDC listener rules.\nEventBridge (scheduled): Kích hoạt Lambda theo lịch đã định.\nCustom AWS CloudFormation resource: Tự động hóa toàn bộ stack và kiến trúc được sử dụng trong bài viết này.\nHình 2: Tự động xoay vòng OIDC client secret\nWorkflow xác thực, như minh họa trong Hình 2, bao gồm các bước:\nEventBridge kích hoạt Lambda handler** Auth0CredentialHandler **mỗi 15 phút.\nLambda handler ``uth0CredentialHandler** **kết nối đến domain quản lý Auth0 và lấy thông tin client hiện tại — auth0_current.\nLambda handler ``Auth0CredentialHandler** truy xuất thông tin đăng nhập hiện có **auth0/credentials/${Auth0-dev-domain} từ Secrets Manager và so sánh với thông tin ``auth0_current đã lấy ở bước trước.\nNếu secret không tìm thấy, handler sẽ thử lại 3 lần trong vòng 30 phút và sau đó ghi log cảnh báo vào AWS CloudWatch.\nGiả định rằng ARN của secret đã tồn tại trong Secrets Manager\nNếu thông tin đăng nhập khác nhau, Auth0CredentialHandler **cập nhật auth0/credentials/${Auth0-dev-domain} **với giá trị mới. Nếu thông tin đăng nhập giống nhau, không thực hiện hành động nào. CloudWatch alarms được cấu hình để kích hoạt khi cập nhật secret thành công hoặc thất bại.\nALB listener rule được cấu hình để lấy thông tin client credentials một cách động từ ARN của resource auth0/credentials/${Auth0-dev-domain}** **trong Secrets Manager.\nKhuyến nghị bảo mật\nCó một số biện pháp để nâng cao bảo mật hệ thống xác thực, bao gồm: triển khai quản lý secret tập trung với mã hóa dữ liệu khi lưu trữ (encryption at rest), cấu hình Lambda với quyền tối thiểu (least-privilege), chỉ giới hạn truy cập đến các resource cần thiết trong Secrets Manager và ALB listener, giúp giảm phạm vi rủi ro bảo mật (security blast radius).\nSử dụng CloudWatch alarms để giám sát các sự kiện quan trọng, bao gồm Cập nhật secret, Thất bại khi cập nhật secret, Các vấn đề liên quan đến credential của ALB và Sử dụng AWS Config để theo dõi cấu hình rule và thực hiện đánh giá bảo mật định kỳ.\nBằng cách Tạo secret riêng biệt cho từng ALB listener rule, cho phép kiểm soát truy cập chi tiết (granular access control) và thu hẹp phạm vi quyền hạn, giúp nâng cao bảo mật tổng thể của hệ thống.\nBằng cách tuân theo các thực hành này, bạn có thể thiết lập khung bảo mật vững chắc cho ứng dụng, đồng thời đảm bảo bảo vệ dữ liệu và quản lý truy cập đúng cách.\nYêu cầu tiên quyết\nGiải pháp này giả định rằng các điều kiện sau đã được đáp ứng trước khi triển khai:\nMột ALB hiện có được cấu hình với listener và target group, sử dụng làm Listenerarn và targetarn trong CloudFormation template.\nTài khoản OIDC IdP (ví dụ: Auth0) và ứng dụng client.\nThông tin đăng nhập client của ứng dụng Auth0 IdP đã được lưu trữ trong Secrets Manager.\n{ \u0026#34;domain\u0026#34;: \u0026#34;your-tenant.auth0.com\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;your-client-id\u0026#34;, \u0026#34;client_secret\u0026#34;: \u0026#34;your-client-secret\u0026#34; } Chi tiết triển khai\nLưu ý: Giải pháp này minh họa tự động xoay vòng OIDC client secret sử dụng Auth0 làm IdP. Mặc dù các nguyên tắc cốt lõi và mô hình kiến trúc có thể áp dụng rộng rãi, các chi tiết triển khai cụ thể có thể khác nhau tùy từng nhà cung cấp danh tính. Người dùng nên tham khảo tài liệu của IdP cụ thể để biết các bước cấu hình chính xác, cách tương tác API và các cơ chế xác thực tương thích với AWS.\nĐây là một phương pháp tự động, đơn giản và có thể mở rộng, sử dụng CloudFormation custom resource để tạo các resource được minh họa trong sơ đồ kiến trúc. CloudFormation template và AWS Lambda implementation được lưu trữ trong demo-stack.\nCác thành phần cốt lõi\nTrong phần này, tôi sẽ giải thích các thành phần chính của giải pháp.\nQuy tắc làm mới thông tin xác thực\nMột EventBridge rule được lên lịch để kích hoạt Lambda function Auth0CredentialHandler** **mỗi 15 phút, sử dụng LambdaInvokePermission của AWS Identity and Access Management (IAM) role.\nAuth0CredentialHandler Lambda function\nLambda function ``Auth0CredentialHandler chịu trách nhiệm quản lý client credentials một cách an toàn. Nó truy xuất cấu hình Auth0 từ Secrets Manager tại resource auth0/credentials/${Auth0-dev-domain}, thực hiện API call đến domain Auth0 để lấy token mới, quản lý cập nhật thông tin đăng nhập mới vào Secrets Manager. Lambda này cần quyền truy cập Secrets Manager, được cấp thông qua execution role.\nIAM role của Lambda có hai bộ quyền chính:\nAWS managed policy ``AWSLambdaBasicExecutionRole, cho phép Lambda tạo log trên CloudWatch. \\\nCustom policy, cấp quyền cụ thể trên Secrets Manager (``GetSecretValue``, ``CreateSecret``, ``UpdateSecret``) cho các secret dưới path auth0/credentials/${Auth0-dev-domain}.\nLambda sẽ thử lại 3 lần trong vòng 30 phút. Nếu tất cả các lần thử thất bại, CloudWatch sẽ ghi cảnh báo và tạo alarms.\nManagedPolicyArns: - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole Policies: - PolicyName: SecretsManagerAccess PolicyDocument: Version: \u0026#39;2012-10-17\u0026#39; Statement: - Effect: Allow Action: - secretsmanager:GetSecretValue - secretsmanager:CreateSecret - secretsmanager:UpdateSecret Resource: - !Sub arn:aws:secretsmanager:${AWS::Region}:${AWS::AccountId}:secret:auth0/* # Permission for Amazon EventBridge to invoke Lambda LambdaInvokePermission: Type: AWS::Lambda::Permission Properties: Action: lambda:InvokeFunction FunctionName: !Ref Auth0CredentialHandler Principal: events.amazonaws.com SourceArn: !GetAtt CredentialRefreshRule.Arn ALB Listener Rules\nCác resource listener rule của Elastic Load Balancing trong CloudFormation được cấu hình để lấy động thông tin client credentials từ Secrets Manager và chuyển tiếp các request đã xác thực đến target group cụ thể. Chúng tích hợp với thông tin đăng nhập Auth0, được Lambda** Auth0CredentialHandler **tự động làm mới định kỳ. Cấu hình này yêu cầu quyền đọc (read access) trên Secrets Manager để lấy Auth0 client credentials phục vụ quá trình xác thực.\n# ALB Listener Rules - replace the Oidc config with your endpoints. Only Client credentials are stored in SecretsManager ListenerRule1: Type: AWS::ElasticLoadBalancingV2::ListenerRule Properties: ListenerArn: arn:aws:elasticloadbalancing:region:account-id:listener/app/my-load-balancer/1234567890/abcdef Priority: 1 Actions: - Type: authenticate-oidc AuthenticateOidcConfig: ClientId: \u0026#39;{{resolve:secretsmanager:auth0/credentials/your-tenant.auth0.com:SecretString:client_id}}\u0026#39; ClientSecret: \u0026#39;{{resolve:secretsmanager:auth0/credentials/your-tenant.auth0.com:SecretString:client_secret}}\u0026#39; Issuer: https://idp1.example.com AuthorizationEndpoint: https://idp1.example.com/auth TokenEndpoint: https://idp1.example.com/token UserInfoEndpoint: https://idp1.example.com/userinfo OnUnauthenticatedRequest: authenticate - Type: forward TargetGroupArn: arn:aws:elasticloadbalancing:region:account-id:targetgroup/target-group-1/1234567890abc Conditions: - Field: path-pattern Values: - /app1/* Giám sát và cảnh báo với CloudWatch\nCloudFormation template được cung cấp được cấu hình để thiết lập giám sát bảo mật cho các cập nhật secret. Template này thực hiện Cấu hình cảnh báo cho cả cập nhật secret thành công và cập nhật thất bại, Tạo các CloudWatch metric filter sử dụng AWS CloudTrail logs, Thiết lập các alarm tương ứng với các ngưỡng đã định, Tạo một Amazon Simple Notification Service (Amazon SNS) topic để gửi cảnh báo tổng hợp. Khi triển khai, giải pháp hạ tầng như mã (infrastructure-as-code) này sẽ tự động phát hiện và thông báo các sự kiện bảo mật tiềm ẩn liên quan đến quản lý secret và các nỗ lực truy cập trái phép.\n# CloudWatch Log Group CloudTrailLogGroup: Type: AWS::Logs::LogGroup Properties: LogGroupName: secrets-manager-monitoring RetentionInDays: 14 # Combined Metric Filter for Both Success and Failed Updates SecretUpdateMetricFilter: Type: AWS::Logs::MetricFilter Properties: LogGroupName: !Ref CloudTrailLogGroup FilterPattern: !Sub \u0026#39;{ $.eventSource = secretsmanager.amazonaws.com \u0026amp;\u0026amp; ($.eventName = UpdateSecret || $.eventName = PutSecretValue) \u0026amp;\u0026amp; $.responseElements.ARN = \u0026#34;${MyCustomResource.SecretArn}\u0026#34; }\u0026#39; MetricTransformations: - MetricNamespace: \u0026#39;SecretsManager/Updates\u0026#39; MetricName: \u0026#39;SecretUpdates\u0026#39; MetricValue: \u0026#39;1\u0026#39; DefaultValue: 0 # Combined Alarm for Both Success and Failed Updates SecretUpdateAlarm: Type: AWS::CloudWatch::Alarm Properties: AlarmName: !Sub \u0026#39;${AWS::StackName}-secret-update\u0026#39; AlarmDescription: !Sub \u0026#39;Alarm for any updates (success or failure) to secret ${MyCustomResource.SecretArn}\u0026#39; MetricName: SecretUpdates Namespace: SecretsManager/Updates Statistic: Sum Period: 300 EvaluationPeriods: 1 Threshold: 0 ComparisonOperator: GreaterThanThreshold TreatMissingData: notBreaching AlarmActions: - !Ref SecretMonitoringTopic Để nâng cao độ tin cậy của quá trình xoay vòng secret, hãy triển khai giám sát toàn diện bằng cách: Tạo CloudWatch alarms để phát hiện thất bại khi Lambda thực hiện xoay vòng vượt quá ngưỡng và tỷ lệ lỗi xác thực cao, Giám sát các đột biến bất thường trong tỷ lệ lỗi HTTP 4xx và 5xx từ ALB, Sử dụng CloudTrail để theo dõi các API call và thay đổi cấu hình liên quan đến secrets trong Secrets Manager và các thiết lập load balancer. Bằng cách triển khai các alarm tùy chỉnh này cùng với các cấu hình mặc định, các sự cố bảo mật tiềm ẩn và nỗ lực truy cập trái phép có thể được phát hiện nhanh chóng trên toàn bộ tài nguyên AWS của bạn. Phương pháp nhiều lớp này giúp duy trì khả năng giám sát quá trình xoay vòng secret và nhanh chóng xác định, phản ứng với các vấn đề tiềm ẩn.\nXem hướng dẫn chi tiết tại Creating CloudWatch alarms for CloudTrail events: examples.\nQuy trình triển khai\nTriển khai CloudFormation template bằng AWS Command Line Interface (AWS CLI) hoặc AWS Management Console. Thay \u0026lt;your-region\u0026gt; bằng AWS Region mà bạn muốn triển khai giải pháp.\naws cloudformation deploy \\ --template-file template.yaml \\ --stack-name oidc-credential-manager-stack \\ --capabilities CAPABILITY_IAM \\ --region Lưu ý: Bạn có thể thêm các tham số bổ sung nếu được yêu cầu bởi cấu hình IdP của bạn.\nKiểm thử và xác minh\nTuyên bố: Khuyến nghị thử nghiệm trong môi trường riêng biệt, không quan trọng để đảm bảo mọi cài đặt cụ thể của khách hàng được xác minh đầy đủ trước khi triển khai vào môi trường sản xuất.\nĐối với cập nhật secret, hãy xác minh rằng các CloudWatch alarms đã được cấu hình được kích hoạt. Đối với xác thực ALB, kiểm tra ALB access logs để tìm các entry authentication_success và sự hiện diện của OIDC identity tokens.\nThiết lập CloudWatch metrics và alarms để giám sát quá trình xoay vòng secret và tỷ lệ xác thực thành công. Xác minh các trường hợp thất bại bằng cách sửa thủ công cấu hình ALB rule trỏ tới một secret ARN khác và xác nhận rằng CloudWatch alarm được kích hoạt. Dưới đây là một ví dụ về sự kiện CloudTrail cho một cập nhật Secrets Manager thành công.\n{ \u0026#34;source\u0026#34;: [\u0026#34;aws.secretsmanager\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;AWS API Call via CloudTrail\u0026#34;], \u0026#34;detail\u0026#34;: { \u0026#34;eventSource\u0026#34;: [\u0026#34;secretsmanager.amazonaws.com\u0026#34;], \u0026#34;eventName\u0026#34;: [\u0026#34;UpdateSecret\u0026#34;], \u0026#34;responseElements\u0026#34;: {\u0026#34;status\u0026#34;: \u0026#34;Success\u0026#34;} } } Sau đây là một ví dụ về nhật ký truy cập ALB:\n/aws/alb/\u0026lt;your-alb-name\u0026gt;: - Look for entries containing: \u0026#34;authentication_success\u0026#34; \u0026#34;id_token_authentication_successful\u0026#34; \u0026#34;x-amzn-oidc-identity\u0026#34; HTTP status code 200 - Example log pattern: timestamp elb_name client:port target:port request_processing_time target_processing_time response_processing_time status_code \u0026#34;authentication_success\u0026#34; \u0026#34;x-amzn-oidc-identity: [token]\u0026#34; Kịch bản nâng cao\nTrong phần này, bạn sẽ học cách giảm thời gian chờ và làm cho cập nhật Secrets Manager gần như đồng bộ (synchronous).\nTối ưu hóa đồng bộ Secrets Manager: Sử dụng EventBridge partner tích hợp để cấu hình EventBridge gọi Lambda function dựa trên các sự kiện nhận được từ IdP bên thứ ba. Xem hướng dẫn chi tiết tại Receiving events from a SaaS partner with Amazon EventBridge . \\\nXoay vòng client ID: Trong khi xoay vòng client secret là kịch bản phổ biến nhất, đôi khi cũng cần xoay vòng client ID. Trong hầu hết các IdP, điều này có nghĩa là tạo một client ứng dụng mới và di chuyển các resource. Để thực hiện, Lambda Auth0CredentialHandler cần quyền sửa đổi ALB listener rules (elasticloadbalancing``:``ModifyRule``, ``elasticloadbalancing``:DescribeListeners, ``elasticloadbalancing``:DescribeRules). Xoay vòng client ID có thể gây gián đoạn xác thực tạm thời, vì vậy thử nghiệm kỹ lưỡng là cần thiết. Sử dụng AWS Config để giám sát cấu hình ALB rule nhằm phát hiện các thay đổi bất ngờ. Tính năng này tăng cường bảo mật tổng thể, mặc dù có thể tăng độ phức tạp của giải pháp và đôi khi cần can thiệp thủ công. \\\nChiến lược đa nhà cung cấp (multi-provider): Nếu tổ chức của bạn quản lý nhiều IdP, hãy triển khai framework xoay vòng tập trung để trừu tượng hóa các khác biệt riêng của nhà cung cấp, tập trung vào các nguyên tắc bảo mật cốt lõi được nêu trong bài viết này. Các cân nhắc chính bao gồm: tạo giao diện độc lập với nhà cung cấp để hỗ trợ giám sát toàn diện và giảm thiểu chi phí cấu hình.\nKết luận\nTrong bài viết này, bạn đã khám phá cách tiếp cận toàn diện để tự động xoay vòng OIDC client secret sử dụng các dịch vụ của AWS. Bằng cách triển khai giải pháp này, bạn có thể: Nâng cao bảo mật ứng dụng, Giảm thiểu chi phí quản lý thủ công, Duy trì chiến lược xác thực vững chắc. Hãy cân nhắc khám phá các kỹ thuật quản lý danh tính nâng cao hoặc tích hợp xác thực đa yếu tố (MFA) với triển khai OIDC của bạn. Nếu bạn mới làm quen với tự động xoay vòng secrets, tham khảo bài viết Back to Basics: Secrets Management.\nKani Murugan là một kỹ sư bảo mật đã được bổ nhiệm biên chế (tenured) tại Amazon Security, nơi cô chuyên về bảo mật sản phẩm, tập trung vào bảo mật ứng dụng, mạng và dữ liệu. Với hơn 8 năm kinh nghiệm trong nhiều lĩnh vực bảo mật khác nhau, Kani mang đến cho công việc của mình một nền tảng kiến thức phong phú. Ngoài công việc, Kani là người đam mê anime và là một độc giả “không kén chọn”, đọc nhiều chủ đề đa dạng. "},{"uri":"https://datngo196.github.io/Internship_Report/2-proposal/","title":"Proposal","tags":[],"description":"","content":"MAPVIBE - AI-Powered Map Location Discovery Platform (Discover dining and other locations in Ho Chi Minh City using natural-language prompts and contextual insights)\n1. Executive Summary We are a team of 5 Information Technology students working together to develop a project called MapVibe. MapVibe is an innovative web platform that helps users, especially GenZ, find dining locations using natural language based on their mood and genuine emotions. For example, instead of searching for \u0026ldquo;coffee shop\u0026rdquo;, users can ask \u0026ldquo;I\u0026rsquo;m feeling sad today, is there any drink place that can help me relieve my sadness?\u0026rdquo;.\nThe project\u0026rsquo;s goal is to improve traditional search methods and create a more personalized, deeper experience for users. We chose AWS as our cloud platform to leverage powerful, flexible, and cost-effective services. This allows the team to focus maximum resources on developing core features, minimizing infrastructure management burden, while keeping operating costs within the $200 budget from AWS Free Tier credits, which is very suitable for a student project.\nMapVibe\u0026rsquo;s core feature allows users to query using natural language to find locations that match their mood or specific needs. The system will analyze and return the most suitable suggestions, along with reviews and detailed information.\nTo achieve this goal, our team will be responsible for the entire process: from design, website development, building and configuring infrastructure on AWS (using services such as Bedrock, Lambda, RDS), to independently compiling the initial dataset of locations.\n2. Problem Statement What’s the Problem? Traditional map platforms like Google Maps rely on keyword-based searches and static filters, struggling to interpret nuanced, context-rich queries (e.g., “quiet coffee shop near the river with outdoor seating”). Users waste time navigating multiple apps to find suitable dining or activity locations. Existing solutions lack conversational interfaces and fail to incorporate contextual signals like time, mood, or group size. The Solution MapVibe employs AWS Bedrock (Titan embedding model, Claude LLM model) to parse natural-language prompts in Vietnamese and English, converting them into structured queries. It retrieves and ranks results from an internal RDS (PostgreSQL) database with geo-indexed place data and vector support features, offering a hybrid interface (conversational search + category filters). User-generated content (reviews, place suggestions) is moderated using AWS Rekognition, ensuring safety and quality through advanced AI-driven analysis.\nBenefits and ROI Speed: Reduces location discovery time from minutes to seconds. Personalization: Context-aware results based on user preferences and behavior, powered by AI. Automation: Eliminates manual filtering with AI-driven intent parsing. Scalability: Global AWS infrastructure ensures low latency and resilience. Cost Efficiency: Optimized to fit within a $200 credit from AWS Free Tier for the entire development and initial deployment cycle. Commercial Potential: Opportunities for partnerships with local businesses or integration with internal booking systems. 3. Solution Architecture Overview User Prompt + Context → Bedrock Titan Embedding Model → Structured Query → RDS (PostgreSQL) Search → Rank \u0026amp; Cache → Web UI Display → User Feedback Loop.\nAWS Services Used Service Function Amazon Route 53 Domain routing AWS Certificate Manager SSL/TLS certificates AWS WAF Web application firewall Amazon CloudFront Global CDN for static assets Amazon API Gateway Secure RESTful API endpoints AWS Lambda Intent parsing, search, and ranking logic Amazon RDS (PostgreSQL) Geo-indexed place data and query caching Amazon S3 Storage for photos, logs, and assets Amazon Cognito User authentication and authorization Amazon Bedrock Titan embedding model and Claude LLM model for intent parsing and summarization Amazon Rekognition AI-driven content moderation for user uploads Amazon Textract Extract text from images and documents (menus, signs, etc.) Amazon EventBridge Scheduled analytics and badge updates Amazon CloudWatch Monitoring and logging Component Design Frontend: Responsive web app (Next.js, bilingual VI/EN, hybrid search UI). Data Ingestion: Prompts and context processed via API Gateway; user uploads (reviews, photos) moderated by Rekognition’s AI. Data Storage: RDS (PostgreSQL) for place data with relational database design (ERD), vector support features, and indexing for optimized query speed; S3 for photos and logs. Data Processing: Lambda microservices handle Bedrock (Titan embedding model and Claude LLM model) calls, query execution, and result ranking. User Management: Cognito for JWT-based authentication (email/social login); guest users access limited features. Output: Displays place cards with AI-generated summaries, ratings, photos, and CTAs (e.g., Get Directions, Call). 4. Technical Implementation Implementation Phases Phase Description Duration 1 Define architecture, Bedrock Titan embedding schema, and RDS (PostgreSQL) schema with ERD design 2 weeks 2 Estimate costs and optimize caching strategy 1 week 3 Build backend (Lambda, RDS PostgreSQL, Bedrock Titan embedding, Rekognition) 3 weeks 4 Develop frontend (Next.js, bilingual, responsive UI) 3 weeks 5 Test and optimize for \u0026lt;10s latency and scalability 2 weeks 6 Launch MVP, deploy via CI/CD (Terraform, GitLab), collect feedback 2 weeks Technical Requirements Edge Devices: Modern browsers (Chrome, Safari, Firefox) with PWA-ready responsive UI. Cloud: AWS Route 53, ACM, WAF, CloudFront, API Gateway, Lambda, RDS (PostgreSQL with vector support), S3, Cognito, Bedrock (Titan embedding, Claude LLM), Rekognition, Textract, EventBridge, CloudWatch. Tools \u0026amp; Frameworks: Next.js (App Router), TypeScript, Terraform for infrastructure-as-code, GitLab for CI/CD. 5. Timeline \u0026amp; Milestones Period Activities Pre-Development (Month 0 - Sept 2025) Research Ho Chi Minh City venue datasets for RDS (PostgreSQL) Month 1 (Oct 2025) Build backend MVP with Bedrock Titan embedding model and RDS (PostgreSQL) Month 2 (Nov 2025) Implement caching, develop frontend integration Month 3 (Nov 2025) Launch public beta, optimize performance, collect feedback Post-Launch (Dec 2025) Add advanced features (e.g., ML-based ranking, offline mode) 6. Budget Estimation Resource Investment Time Estimation We estimate that each team member will contribute approximately 20 hours per week to the project. With each phase lasting 2 weeks, the total time investment is estimated as follows:\nProject Phase Total Estimated Hours Phase 1: Platform Setup 200 hours (5 people * 20 hours/week * 2 weeks) Phase 2: Core Feature Development 200 hours (5 people * 20 hours/week * 2 weeks) Phase 3: Completion and Deployment 200 hours (5 people * 20 hours/week * 2 weeks) Total Hours 600 hours Total Financial Cost $0 Resource Contribution Distribution The direct financial cost of the project is negligible and fully covered by credits. The main contribution comes from the team\u0026rsquo;s time and support from AWS.\nParticipant Contribution % Contribution (Total Value) Client (Internship Program) - Learning opportunities and practical experience. - Partner (Student Team) - Time and effort (estimated 600 hours). - AWS - $200 credit. - Services in Free Tier package. 100% (financial cost) Cost Optimization Measures Free-Tier Utilization: Leverage AWS free tiers for Lambda, RDS, S3, CloudFront, Rekognition, and Cognito to minimize costs. Aggressive Caching for Bedrock: Achieve a high cache hit rate to reduce AI token costs. Batch Rekognition Processing: Non-real-time image checks to save costs. Optimized RDS Usage: Use PostgreSQL with proper indexing to minimize query costs. Static Asset Caching: Minimize outbound data transfer costs through CloudFront. Budget Control The entire project operates within the $200 credit from AWS Free Tier. All infrastructure costs are covered by AWS credits and free tier services. No direct financial costs are incurred by the team. 7. Risk Assessment Risk Impact Probability Mitigation RDS data inconsistency High Medium Regular data validation and backups Inaccurate Titan embedding parsing (VN/EN) Medium Low Predefined prompt templates, validation Scalability under high load Medium Medium Serverless auto-scaling, caching Privacy concerns (location data) High Low Explicit user consent, anonymized queries Budget overrun High Medium Strict monitoring, use of free tiers, cost alerts AWS Bedrock service dependency (Titan, Claude) High Low Alternative fallback mechanisms, cached results GitLab platform dependency Medium Low Regular backups, alternative repository options Initial data quality Medium Medium Data validation processes, user feedback integration Contingency Plans: Use cached RDS results or local JSON fallback for demos. Implement IP-based rate limits for unauthenticated users. Monitor AWS costs weekly to prevent budget overruns.\n8. Expected Outcomes Project Success Criteria To ensure the MapVibe project succeeds, we have set specific, measurable success criteria:\nComplete Infrastructure Deployment: Successfully and securely deploy the entire system architecture to AWS, including all planned services such as VPC, Subnet, RDS, Lambda, S3, CloudFront, API Gateway, and Cognito. Core Search Feature Works Effectively: The natural language search feature using AWS Bedrock (Titan embedding model, Claude LLM model) and RDS PostgreSQL must be able to understand and return relevant, meaningful results for at least 90% of common user queries. Cost Optimization: Total AWS service usage costs throughout development and initial deployment do not exceed the $200 credit from AWS Free Tier package. Product Launch (MVP): Complete and launch a minimum viable product (MVP) version of the MapVibe website for the target user group (GenZ) on both desktop and iOS, Android platforms. Additionally, include an administrator dashboard for managing content and users. Collect Positive Feedback: After launch, collect at least 50 new location suggestions from users in the first month, demonstrating community interaction and engagement. Technical Improvements Mood-Based Conversational Search: Natural-language support for Vietnamese and English with \u0026lt;10s latency, powered by Bedrock (Titan embedding model and Claude LLM model), understanding user emotions and moods. AI Summaries: Bedrock-generated place overviews, refreshed every 7 days or after 10 new reviews. Scalability: Serverless architecture with global CDN delivery via CloudFront. Moderation: Rekognition\u0026rsquo;s AI ensures safe user-generated content (reviews, photos). Relational Database: PostgreSQL with optimized indexing for fast query performance. Long-Term Value Personalization: ML-based re-ranking and user behavior analysis based on mood and preferences. Offline Support: PWA for offline shortlisting of venues. Extensibility: Potential integration with internal booking systems. Contextual Expansion: Recommendations based on weather, events, social trends, and user emotions. Attachments / References AWS Pricing Calculator GitLab Repository 9. IMPORTANT: Our Proposal Docs Version Proposal Docs Version Related Documents "},{"uri":"https://datngo196.github.io/Internship_Report/4-eventparticipated/4.2-event2/","title":"AI-Driven Development Workshop","tags":[],"description":"","content":"Summary Report: “AI-Driven Development Workshop” Event Objectives Understand the overview of the AI-Driven Software Development Life Cycle (SDLC) Access and view a real-world demo of Amazon Q Developer Deep dive into the Kiro tool and its application in the development process Update on the latest developer support tools to increase productivity Speakers Toan Huynh – Speaker on AI-Driven SDLC \u0026amp; Amazon Q My Nguyen – Speaker on Kiro Demonstration Key Highlights AI-Driven Development Life Cycle (SDLC) Shift in Paradigm: Shifting from traditional development processes to processes with integrated AI support at every stage. Automation: Automating repetitive tasks in the development lifecycle, from coding to testing and deploying. Efficiency: Optimizing time and resources thanks to intelligent AI assistants. Amazon Q Developer Demonstration Coding Assistant: Demo of code suggestions, code logic explanation, and automatic unit test generation. Troubleshooting: Using Amazon Q to debug and find solutions for technical errors in real-time. Integration: How to integrate Amazon Q into the development environment (IDE) and daily workflows. Kiro Demonstration Tool Capabilities: Introduction to the core features of Kiro (related to Kiro IDE/Agent). Practical Use Cases: Live demo on how to use Kiro to solve specific programming problems. Developer Experience: Improving the developer experience through Kiro\u0026rsquo;s interface and intelligent features. Key Takeaways Tooling Landscape Amazon Q Developer is not just a chat tool but a comprehensive assistant for the SDLC. Kiro brings new approaches to supporting the development environment (IDE/Agent). Productivity Focus Applying AI-Driven SDLC helps minimize manual tasks, allowing developers to focus on complex business logic. It is necessary to proactively get used to these tools to avoid falling behind in new technology trends. Applying to Work Integrate Amazon Q: Install and pilot Amazon Q Developer in current projects to support code reviews and test writing. Explore Kiro: Dedicate time to research Kiro more deeply after the demo to consider its applicability to the team\u0026rsquo;s workflow. Review SDLC Process: Re-evaluate the team\u0026rsquo;s current development process and identify bottlenecks that can be solved with AI. Event Experience The afternoon workshop focused deeply on technical demos, providing an intuitive view of the power of modern programming support tools.\nHands-on Insight Toan Huynh\u0026rsquo;s presentation helped me clearly visualize what an \u0026ldquo;AI-ized\u0026rdquo; SDLC process looks like. My Nguyen\u0026rsquo;s demo on Kiro was very practical, showing the potential of emerging tools alongside giants like AWS. Impact on Workflow It became clear that AI is changing the way we write software: faster, more accurate, and with fewer errors. The event was concise but substantial, going straight into the combat tools that developers care about. Some event photos Add your event photos here\nOverall, the afternoon session was the perfect complement in terms of Tools to the Architecture knowledge gained earlier, completing the picture of modern software development.\n"},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Delve into critical networking services on the AWS platform. Set up and configure a secure Virtual Private Cloud (VPC) environment, including the creation of Public and Private Subnets distributed across multiple Availability Zones (AZs) to ensure a high-availability architecture. Master the Internet connectivity mechanism for resources within the VPC, differentiating the roles of the Internet Gateway (IGW) and the NAT Gateway. Understand and implement AWS network security layers: Network Access Control Lists (NACLs) at the Subnet level and Security Groups (SGs) at the Elastic Network Interface (ENI) level. Research large-scale networking solutions between multiple VPCs, specifically VPC Peering and Transit Gateway. Familiarize with the types of Elastic Load Balancers (ELB), focusing on Layer 7 routing capabilities (ALB) and Layer 4 extreme performance (NLB). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Set up Basic VPC Architecture (Multi-AZ): Create a VPC with a specified CIDR range. Create at least 4 Subnets (Public/Private across 2 different AZs) to ensure a high-availability architecture. Understand the rule of 5 IP addresses reserved by AWS in each Subnet.\n09/08/2025 09/08/2025 3 - Configure Internet Gateway (IGW): Create and attach an IGW to the VPC. Create a Custom Route Table for Public Subnets. Route Internet traffic (0.0.0.0/0) via the IGW. Associate this Route Table with the Public Subnets. 09/09/2025 09/09/2025 4 - Deploy NAT Gateway: Differentiate NAT Gateway and NAT Instance. Allocate an Elastic IP. Deploy the NAT Gateway in a Public Subnet. Configure the Route Table for Private Subnets, routing Internet traffic (0.0.0.0/0) through the NAT Gateway, allowing outbound access only. 09/10/2025 09/10/2025 5 - Configure Security and Deploy EC2: Study and differentiate Security Groups (stateful, ENI level, ALLOW only) and NACLs (stateless, Subnet level, ALLOW/DENY). Create Security Groups for public and private hosts. Deploy EC2 in Public and Private Subnets. Test connectivity between Subnets and to the Internet (using a Bastion Host/Jump Host concept to SSH into Private EC2). 09/11/2025 09/11/2025 6 - Connectivity and ELB: Learn about VPC Peering (1:1 connection, no transitive routing support) and Transit Gateway (Central Hub for connecting a large number of VPCs). Explore Elastic Load Balancing (ELB), focusing on ALB (Layer 7, path-based routing) and NLB (Layer 4, extreme performance, static IP support). 09/12/2025 09/12/2025 Week 2 Achievements: Established a Complete VPC: Successfully created a VPC and divided Subnets into Public/Private tiers across multiple Availability Zones (AZs), ensuring a high-availability architecture. Mastered Internet Outbound/Inbound Mechanism: Configured IGW to allow Public Internet access for Public Subnets. Secured Internet Access for Private Subnets: Deployed a NAT Gateway (placed in a Public Subnet) and configured the corresponding Route Table, allowing instances in the Private Subnet to access the Internet outbound only. Applied Network Layer Security: Differentiated and configured Security Groups (Stateful, applied at ENI) and NACLs (Stateless, applied at Subnet). Successfully deployed EC2 Instances in both Public and Private Subnets and verified internal and external connectivity using jump hosts (Bastion Host) Researched Large-Scale Connectivity: Understood the functional difference between VPC Peering (1:1) and the scalable Transit Gateway (Hub-and-spoke). Familiarized with Elastic Load Balancer types (ALB for Layer 7 routing, NLB for Layer 4 extreme performance) and core features "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Application Details","tags":[],"description":"","content":"Frontend Applications Web Application (apps/web) The main user-facing application built with:\nReact 19 - Latest React with concurrent features Vite - Fast build tool and dev server TailwindCSS - Utility-first CSS framework React Router - Client-side routing TanStack Query - Data fetching and caching TipTap - Rich text editor for reviews Key Features:\nNatural language search using AI Place discovery and recommendations User reviews and ratings Photo uploads User profiles and saved places Responsive design for mobile and desktop Development:\ncd apps/web bun run dev Build:\nbun run build Admin Dashboard (apps/admin) Admin interface for content management:\nReact 19 with Vite TailwindCSS for styling Admin-specific components and pages Key Features:\nContent moderation User management Analytics dashboard Place approval workflow Review management Development:\ncd apps/admin bun run dev Backend API (apps/api) Main API Lambda function handling:\nREST API endpoints Authentication with Cognito Database operations with Kysely S3 operations for photos Integration with AWS Bedrock SQS queue processing Key Handlers:\nPlaces (CRUD, search, nearby) Reviews (create, vote, comment) Users (profile, photos, stats) Photos (upload, delete) Activities (tracking) Development:\ncd apps/api bun run dev Build:\nbun run build Lambda Functions Specialized Lambda functions in infrastructure:\nlambda-embeddings - Generates embeddings for places using Bedrock lambda-rag - Retrieval Augmented Generation for AI search lambda-ocr-menu - Extracts text from menu images using Textract lambda-rekognition - Content moderation using Rekognition lambda-review-aggregate - Aggregates review statistics lambda-s3-trigger - Processes S3 upload events lambda-migration - Database migration runner Shared Packages types - TypeScript definitions shared across apps ui-components - Reusable React components database - Kysely-based database layer utils - Common utility functions constants - Application constants "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Deploy Infrastructure","tags":[],"description":"","content":"Deploy with Terraform Deploy the infrastructure:\ncd infrastructure/terraform terraform apply This will create all AWS resources. The process may take 15-30 minutes.\nWhat Gets Created The Terraform configuration creates:\nVPC Module\nVPC with public subnets Internet Gateway Route tables Security groups RDS Module\nPostgreSQL database instance (db.t3.micro) Database credentials stored in Secrets Manager Public accessibility (for MVP) Secrets Manager\nDatabase credentials secret Auto-generated secure password Cognito Module\nUser Pool for authentication User Pool Client Custom domain (login.mapvibe.site) Optional Google OAuth integration Lambda Functions\nAPI Lambda (main REST API) Embeddings Lambda (Bedrock integration) RAG Lambda (AI search) OCR Menu Lambda (Textract) Rekognition Lambda (content moderation) Review Aggregate Lambda S3 Trigger Lambda Migration Lambda API Gateway\nREST API with custom domain Lambda integrations Cognito authorizers CORS configuration S3 \u0026amp; CloudFront\nS3 bucket for static assets S3 bucket for photos CloudFront distribution WAF integration Custom domain (mapvibe.site) Route53 \u0026amp; ACM\nHosted zone for domain SSL certificates DNS records WAF\nWeb ACL for CloudFront Security rules Monitor Deployment Watch the Terraform output for progress. You\u0026rsquo;ll see:\nResources being created Any errors or warnings Output values (URLs, ARNs, etc.) Save Outputs After deployment, save the outputs:\nterraform output \u0026gt; outputs.txt Important outputs include:\nAPI Gateway URL CloudFront URLs Cognito User Pool ID RDS endpoint Database secret ARN "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.2-prerequiste/","title":"Prerequisites","tags":[],"description":"","content":"Required Software Before starting this workshop, ensure you have the following installed:\nBun (\u0026gt;= 1.3.2)\nDownload from: https://bun.sh Verify installation: bun --version Node.js (\u0026gt;= 24.11.1)\nRequired for some tooling Download from: https://nodejs.org Terraform (\u0026gt;= 1.0)\nRequired for infrastructure deployment Download from: https://www.terraform.io/downloads Verify installation: terraform --version AWS CLI (\u0026gt;= 2.0)\nRequired for AWS operations Download from: https://aws.amazon.com/cli/ Configure with: aws configure Git\nFor cloning the repository Download from: https://git-scm.com/ AWS Account Requirements AWS Account with appropriate permissions\nYou need an AWS account with permissions to create and manage: VPC, Subnets, Security Groups RDS (PostgreSQL) Lambda functions API Gateway CloudFront distributions S3 buckets Cognito User Pools Route53 hosted zones ACM certificates WAF web ACLs Secrets Manager IAM roles and policies AWS Region\nThis workshop uses ap-southeast-1 (Singapore) by default WAF requires us-east-1 (N. Virginia) for CloudFront AWS Credentials\nConfigure AWS CLI with your credentials: aws configure Or set environment variables: export AWS_ACCESS_KEY_ID=your_access_key export AWS_SECRET_ACCESS_KEY=your_secret_key export AWS_DEFAULT_REGION=ap-southeast-1 Environment Variables You will need to create .env files for the project:\nRoot .env file - For infrastructure variables apps/web/.env - For frontend configuration apps/admin/.env - For admin dashboard configuration Contact the project maintainer for the required environment variables.\nOptional: Google OAuth (for Cognito) If you want to enable Google OAuth login:\nCreate a Google OAuth 2.0 client ID and secret Add them to your Terraform variables Verify Prerequisites Run the following commands to verify your setup:\n# Check Bun bun --version # Check Node.js node --version # Check Terraform terraform --version # Check AWS CLI aws --version # Check AWS credentials aws sts get-caller-identity If all commands succeed, you\u0026rsquo;re ready to proceed!\n"},{"uri":"https://datngo196.github.io/Internship_Report/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Sử dụng Raspberry Pi 5 như các nút lai (Hybrid Nodes) của Amazon EKS cho các khối tải (workload) tại biên (edge) *Bởi Alberto Crescini, Gladwin Neo, và Utkarsh Pundir, đăng ngày 17 tháng 9 năm 2025, thuộc các chuyên mục:Amazon Elastic Kubernetes Service **, Manufacturing *, Technical How-to.\nKể từ khi ra mắt, Amazon Elastic Kubernetes Service (Amazon EKS) đã vận hành hàng chục triệu cụm (cluster), giúp người dùng tăng tốc triển khai ứng dụng, tối ưu chi phí, và tận dụng tính linh hoạt của Amazon Web Services (AWS) trong việc lưu trữ và vận hành các ứng dụng container hóa. Amazon EKS loại bỏ những phức tạp trong việc duy trì hạ tầng control plane của Kubernetes, đồng thời tích hợp liền mạch với các tài nguyên và hạ tầng AWS.\nTuy nhiên, một số khối tải (workload) cần được chạy tại biên (edge) để xử lý theo thời gian thực, chẳng hạn như các ứng dụng nhạy cảm với độ trễ (latency-sensitive) hoặc tạo ra lượng dữ liệu khổng lồ cần xử lý nhanh tại chỗ.\nTrong những tình huống như vậy, khi có kết nối Internet ổn định, người dùng thường muốn duy trì lợi ích của việc tích hợp đám mây, đồng thời vẫn sử dụng phần cứng tại chỗ (on-premises). Chính vì thế, tại AWS re:Invent 2024, chúng tôi đã giới thiệu Amazon EKS Hybrid Nodes — một giải pháp cho phép người dùng mở rộng mặt dữ liệu (data plane) của Kubernetes ra biên, trong khi giữ control plane chạy trong AWS Region. Amazon EKS Hybrid Nodes giúp thống nhất việc quản lý Kubernetes trên môi trường đám mây, tại chỗ và tại biên, bằng cách cho phép người dùng sử dụng hạ tầng tại chỗ như các node trong cụm EKS, bên cạnh Amazon Elastic Compute Cloud (Amazon EC2).\nĐể minh họa cách sử dụng Amazon EKS Hybrid Nodes, chúng tôi trình bày một kịch bản thực tế trong lĩnh vực sản xuất (manufacturing) — nơi các hệ thống thường phụ thuộc vào dữ liệu thời gian thực từ các cảm biến số (digital sensors), cần được xử lý cục bộ do yêu cầu về độ trễ và độ tin cậy, trong khi vẫn tận dụng đám mây để phân tích và lưu trữ dài hạn.\nTrong ví dụ này, hệ thống đọc các giá trị khoảng cách từ cảm biến siêu âm (ultrasonic sensor), xử lý dữ liệu trực tiếp trên thiết bị biên (edge device) đang hoạt động như một Hybrid Node, và sau đó lưu trữ dữ liệu vào Amazon DynamoDB trên AWS.\nTrong bài viết này, chúng tôi sẽ hướng dẫn cách triển khai Amazon EKS Hybrid Nodes sử dụng Raspberry Pi 5, một nền tảng phổ biến cho tính toán biên (edge computing). Bài viết bao gồm:\nThiết lập cụm EKS kết nối liền mạch giữa hạ tầng đám mây và hạ tầng biên\nBảo mật kết nối bằng WireGuard VPN để thiết lập truyền thông site-to-site\nKích hoạt mạng container bằng Cilium cho các triển khai sử dụng Hybrid Nodes\nTrình bày một ứng dụng Internet of Things (IoT) thực tế nhằm minh họa sức mạnh của sự tích hợp giữa điện toán biên và điện toán đám mây (edge–cloud integration)\nVì sao chọn Raspberry Pi 5? Raspberry Pi 5 có thiết kế nhỏ gọn và có thể triển khai tại biên (edge), cho phép xử lý dữ liệu trước khi truyền lên đám mây. Tận dụng ưu điểm này, chúng tôi xây dựng một ứng dụng kiến trúc microservices, trong đó một phần chạy tại biên trên Raspberry Pi 5 và một phần chạy trên AWS trong môi trường đám mây. Ở phía biên, Raspberry Pi cục bộ được kết nối với cảm biến siêu âm (ultrasonic sensor) để thu nhận dữ liệu khoảng cách theo thời gian thực. Dữ liệu này sau đó được xử lý và tải lên cơ sở dữ liệu DynamoDB trên AWS. Tiếp theo, dữ liệu được hiển thị thông qua một bảng điều khiển (dashboard) chạy như một triển khai độc lập trong cụm (cluster deployment). Với cách triển khai này, bạn có thể tiền xử lý dữ liệu tại chỗ, từ đó giảm lượng dữ liệu cần truyền lên AWS, giúp tối ưu băng thông và chi phí, đồng thời tăng hiệu quả xử lý cục bộ cho các ứng dụng biên.\nTổng quan kiến trúc Trong môi trường đám mây, chúng tôi triển khai một Amazon Virtual Private Cloud (Amazon VPC) chứa cụm Amazon EKS. Bên trong VPC này, một phiên bản Amazon EC2 đóng vai trò cổng kết nối (gateway) giữa môi trường đám mây và mạng biên (edge network) tại cơ sở. Phiên bản EC2 này thiết lập một đường hầm VPN bảo mật site-to-site sử dụng WireGuard, kết nối với Raspberry Pi 5, thiết bị đóng vai trò là Hybrid Node của chúng tôi. Khi đường hầm VPN được thiết lập, lưu lượng dữ liệu giữa Raspberry Pi và đám mây sẽ được định tuyến thông qua máy chủ WireGuard đang chạy trên Amazon EC2, giúp mở rộng cụm EKS ra đến vùng biên. Từ góc nhìn của cụm EKS, Raspberry Pi hoạt động giống như bất kỳ node nào khác, mặc dù nó nằm ngoài phạm vi của VPC. Kiến trúc tổng thể được thể hiện trong hình minh họa bên dưới.\nMặt điều khiển Kubernetes (control plane) được quản lý hoàn toàn bởi AWS, bao gồm API server, etcd datastore, scheduler và controller manager. Trong phần hướng dẫn này, chúng tôi cấu hình control plane của Kubernetes với điểm truy cập công khai (public endpoint), cho phép các node Raspberry Pi có thể giao tiếp với control plane thông qua Internet. AWS đảm nhận toàn bộ sự phức tạp trong việc bảo mật và mở rộng control plane của Kubernetes để đảm bảo tính sẵn sàng cao (high availability), giúp bạn có thể tập trung vào phát triển và triển khai ứng dụng của mình.\nChúng tôi sử dụng một phiên bản EC2 chuyên dụng chạy WireGuard, đóng vai trò cổng VPN (VPN gateway), tạo đường hầm bảo mật giữa AWS và hạ tầng biên (edge infrastructure). Máy chủ này hoạt động như trung tâm (hub) trong mô hình hub-and-spoke, cho phép trao đổi dữ liệu giữa control plane của Amazon EKS và các node Raspberry Pi, phục vụ cho các thao tác như kubectl exec, truy xuất log, và xử lý webhook.\nCác thiết bị Raspberry Pi chạy các thành phần node tiêu chuẩn của Kubernetes gồm kubelet, kube-proxy, và container runtime, cùng với công cụ dòng lệnh Amazon EKS Hybrid Nodes CLI (nodeadm). Các node này đăng ký với cụm EKS thông qua AWS Systems Manager, và hiển thị trong cụm như những worker node tiêu chuẩn, mặc dù được vận hành trên phần cứng do người dùng tự quản lý.\nCác node Raspberry Pi chủ động thiết lập kết nối với control plane của Amazon EKS thông qua Internet công cộng. Quá trình này bao gồm giao tiếp với API server để đăng ký node, cập nhật trạng thái pod, và gửi yêu cầu tài nguyên (resource requests). Phương thức public endpoint này giúp đơn giản hóa việc kết nối, đồng thời vẫn duy trì mức độ bảo mật cao nhờ xác thực qua AWS Identity and Access Management (IAM) và mã hóa TLS.\nBắt đầu thiết lập Để kết nối mạng giữa thiết bị Raspberry Pi và cụm EKS đang chạy trên đám mây, trước tiên chúng ta cấu hình một máy chủ WireGuard nhẹ trên một phiên bản EC2. Máy chủ này chỉ hoạt động như một cổng mạng (network gateway), vì vậy phiên bản EC2 t4g.nano tiết kiệm chi phí là đủ cho hầu hết các trường hợp sử dụng.\nSau khi máy chủ WireGuard được khởi động, chúng ta cài đặt client WireGuard trên Raspberry Pi để thiết lập kết nối liên tục (persistent connection), đồng thời cấu hình định tuyến phù hợp (routing) để cho phép trao đổi lưu lượng giữa Raspberry Pi và VPC mà cụm EKS đang sử dụng.\nTiếp theo, chúng ta thêm node lai (hybrid node) vào cụm EKS, cấu hình CNI (Container Network Interface), và cuối cùng cài đặt ứng dụng để hoàn thiện quá trình triển khai.\nYêu cầu:\nRaspberry Pi 5, chạy Ubuntu 24.10, bật SSH\nKết nối Ethernet có dây (khuyến nghị để đảm bảo ổn định)\nAWS Command Line Interface (AWS CLI)\nkubectl\nHelm\nBước 1: Tạo cụm EKS Bắt đầu bằng việc tạo một Amazon VPC trong Region AWS mà bạn chọn, với ít nhất một subnet công khai và một subnet riêng tư. Các subnet này sẽ chứa các worker node trên đám mây và các giao diện mạng cần thiết để giao tiếp với control plane. Khi thiết lập cụm EKS, hãy đảm bảo rằng các tham số mạng từ xa (remote networking parameters) được cấu hình để control plane có thể kết nối với các hybrid node và pod nằm ngoài VPC.\nĐể đơn giản hóa quá trình này, AWS cung cấp bộ Template Terraform trên AWS Samples GitHub repository. Các template này tự động hóa nhiều phần cấu hình mạng và Amazon EKS, chẳng hạn như kích hoạt hybrid networking và chuẩn bị các chính sách IAM và CNI cần thiết.\nNếu bạn mới làm quen với Amazon EKS Hybrid Nodes hoặc muốn tìm hiểu sâu hơn về quá trình cấu hình, hãy tham khảo tài liệu chính thức của AWS về việc kích hoạt cụm EKS cho Hybrid Nodes.\nBước 2: Thiết lập máy chủ VPN Amazon EKS Hybrid Nodes cần kết nối ổn định và mạng riêng giữa môi trường tại chỗ/biên và VPC của bạn. Điều này đòi hỏi thiết lập VPN hoặc giải pháp mạng riêng bảo mật tương tự. Có nhiều tùy chọn được AWS tài liệu hóa, chẳng hạn nhưAWS Site-to-Site VPN, AWS Direct Connect, hoặc kết nối VPN tự triển khai. Ở đây, chúng tôi sử dụng WireGuard, một phần mềm mã nguồn mở cho kết nối VPN nhanh và bảo mật.\n2.1 Cài đặt WireGuard Chúng tôi cài đặt WireGuard bằng cách triển khai máy chủ trên một EC2 instance trong tài khoản AWS của mình. Bạn có thể tham khảo bất kỳ hướng dẫn cài đặt WireGuard chuẩn nào để cấu hình máy chủ trên EC2, đảm bảo mở cổng UDP/51820 từ IP cục bộ tới security group của EC2. Bắt đầu bằng cách cài đặt WireGuard thông qua APT.\nsudo apt update \u0026amp;\u0026amp; sudo apt install -y wireguard sudo mkdir -p /etc/wireguard 2.2 Tạo cấu hình WireGuard\nTiếp theo, sử dụng trình soạn thảo mà bạn ưa thích để thêm cấu hình sau, thay thế các giá trị giữ chỗ (placeholders) bằng Public Key và Private Key của máy chủ WireGuard của bạn.\nsudo nano /etc/wireguard/wg0.conf Thêm cấu hình sau (thay thế các giá trị giữ chỗ):\n[Interface] PrivateKey = \u0026lt;client-private.key\u0026gt; Address = 10.200.0.2/24 [Peer] # Public key from AWS server (/etc/wireguard/public.key) PublicKey = \u0026lt;public.key\u0026gt; # Your EC2 instance\u0026#39;s public IP Endpoint = \u0026lt;ec2-public-ip\u0026gt;:51820 # WireGuard server network, AWS VPC CIDR \u0026amp; EKS Service CIDR AllowedIPs = 10.200.0.1/24,10.0.0.0/24,172.16.0.0/16 PersistentKeepalive = 25 Sau đó, kích hoạt dịch vụ WireGuard và xác minh rằng kết nối đã được thiết lập với máy chủ Amazon EC2.\nsudo systemctl enable wg-quick@wg0 sudo systemctl start wg-quick@wg0 sudo wg show Bạn sẽ thấy kết quả tương tự như sau:\ninterface: wg0 public key: zH6sK7s93lF4ZkPoe8L7TtyOe0e0zFqUYrqUJo1hXVA= private key: (hidden) listening port: 51820 peer: 8N3e1FzEJmGaJ8t6C2Zh1n3oA2uNfz8MZp4nCzHn3XA= endpoint: 52.14.123.45:51820 allowed ips: 10.0.0.0/16 latest handshake: 23 seconds ago transfer: 1.47 MiB received, 1.21 MiB sent persistent keepalive: every 25 seconds Như bước đầu tiên cho việc cấu hình mạng, cần bật IPv4 forwarding trên instance để nó có thể định tuyến các gói dữ liệu giữa các giao diện mạng:\necho \u0026#34;net.ipv4.ip_forward = 1\u0026#34; | sudo tee -a /etc/sysctl.conf sudo sysctl -p Tiếp theo, để cho phép EC2 instance chuyển tiếp lưu lượng giữa mạng WireGuard và VPC của bạn, hãy cấu hình iptables để thực hiện Network Address Translation (NAT) và cho phép chuyển tiếp gói dữ liệu (packet forwarding).\n# Enable masquerading for outgoing traffic via Wireguard interface iptables -t nat -A POSTROUTING -o wg0 -j MASQUERADE # Allow packets from VPC interface to be forwarded to Wireguard iptables -A FORWARD -i eth0 -o wg0 -j ACCEPT # Allow return traffic from Wireguard back into VPC for established connections iptables -A FORWARD -i wg0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT Lệnh đầu tiên báo cho kernel ghi lại địa chỉ IP nguồn (source IP) của các gói dữ liệu đi qua giao diện WireGuard (wg0) thành địa chỉ IP của EC2 instance, điều này cần thiết để định tuyến lưu lượng trả về. Quy tắc thứ hai cho phép các gói từ giao diện VPC (eth0) được chuyển tiếp tới WireGuard. Quy tắc thứ ba cho phép lưu lượng trả về từ WireGuard quay lại VPC, nhưng chỉ áp dụng cho các kết nối đã được thiết lập trước đó.\nTiếp theo, để đảm bảo các quy tắc này được giữ nguyên sau khi khởi động lại (persist across reboots), hãy cài đặt và cấu hình gói iptables-persistent:\nsudo apt update sudo apt install iptables-persistent sudo netfilter-persistent save sudo systemctl enable netfilter-persistent Điều này lưu các quy tắc hiện tại vào/etc/iptables/rules.v4** và **/etc/iptables/rules.v6 và đảm bảo chúng được áp dụng tự động sau mỗi lần khởi động lại.\nỞ bước cuối cùng, hãy tắt tính năng kiểm tra source/destination (source/destination check) trên giao diện của instance. Theo mặc định, AWS bật kiểm tra source/destination để đảm bảo một instance chỉ xử lý lưu lượng được gửi đến hoặc đi từ chính nó. Tuy nhiên, vì instance của chúng ta đóng vai trò là gateway, định tuyến gói dữ liệu thay cho các thiết bị khác trong mạng, nên cần tắt giới hạn này.\nThêm Raspberry Pi vào cụm như một node từ xa** **Khi mạng đã được cấu hình và cụm EKS đã được tạo, bước tiếp theo là thêm node vào cụm để Kubernetes có thể bắt đầu lập lịch (scheduling) pod trên node này.\nTrước tiên, đảm bảo node có thể xác thực với cụm. Amazon EKS Hybrid Nodes xác thực với cụm EKS thông qua IAM, do đó cần gán IAM role cho các máy tại chỗ (on-premises). Điều này yêu cầu thiết lập cơ chế xác thực bằng Systems Manager hoặc IAM Roles Anywhere. Hướng dẫn trên GitHub sử dụng Systems Manager Hybrid Activations cho mục đích này. Bạn có thể theo hướng dẫn để tạo AmazonEKSHybridNodesRole bằng một trong hai tùy chọn. Sau đó, đăng ký node bằng nodeadm. Hãy theo dõi các hướng dẫn trong chỉ dẫn và chắc chắn chỉ định role mà bạn đã tạo ở bước trước.\nThiết lập Container Network Interface (CNI)\nSau khi cụm EKS và các hybrid node được tạo và cấu hình thành công, node của chúng ta vẫn hiển thị trạng thái Not Ready. Nguyên nhân là Container Network Interface (CNI) chưa được cài đặt. CNI là thành phần quan trọng chịu trách nhiệm thiết lập các giao diện mạng bên trong container, cấp phát địa chỉ IP, và cấu hình định tuyến để pod có thể giao tiếp liền mạch trong cụm và với mạng bên ngoài. Nếu không có CNI, các node Kubernetes không thể cung cấp kết nối mạng cần thiết cho pod, từ đó ngăn cản triển khai workload. Vì vậy, cần cài đặt CNI trước khi hybrid node sẵn sàng. Cilium là giải pháp mã nguồn mở, cloud-native để cung cấp, bảo mật và quan sát kết nối mạng giữa các workload, và được hỗ trợ chính thức cho Amazon EKS Hybrid Nodes\nBước 1: Cài đặt Cilium\nSau khi cài đặt Helm, chúng ta thêm Cilium Helm chart và cài đặt Cilium vào cụm EKS.\nTạo file cilium-values.yaml:\naffinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: eks.amazonaws.com/compute-type operator: In values: - hybrid ipam: mode: cluster-pool operator: clusterPoolIPv4MaskSize: 25 clusterPoolIPv4PodCIDRList: - 172.16.0.0/24 operator: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: eks.amazonaws.com/compute-type operator: In values: - hybrid unmanagedPodWatcher: restart: false envoy: enabled: false Sau đó chúng ta có thể cài đặt Cilium bằng Helm:\n[ec2-user@ip-10-0-6-175 terraform]$ helm repo add cilium https://helm.cilium.io/ \u0026gt; helm install cilium cilium/cilium \\ \u0026gt; --version 1.16.6 \\ \u0026gt; --namespace kube-system \\ \u0026gt; --values cilium-values.yaml NAME: cilium LAST DEPLOYED: Mon Apr 28 03:50:01 2025 NAMESPACE: kube-system STATUS: deployed REVISION: 1 TEST SUITE: None Bạn đã cài đặt Cilium thành công, bây giờ hãy đợi cho đến khi cả hai pod đều sẵn sàng:\n[ec2-user@ip-10-0-6-175 terraform]$ kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system cilium-gzvhm 1/1 Running 0 4m50s kube-system cilium-operator-9c54b46b8-whgn9 1/1 Running 0 4m50s kube-system coredns-6d87fdb75-95wn2 1/1 Running 0 35s kube-system coredns-6d87fdb75-b2xf5 1/1 Running 0 35s kube-system kube-proxy-w48jx 1/1 Running 0 9m31s Bước 2: Xác minh các nút lai đang chạy\nChúng ta có thể kiểm tra xem tất cả các nút trong cụm EKS của mình có đang chạy thành công hay không. Chúng ta có thể kiểm tra trạng thái nút:\nkubectl get nodes Nút này hiện được đánh dấu là Sẵn sàng.\n[ec2-user@ip-10-0-6-175 terraform]$ kubectl get nodes NAME STATUS ROLES AGE VERSION ip-10-0-6-175.ec2.internal Ready \u0026lt;none\u0026gt; 9m31s v1.30.9-eks-5d632ec Khi cụm của chúng ta hoạt động và mạng lưới container hoạt động như mong đợi, chúng ta sẽ thấy nút ở trạng thái Sẵn sàng trên Bảng thông tin tổng quan về nút Amazon EKS, như minh họa trong hình sau.\nTriển khai ứng dụng mẫu trên Amazon EKS Hybrid Nodes với tích hợp edge\nỨng dụng bao gồm hai deployment Kubernetes:\nUltrasonic: Đọc các giá trị đo từ cảm biến siêu âm và ghi vào DynamoDB. \\\nDashboard: Đọc dữ liệu từ DynamoDB và hiển thị trên giao diện tương tác (UI).\nChúng tôi sử dụng cảm biến siêu âm HC-SR04, thiết bị phát sóng âm và đo thời gian hồi âm để tính khoảng cách. Loại cảm biến này phổ biến trong các ngành sản xuất và ô tô, ví dụ:\nPhát hiện sự hiện diện hoặc vắng mặt của vật thể trên dây chuyền lắp ráp\nĐo mực chất lỏng trong các thùng chứa\nGiám sát tình trạng chỗ đỗ xe\nTrong một thiết lập nâng cao hơn, pipeline này có thể mở rộng để chạy mô hình nhận diện vật thể (object detection) tại chỗ và kích hoạt sự kiện, ví dụ gửi thông tin lên hàng đợi Amazon Simple Queue Service (Amazon SQS) dựa trên các điều kiện được phát hiện.\nTuy nhiên, trong demo này, chúng tôi ưu tiên tính rõ ràng và minh bạch. Node sẽ phát hiện khoảng cách của một vật thể đặt trước Raspberry Pi và đẩy giá trị này vào bảng DynamoDB mỗi 10 giây.\nBước 1: Yêu cầu phần cứng và thiết lập Cảm biến siêu âm HC-SR04:\nĐiện trở 1kΩ và 2kΩ (dùng trong mạch chia điện áp)\nDây nối (Jumper Wires)\nBreadboard\nChúng tôi sử dụng breadboard để nhanh chóng thử nghiệm mà không cần hàn. Breadboard giúp tối ưu hóa việc đi dây, hỗ trợ lặp nhanh, và đặt cảm biến HC-SR04 theo chiều đứng để tối ưu vị trí đo. Mỗi hàng trên breadboard chia sẻ điện liên tục, giúp đơn giản hóa kết nối.\nKết nối HC-SR04 với GPIO của Raspberry Pi\nKết nối chân 3.3V và GND của Raspberry Pi với đường nguồn (power rails) của breadboard.\nCắm cảm biến HC-SR04 vào breadboard. Sau đó kết nối:\nVCC → Breadboard + rail (dây đỏ)\nGND → Breadboard – rail (dây đen)\nTRIG → Raspberry Pi GPIO 4 (dây cam)\nECHO → Voltage divider → GPIO 17 (dây xanh)\nMạch chia điện áp sử dụng điện trở 1kΩ và 2kΩ mắc nối tiếp, giúp giảm tín hiệu 5V từ chân ECHO của cảm biến xuống khoảng 3.3V, an toàn cho GPIO của Raspberry Pi.\nSơ đồ minh họa được cung cấp để làm rõ cách bố trí này.\nBản đồ GPIO này sau này có thể được trừu tượng hóa và quản lý động qua Kubernetes ConfigMaps, giúp linh hoạt trong việc xử lý cấu hình phần cứng cho các deployment khác nhau. Chúng tôi sẽ trình bày chi tiết ở phần sau.\nBước 2: Triển khai bảng DynamoDB Chúng tôi lưu dữ liệu vào bảng DynamoDB có tên eks-timeseries, được tạo trong Region eu-west-1 . Bảng sử dụng schema như sau:\nPartition Key: yyyymmdd \\\nSort Key: hhmmss\nSchema này cho phép truy vấn theo thời gian một cách hiệu quả và phù hợp với các mô hình dữ liệu dạng time series, nơi dữ liệu được truy xuất theo ngày và sắp xếp theo dấu thời gian (timestamp).\nAWS CloudFormation template:\nResources: TimeSeriesTable: Type: AWS::DynamoDB::Table Properties: TableName: eks-timeseries AttributeDefinitions: - AttributeName: yyyymmdd AttributeType: S - AttributeName: hhmmss AttributeType: S KeySchema: - AttributeName: yyyymmdd KeyType: HASH - AttributeName: hhmmss KeyType: RANGE BillingMode: PAY_PER_REQUEST Tags: - Key: Environment Value: EdgeDemo Bước 3: Triển khai ứng dụng cảm biến Trong repository GitHub, có thư mục examples chứa dự án ultrasonic-demo. Thư mục này bao gồm:\nCác file manifest Kubernetes\nMã nguồn Python\nDockerfile để build image container\nBắt đầu bằng việc build Docker image từ thư mục ultrasonic-demo và đẩy lên container registry của bạn, ví dụ Amazon Elastic Container Registry (Amazon ECR).\nHãy chú ý phần ConfigMap trong manifest, vì nó định nghĩa các biến môi trường mà script Python cần để truy cập GPIO và DynamoDB, đồng thời cấu hình AWS CLI.\nĐể triển khai ứng dụng, chạy lệnh:\nkubectl apply -f manifest.yaml Sau khi triển khai, xác minh rằng pod ultrasonic-sensor đang chạy:\nkubectl get pods Tiếp theo, kiểm tra logs để giám sát dữ liệu từ cảm biến và các ghi chép vào DynamoDB:\nkubectl logs \u0026lt;pod-name\u0026gt; Bạn sẽ thấy các giá trị khoảng cách xuất hiện trong logs, và các kết quả tương tự cũng sẽ hiển thị trên bảng DynamoDB.\nBước 4: Triển khai frontend dashboard Để trực quan hóa dữ liệu từ cảm biến, chúng tôi xây dựng một frontend dashboard truy vấn dữ liệu trực tiếp từ DynamoDB và hiển thị dưới dạng biểu đồ cập nhật theo thời gian thực (live-updating chart).\nBất kỳ người dùng dữ liệu đã xác thực, kể cả các ứng dụng bên ngoài, đều có thể truy vấn DynamoDB trực tiếp.\nChúng tôi muốn tất cả ứng dụng đều được container hóa, do đó quyết định triển khai dashboard thông qua một deployment trong cụm.\nXem lại thư mục frontend trong repository để hiểu cấu trúc.\nBuild Docker image cho frontend và đẩy lên container registry, tương tự như cách đã làm với backend. Sau đó, cập nhật manifest Kubernetes được cung cấp.\nĐể triển khai ứng dụng, chạy lệnh:\nkubectl apply -f manifest.yaml Sau đó, bạn có thể thiết lập port-forwarding cho service trên máy local:\nkubectl port-forward svc/pi-dashboard 8080:80 Truy cập dashboard từ trình duyệt bằng cách mở http://localhost:8080.\nBạn sẽ thấy biểu đồ trực tiếp (live chart) cập nhật các giá trị khoảng cách theo thời gian thực, được truy xuất trực tiếp từ bảng DynamoDB.\nKết luận\nVậy là xong! Bạn vừa biến Raspberry Pi 5 thành một node của cụm Amazon EKS, hoạt động ngoài Amazon VPC, đọc dữ liệu thực từ cảm biến thông qua GPIO, và đẩy dữ liệu một cách an toàn lên đám mây bằng Amazon DynamoDB. Chúng tôi hy vọng ví dụ này với Raspberry Pi có thể làm minh họa thực tế cho cách kiến trúc Kubernetes lai (hybrid Kubernetes) kết nối các môi trường vật lý với đám mây, bất kể bạn đang làm việc với: Cảm biến trong nhà máy, Server tại cửa hàng bán lẻ, Engine xử lý inference trong bệnh viện hoặc sàn giao dịch. Đối với các tổ chức muốn hiện đại hóa hạ tầng phân tán, Amazon EKS Hybrid Nodes cung cấp một hướng đi thực tiễn. Bạn có thể build một lần và chạy trên đám mây, tại biên (edge), hoặc trên máy chủ bare metal của mình. Với sự linh hoạt và mạnh mẽ của phương pháp này, hiện tại là thời điểm lý tưởng để bắt đầu proof of concept và khám phá các khả năng cho tổ chức của bạn.\nMuốn tự thử nghiệm? Hãy tham khảo repository GitHub, clone ví dụ, và bắt đầu xây dựng. Ngoài ra, hãy xem hướng dẫn chính thức về Amazon EKS Hybrid Nodes, và liên hệ đội ngũ AWS của bạn nếu có thắc mắc khi bắt đầu.\n—\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\nVề các tác giả\nAlberto Crescini là Enterprise Solutions Architect tại AWS, hỗ trợ các công ty năng lượng và tiện ích ở Vương quốc Anh xây dựng hạ tầng cho quá trình chuyển đổi năng lượng. Anh hỗ trợ khách hàng trong các dự án như cân bằng lưới điện (grid balancing) và sản xuất năng lượng linh hoạt (flexible generation), đồng thời hướng dẫn họ hiện đại hóa hệ thống và nền tảng hyperscale thông qua lĩnh vực tập trung AWS Containers. Utkarsh Pundir là Containers Specialist Solutions Architect tại AWS, nơi anh hỗ trợ khách hàng xây dựng các giải pháp trên EKS. Các lĩnh vực trọng tâm của anh bao gồm kiến trúc lai (hybrid architecture) và triển khai workload Generative AI trên EKS như một phần của các sáng kiến go-to-market của AWS. Gladwin Neo là Containers Specialist Solutions Architect tại AWS, nơi anh hỗ trợ khách hàng di chuyển và hiện đại hóa các workload để triển khai trên Amazon Elastic Kubernetes Service (EKS) hoặc Amazon Elastic Container Service (ECS). "},{"uri":"https://datngo196.github.io/Internship_Report/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"This section will list and introduce the blogs I have translated:\nBlog 1 - Chứng nhận ISO năm 2025 và CSA STAR hiện đã khả dụng cùng với hai dịch vụ bổ sung Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - Tự động xoay vòng OIDC client secret với Application Load Balancer Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - Sử dụng Raspberry Pi 5 như các nút lai (Hybrid Nodes) của Amazon EKS cho các khối tải (workload) tại biên (edge) Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://datngo196.github.io/Internship_Report/4-eventparticipated/4.3-event3/","title":"AWS AI/ML &amp; GenAI Workshop","tags":[],"description":"","content":"Summary Report: “AWS AI/ML \u0026amp; GenAI Workshop” Event Objectives Provide an overview of the AI/ML landscape and trends in Vietnam Guide hands-on practice on Amazon SageMaker for building end-to-end ML models Deep dive into Generative AI with Amazon Bedrock (Foundation Models, Agents, Guardrails) Equip attendees with Prompt Engineering skills and RAG (Retrieval-Augmented Generation) application building Speakers AWS Experts Team (Specific speaker names were not listed, but the session was led by technical experts) Key Highlights Welcome \u0026amp; Introduction Landscape Overview: Update on the panorama of Artificial Intelligence and Machine Learning (AI/ML) in the Vietnam market. Networking: Ice-breaker activity to create an open atmosphere for the workshop. AWS AI/ML Services Overview (SageMaker) End-to-end ML Platform: Understand the workflow on Amazon SageMaker from Data preparation, Labeling, to Training and Tuning models. MLOps Integration: Integrating Machine Learning Operations (MLOps) to automate deployment. SageMaker Studio Demo: Experience the interface and features of SageMaker Studio directly through a live walkthrough. Generative AI with Amazon Bedrock Foundation Models Selection: Comparison and guide on selecting suitable foundation models like Claude, Llama, Titan. Prompt Engineering: Optimization techniques: Chain-of-Thought, Few-shot learning. RAG Architecture: \u0026ldquo;Retrieval-Augmented Generation\u0026rdquo; architecture and how to integrate Knowledge Bases to increase AI accuracy. Advanced Features: Using Bedrock Agents for multi-step workflows and Guardrails for content safety. Live Demo: Building a complete GenAI Chatbot using Amazon Bedrock right in the class. Key Takeaways Platform Capabilities SageMaker is a powerful tool for traditional Machine Learning tasks, standardizing the process from data to model. Bedrock provides the fastest shortcut to access Generative AI via API without managing complex infrastructure. Strategic Implementation RAG \u0026amp; Agents are two key technologies that help GenAI applications solve complex business problems rather than just simple chatting. Guardrails are an indispensable component to ensure AI operates within safety frameworks and complies with corporate regulations. Applying to Work Implement MLOps: Apply standard processes on SageMaker to manage model lifecycles in current projects. Build RAG Systems: Experiment with integrating internal documents into Bedrock Knowledge Base to create information retrieval assistants. Optimize Prompts: Apply Chain-of-Thought techniques to improve the response quality of existing chatbots. Model Evaluation: Use the learned criteria to select the most suitable model (Claude vs Llama) in terms of cost and performance for each use case. Event Experience The workshop was a balanced combination of traditional Machine Learning and modern Generative AI, providing a solid foundational knowledge.\nHands-on \u0026amp; Demo The SageMaker Studio walkthrough helped me clearly visualize a professional working environment for Data Scientists. The Building a Chatbot with Bedrock demo was a highlight, proving that creating GenAI applications has become easier and faster than ever. Market Insight The introduction to the AI landscape in Vietnam helped me position my business within the general trend and identify potential opportunities. Some event photos Add your event photos here\nOverall, this event equipped me with a full \u0026ldquo;toolkit\u0026rdquo;: from SageMaker for Predictive models to Bedrock for Generative models, ready for upcoming AI projects.\n"},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Successfully build the Hybrid DNS network architecture to integrate the On-Premise DNS system (simulated by AWS Managed Microsoft Active Directory) with Amazon Route 53 DNS service. Successfully configure Inbound Endpoint, Outbound Endpoint, and Resolver Rules for bidirectional DNS query routing. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Preparation and Network Infrastructure Initialization: Review Route 53 Resolver features. Create an EC2 Key Pair (e.g., hr-dns-key) for secure Remote Desktop access. Initialize the CloudFormation Template (e.g., hr-dns-vpc-stack) to deploy the foundational high-availability and secure network infrastructure (VPC, Subnets, Gateways). 09/15/2025 09/15/2025 3 - Infrastructure Finalization \u0026amp; RDGW Connection: Monitor CloudFormation stack completion. Reconfigure the VPC Security Group (SG): remove unused ports (3391, 443) and retain ICMP and RDP (3389). Connect to the Remote Desktop Gateway (RDGW) Host by downloading the RDP file, uploading the Key Pair to decrypt, and retrieving the Administrator password. 09/16/2025 09/16/2025 4 - Route 53 Outbound Endpoint Setup: Create the Route 53 Outbound Endpoint to allow Route 53 Resolver to forward DNS queries externally (to AD). Select the correct VPC and corresponding Security Group. Configure automatic IP addresses in two different Availability Zones. Wait for the endpoint status to become operational. 09/17/2025 09/17/2025 5 - Resolver Rules and Inbound Endpoint Setup: Create a Resolver Rule (type Forward) to forward DNS queries for the specific domain (e.g., onprem.example.com) to the AWS Managed Microsoft AD DNS IP addresses. Create the Route 53 Inbound Endpoint to allow the On-Premise DNS system (AD) to query the Route 53 Resolver, configuring it within private subnets. 09/18/2025 09/18/2025 6 - Testing and Resource Cleanup: Test results using the nslookup onprem.example.com command on the RDGW host. Verify that the query is resolved via the VPC DNS Resolver IP (VPC CIDR + 2, e.g., 10.0.0.2). Clean up resources: Delete Inbound/Outbound Endpoints. Disassociate the VPC from the Resolver Rule before deleting the Rule. Delete AWS Managed Microsoft Active Directory, and finally, delete the CloudFormation Stacks. 09/19/2025 09/19/2025 Week 3 Achievements: Successfully implemented the Hybrid DNS architecture using Route 53 Resolver. Configured the Outbound Endpoint to allow Route 53 Resolver to forward DNS queries externally (to AWS Managed AD). Created the Inbound Endpoint enabling the On-Premise DNS system (AD) to query the Route 53 Resolver. Resolver Rules (Forward type) were successfully established to route queries for onprem.example.com to the AWS Managed Microsoft AD DNS IP addresses. Testing using nslookup on the RDGW host confirmed successful bidirectional DNS resolution. Verified that queries were resolved via the VPC DNS Resolver IP (e.g., 10.0.0.2, defined as VPC CIDR + 2). Completed comprehensive resource cleanup to prevent unexpected costs. "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.3-s3-vpc/","title":"Project Structure","tags":[],"description":"","content":"Monorepo Architecture MapVibe uses a monorepo architecture managed by TurboRepo and Bun. This allows for:\nShared code and dependencies across multiple applications Efficient builds with caching Consistent tooling and configurations Simplified dependency management Directory Structure mapvibe/ ├── apps/ # Applications │ ├── web/ # Main frontend application │ ├── admin/ # Admin dashboard │ └── api/ # Backend API Lambda function ├── packages/ # Shared packages │ ├── types/ # TypeScript type definitions │ ├── ui-components/ # Shared React components │ ├── database/ # Database layer (Kysely) │ ├── api-functions/ # Shared API utilities │ ├── utils/ # Common utilities │ └── constants/ # Shared constants ├── infrastructure/ # Infrastructure as Code │ ├── terraform/ # Terraform configurations │ │ ├── main.tf # Main configuration │ │ └── modules/ # Terraform modules │ └── s3-cloudfront/ # S3 and CloudFront configs ├── scripts/ # Deployment and build scripts ├── package.json # Root package configuration ├── turbo.json # TurboRepo configuration └── tsconfig.json # TypeScript configuration Applications apps/web - Main user-facing web application\nBuilt with React 19, Vite, and TailwindCSS Features: Search, place discovery, reviews, user profiles Deployed to S3 + CloudFront apps/admin - Admin dashboard\nBuilt with React 19, Vite, and TailwindCSS Features: Content moderation, analytics, user management Deployed to separate S3 + CloudFront apps/api - Main API Lambda function\nHandles REST API endpoints Integrates with RDS, S3, Cognito, Bedrock Built with TypeScript and Node.js Shared Packages packages/types - Shared TypeScript types and interfaces packages/ui-components - Reusable React UI components packages/database - Database access layer using Kysely packages/utils - Common utility functions packages/constants - Application constants Infrastructure The infrastructure/ directory contains Terraform modules for:\nVPC and networking RDS PostgreSQL database Lambda functions (API, embeddings, RAG, OCR, Rekognition, etc.) API Gateway CloudFront and S3 Cognito User Pool Route53 and ACM WAF Content Monorepo Setup Application Details "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Verify Deployment","tags":[],"description":"","content":"Verify Resources After deployment, verify that all resources were created successfully:\n1. Check VPC aws ec2 describe-vpcs --filters \u0026#34;Name=tag:Project,Values=mapvibe\u0026#34; 2. Check RDS aws rds describe-db-instances --query \u0026#34;DBInstances[?contains(DBInstanceIdentifier, \u0026#39;mapvibe\u0026#39;)]\u0026#34; 3. Check Lambda Functions aws lambda list-functions --query \u0026#34;Functions[?contains(FunctionName, \u0026#39;mapvibe\u0026#39;)]\u0026#34; 4. Check API Gateway aws apigateway get-rest-apis --query \u0026#34;items[?contains(name, \u0026#39;mapvibe\u0026#39;)]\u0026#34; 5. Check CloudFront aws cloudfront list-distributions --query \u0026#34;DistributionList.Items[?contains(Aliases.Items[0], \u0026#39;mapvibe\u0026#39;)]\u0026#34; 6. Check Cognito aws cognito-idp list-user-pools --max-results 10 --query \u0026#34;UserPools[?contains(Name, \u0026#39;mapvibe\u0026#39;)]\u0026#34; 7. Check S3 Buckets aws s3 ls | grep mapvibe Test API Endpoint Test the API Gateway endpoint:\n# Get API Gateway URL from Terraform output API_URL=$(terraform output -raw api_gateway_url) # Test health endpoint (if available) curl $API_URL/health Check Database Connection Retrieve database credentials and test connection:\n# Get secret ARN SECRET_ARN=$(terraform output -raw db_secret_arn) # Get credentials aws secretsmanager get-secret-value --secret-id $SECRET_ARN # Test connection (requires psql) # Use credentials from secret to connect Verify CloudFront Distribution Check CloudFront distribution status:\nDIST_ID=$(terraform output -raw cloudfront_distribution_id) aws cloudfront get-distribution --id $DIST_ID Wait for status to be \u0026ldquo;Deployed\u0026rdquo; before accessing the site.\n"},{"uri":"https://datngo196.github.io/Internship_Report/4-eventparticipated/4.4-event4/","title":"AWS DevOps &amp; Modern Operations","tags":[],"description":"","content":"Summary Report: “AWS DevOps \u0026amp; Modern Operations” Event Objectives Build a DevOps mindset and master key efficiency metrics (DORA metrics) Establish a complete CI/CD process using AWS Developer Tools Modernize infrastructure management with Infrastructure as Code (IaC) using CloudFormation and CDK Deploy containerized applications (Docker) on ECS, EKS, and App Runner Set up a comprehensive Observability system for distributed applications Speakers AWS Experts Team (Specialists in DevOps, Containers, and Observability) Key Highlights DevOps Mindset \u0026amp; CI/CD DORA Metrics: Understanding the importance of Deployment Frequency, Lead Time for Changes, MTTR, and Change Failure Rate. Git Strategies: Comparison of GitFlow and Trunk-based development strategies. Pipeline Automation: Demo of a full CI/CD pipeline from CodeCommit (source), CodeBuild (build/test) to CodeDeploy (deployment), orchestrated by CodePipeline. Deployment Strategies: Safe deployment techniques: Blue/Green, Canary, and Rolling updates. Infrastructure as Code (IaC) CloudFormation: Managing infrastructure via templates, concept of Stacks, and Drift detection. AWS CDK: Using familiar programming languages to define infrastructure, leveraging \u0026ldquo;Constructs\u0026rdquo; and reusable patterns. IaC Choice: Discussion on criteria for choosing between CloudFormation and CDK depending on the project. Container Services Spectrum of Compute: From image management (ECR) to orchestration options: ECS (simplified), EKS (standard Kubernetes), and App Runner (maximum simplification). Microservices Deployment: Comparison and demo of microservices deployment on different platforms. Monitoring \u0026amp; Observability Full-stack Observability: Combining CloudWatch (Metrics, Logs, Alarms) and X-Ray (Distributed Tracing) for a comprehensive view of system health. Best Practices: Setting up Monitoring Dashboards and effective On-call processes. Key Takeaways Automation First CI/CD is not just a toolset but a culture that minimizes human error and accelerates release velocity. IaC is a mandatory standard for modern infrastructure, ensuring consistency across Dev/Test/Prod environments. Operational Excellence Observability is more critical than simple Monitoring, especially in Microservices architectures for error tracing. Choosing the right deployment strategy (like Blue/Green) helps reduce Downtime to zero. Applying to Work Refactor Pipeline: Transition current manual build processes to AWS CodePipeline with automated testing steps. Adopt CDK: Start using AWS CDK to define infrastructure for new projects instead of manual Console operations. Containerization: Dockerize applications and pilot deployment on AWS App Runner for smaller services. Setup Tracing: Integrate AWS X-Ray into applications to monitor latency between microservices. Event Experience The full-day event was intense but the content was very cohesive, moving logically from Mindset to Tools and Operations.\nIntegrated Workflow The \u0026ldquo;Full CI/CD pipeline walkthrough\u0026rdquo; demo was impressive, showing the complete picture of how code moves from a developer\u0026rsquo;s machine to Production. Understanding the clear differences and specific use cases for ECS vs EKS gave me confidence in proposing solutions for the company. Practical Focus Lessons on Deployment strategies (Feature flags, Canary) were very practical for solving the team\u0026rsquo;s \u0026ldquo;deployment fear.\u0026rdquo; The Career roadmap at the end provided clear direction for developing DevOps skills. Some event photos Add your event photos here\nOverall, the workshop systematized the entire body of knowledge regarding modern operations, helping me understand the tight coupling between Code, Infrastructure, and Monitoring.\n"},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives: Deep dive into AWS Compute services (EC2) including scaling and storage options. Implement data protection strategies using AWS Backup. Configure Hybrid Cloud Storage using AWS Storage Gateway. Master Amazon S3 for static website hosting, content delivery (CloudFront), and data management (Versioning/Replication). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Study EC2 core concepts including Instance types, AMIs, Key Pairs, differences between EBS and Instance Store, and practice launching an instance with User Data configuration 09/22/2025 09/22/2025 3 - Learn about EC2 Auto Scaling and Pricing options, then proceed to Lab 13 to deploy AWS Backup infrastructure, create a backup plan, and test the restoration process. 09/23/2025 09/23/2025 4 - Complete Lab 24 by setting up an EC2 for Storage Gateway, activating the Gateway, and creating File Shares. Start Lab 57 by creating an S3 bucket and loading initial data. 09/24/2025 09/24/2025 5 - Continue Lab 57 by enabling Static Website Hosting on S3, configuring public access settings, and setting up an Amazon CloudFront distribution to serve the website content. 09/25/2025 09/25/2025 6 - Finalize Lab 57 by exploring advanced features like Bucket Versioning, Lifecycle rules (moving objects), and Multi-Region Replication, followed by a complete resource cleanup. 09/26/2025 09/26/2025 Week 4 Achievements: Compute (EC2): Understood the differences between EBS and Instance Store. Learned how to use User Data to bootstrap instances. Configured EC2 Auto Scaling groups and understood pricing models. Data Protection: Successfully deployed AWS Backup to automate data backup and restoration procedures. Hybrid Storage: Created and configured AWS Storage Gateway to map file shares to cloud storage. Storage \u0026amp; CDN (S3 \u0026amp; CloudFront): Hosted a static website on Amazon S3. Integrated Amazon CloudFront for content delivery/caching. Implemented data management features: Versioning, Cross-Region Replication, and Lifecycle policies. "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"Configure Services","tags":[],"description":"","content":"Configure Environment Variables After infrastructure deployment, configure environment variables for applications:\nFrontend Configuration (apps/web/.env) VITE_API_URL=https://api.mapvibe.site VITE_COGNITO_USER_POOL_ID=\u0026lt;from-terraform-output\u0026gt; VITE_COGNITO_CLIENT_ID=\u0026lt;from-terraform-output\u0026gt; VITE_COGNITO_REGION=ap-southeast-1 VITE_CLOUDFRONT_DOMAIN=https://mapvibe.site Admin Configuration (apps/admin/.env) VITE_API_URL=https://api.mapvibe.site VITE_COGNITO_USER_POOL_ID=\u0026lt;from-terraform-output\u0026gt; VITE_COGNITO_CLIENT_ID=\u0026lt;from-terraform-output\u0026gt; VITE_COGNITO_REGION=ap-southeast-1 Run Database Migrations Run database migrations using the migration Lambda:\n# Get migration Lambda name MIGRATION_LAMBDA=$(terraform output -raw migration_lambda_name) # Invoke migration aws lambda invoke \\ --function-name $MIGRATION_LAMBDA \\ --payload \u0026#39;{}\u0026#39; \\ response.json # Check response cat response.json Configure Cognito Set up User Pool attributes (if needed) Configure OAuth providers (Google, etc.) Set up email/SMS verification (if needed) Update Lambda Environment Variables Some Lambda functions may need additional environment variables. Check Terraform outputs and update if necessary.\nTest Endpoints Test the deployed endpoints:\nAPI Gateway: https://api.mapvibe.site Frontend: https://mapvibe.site Admin: https://admin.mapvibe.site Cognito Hosted UI: https://login.mapvibe.site Next Steps Once infrastructure is deployed and configured:\nBuild and deploy frontend applications Deploy Lambda functions Test the complete system "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.4-s3-onprem/","title":"Infrastructure Setup","tags":[],"description":"","content":"Overview In this section, you will set up the AWS infrastructure for MapVibe using Terraform. The infrastructure includes:\nVPC and Networking - Virtual Private Cloud with subnets and security groups RDS PostgreSQL - Database for storing application data Lambda Functions - Serverless compute for API and processing API Gateway - REST API endpoint management CloudFront \u0026amp; S3 - CDN and static asset storage Cognito - User authentication and authorization Route53 \u0026amp; ACM - DNS and SSL certificate management WAF - Web Application Firewall for security Secrets Manager - Secure credential storage Terraform Configuration The infrastructure is defined in infrastructure/terraform/ using Terraform modules for each AWS service.\nContent Terraform Setup Deploy Infrastructure Verify Deployment Configure Services "},{"uri":"https://datngo196.github.io/Internship_Report/4-eventparticipated/4.5-event5/","title":"AWS Security Specialty Workshop","tags":[],"description":"","content":"Summary Report: “AWS Security Specialty Workshop” Event Objectives Deeply understand the role of the Security Pillar within the Well-Architected Framework Master the 5 security pillars: IAM, Detection, Infrastructure, Data Protection, Incident Response Update on top security threats in the Vietnam cloud market Practice reviewing permissions (IAM) and building Incident Response (IR) Playbooks Speakers AWS Security Experts Team (Specialized in security architecture and compliance) Key Highlights Foundation \u0026amp; Identity (Pillar 1) Core Principles: Strictly applying Least Privilege, Zero Trust, and Defense in Depth principles. Modern IAM: Shifting from IAM Users (long-term credentials) to IAM Roles and AWS Identity Center (SSO) for centralized management. Access Control: Using Service Control Policies (SCPs) and Permission Boundaries to limit permission scopes in multi-account environments. Mini Demo: Practice Validating IAM Policies and simulating access to detect security flaws. Detection \u0026amp; Infrastructure (Pillar 2 \u0026amp; 3) Continuous Monitoring: Enabling CloudTrail (org-level), GuardDuty, and Security Hub for continuous monitoring. Logging Strategy: Logging at every layer: VPC Flow Logs (network), ALB logs (application), S3 logs (storage). Network Security: Network segmentation with VPC, combining Security Groups and NACLs. Edge protection with WAF, Shield, and Network Firewall. Data Protection \u0026amp; Incident Response (Pillar 4 \u0026amp; 5) Encryption: Encrypting data in-transit and at-rest on S3, EBS, RDS using KMS. Secrets Management: Eliminating hard-coded credentials by using Secrets Manager and Parameter Store with rotation mechanisms. IR Automation: Building Playbooks for common incidents (compromised keys, malware) and automating isolation processes using Lambda/Step Functions. Key Takeaways Zero Trust Mindset Identity is the new perimeter: In the Cloud environment, Identity is the most critical defense barrier, not IP addresses. Never trust by default; always verify and grant least privilege. Automation is Key Manual security cannot keep up with the speed of the Cloud. Detection-as-Code and Auto-remediation must be applied to minimize human risk. Applying to Work Review IAM: Audit all IAM Users, delete old keys, and switch to IAM Roles for applications. Enable GuardDuty: Activate GuardDuty across all regions/accounts to detect anomalous behaviors. Implement Secrets Manager: Replace config files containing DB passwords with API calls to Secrets Manager. Draft IR Playbook: Write an incident response procedure for \u0026ldquo;Compromised IAM Key\u0026rdquo; scenarios and rehearse with the team. Event Experience The workshop dove deep into technical details, comprehensively covering the security aspects that a Cloud Engineer needs to master.\nComprehensive Framework Structuring content by the 5 Pillars helped me systematize previously scattered security knowledge into a standard framework. The section on Top threats in Vietnam was very practical, helping identify specific risks within the local context. Practical Demos The demos on Access Analyzer and Validate IAM Policy were extremely useful, solving the daily headache of debugging permissions. The Incident Response section helped me understand that \u0026ldquo;detection\u0026rdquo; is only half the story; automated \u0026ldquo;response\u0026rdquo; is the goal. Some event photos Add your event photos here\nOverall, the event confirmed that security is not a blocker but an enabler that allows businesses to operate faster and more securely.\n"},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives: Master advanced Amazon S3 features (Storage Classes, Lifecycle, Access Points) and Glacier. Understand Hybrid Cloud solutions using AWS Storage Gateway and the Snow Family. Learn to migrate on-premises Virtual Machines to AWS (VM Import/Export). Deploy and manage Windows File Server file systems (FSx) with Multi-AZ configurations. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Watch Module 04 theory videos covering S3 Storage Classes, Access Points, Static Website Hosting, CORS, and the Snow Family, then start Lab 13 by creating S3 buckets and deploying backup infrastructure. 09/29/2025 09/29/2025 3 - Complete Lab 13 by setting up notifications and testing the restore process, then begin Lab 14 by preparing VMWare Workstation and exporting a virtual machine from on-premises environment.\n09/30/2025 09/30/2025 4 - Continue Lab 14 by uploading the VM to AWS, importing it as an AMI, and launching an instance; proceed to Lab 24 to initialize a Storage Gateway service. 10/01/2025 10/01/2025 5 - Finalize Lab 24 by creating File Shares and mounting them on a local machine, then start Lab 25 to create SSD and HDD Multi-AZ file systems (FSx for Windows File Server). 10/02/2025 10/02/2025 6 - Complete the setup of Multi-AZ file systems in Lab 25, review all storage concepts learned during the week, and perform a thorough cleanup of all created resources (S3, Gateways, File Systems). 10/03/2025 10/03/2025 Week 5 Achievements: Advanced Storage: Deepened understanding of S3 performance, security (CORS/ACL), and archival strategies with Glacier. Explored the AWS Snow Family for offline data transfer. Backup \u0026amp; Migration: Successfully configured AWS Backup notifications and tested data restoration. Performed a \u0026ldquo;Lift and Shift\u0026rdquo; migration by importing a VMWare virtual machine into AWS EC2. Hybrid \u0026amp; File Systems: Bridged on-premise and cloud storage using AWS Storage Gateway. Deployed highly available Windows File Systems (FSx) with Multi-AZ SSD/HDD configurations. "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.5-policy/","title":"Development &amp; Deployment","tags":[],"description":"","content":"Overview This section covers the development workflow and deployment process for MapVibe applications.\nDevelopment Workflow Local Development\nRun frontend apps locally with bun run dev Test API locally with bun run dev in apps/api Use local database or connect to dev RDS Build Process\nBuild all packages: bun run build Build specific app: cd apps/web \u0026amp;\u0026amp; bun run build Testing\nType checking: bun run type-check Linting: bun run lint Deployment Process Deploy Infrastructure cd infrastructure/terraform terraform apply Deploy API # Build API cd apps/api bun run build # Deploy using script bun run deploy # Or use: pwsh ../../scripts/deploy-api.ps1 Deploy Frontend (Web) # Build frontend cd apps/web bun run build # Deploy to S3 + CloudFront bun run deploy Deploy Admin Dashboard # Build admin cd apps/admin bun run build # Deploy using script pwsh ../../scripts/deploy-admin.ps1 Run Database Migrations pwsh scripts/deploy-migrate.ps1 Deployment Scripts The scripts/ directory contains PowerShell scripts for deployment:\ndeploy-api.ps1 - Deploy API Lambda deploy-admin.ps1 - Deploy admin dashboard deploy-migrate.ps1 - Run database migrations build-all-lambdas.ps1 - Build all Lambda functions Best Practices Always test locally before deploying Use environment-specific configurations Monitor CloudWatch logs after deployment Verify deployments by testing endpoints Keep infrastructure in sync with code changes "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/","title":"Workshop","tags":[],"description":"","content":"MapVibe - Building an AI-Powered Location Discovery Platform Overview MapVibe is a modern web application that helps users discover dining and activity locations using natural language queries powered by AWS AI services. Built with a monorepo architecture using TurboRepo and Bun, MapVibe leverages AWS serverless services to provide a scalable, cost-effective solution.\nIn this workshop, you will learn how to:\nSet up and configure a monorepo project structure Deploy infrastructure using Terraform on AWS Build and deploy serverless Lambda functions Configure AWS services including RDS, Cognito, CloudFront, API Gateway, and Bedrock Develop a full-stack application with React frontend and Node.js backend The project demonstrates modern cloud architecture patterns using:\nMonorepo Architecture - TurboRepo for efficient builds and dependency management Serverless Backend - AWS Lambda functions for API endpoints and processing AI Integration - AWS Bedrock for natural language processing and embeddings Infrastructure as Code - Terraform for managing AWS resources Modern Frontend - React 19 with Vite and TailwindCSS Content Workshop overview Prerequisites Project Structure Infrastructure Setup Development \u0026amp; Deployment Cleanup "},{"uri":"https://datngo196.github.io/Internship_Report/4-eventparticipated/4.6-event6/","title":"Workshop: Data Science on AWS","tags":[],"description":"","content":"Summary Report: “Workshop: Data Science on AWS” Event Objectives Explore the complete journey of building a modern Data Science system from theory to practice. Understand the end-to-end Data Science Pipeline on AWS, from storage to processing and deployment. Gain hands-on experience with real-world datasets (IMDb) and practical models (Sentiment Analysis). Analyze the trade-offs between Cloud and On-premise infrastructures regarding cost and performance. Speakers Mr. Văn Hoàng Kha – Cloud Solutions Architect, AWS Community Builder Mr. Bạch Doãn Vương – Cloud DevOps Engineer, AWS Community Builder Key Highlights 1. Cloud in Data Science \u0026amp; Pipeline Overview Importance of Cloud: Discussed why modern data science relies on the cloud for scalability and integration, moving away from rigid on-premise constraints. The AWS Data Science Pipeline: Storage: Using Amazon S3 as the foundational data lake. ETL/Processing: Utilizing AWS Glue for serverless data integration. [cite_start]Modeling: Leveraging Amazon SageMaker as the central hub for building, training, and deploying models[cite: 212]. [cite_start]The session overviewed the broad AWS AI/ML stack, which encompasses AI services, ML services, and infrastructure[cite: 201]. 2. Practical Demos Demo 1: Data Processing with AWS Glue: Scenario: Processing and cleaning raw data from the IMDb dataset. Technique: Demonstrated how to handle feature engineering and data preparation efficiently. [cite_start]The workshop highlighted different approaches, ranging from low-code options like SageMaker Canvas [cite: 209] [cite_start]to code-first methods using Numpy/Pandas[cite: 210]. Demo 2: Sentiment Analysis with SageMaker: Scenario: Training and deploying a machine learning model to analyze text sentiment. [cite_start]Workflow: Showcased the \u0026ldquo;Train, Tune, Deploy\u0026rdquo; lifecycle within SageMaker Studio[cite: 212]. [cite_start]The session also touched upon \u0026ldquo;Bring Your Own Model\u0026rdquo; (BYOM) concepts, demonstrating flexibility with frameworks like TensorFlow and PyTorch[cite: 213]. 3. Strategic Discussions Cloud vs. On-Premise: A deep dive into cost optimization and performance metrics. The discussion highlighted how cloud elasticity allows for experimenting with heavy workloads without the massive upfront capital expenditure of on-premise hardware. Mini-Project Guidance: Introduction to a post-workshop project designed to reinforce the skills learned. Key Takeaways Technical Workflow Unified Pipeline: A robust data science workflow is not just about the code; it requires seamless integration between storage (S3), cleaning (Glue), and modeling (SageMaker). [cite_start]Tool Selection: Understanding when to use managed services (like Amazon Comprehend or Textract [cite: 202, 203]) versus building custom models on SageMaker is crucial for efficiency. Industry Application Real-world Context: The transition from academic theory to industry application lies in automation and scalability. Cost Awareness: Successful data projects must balance model accuracy with computational costs. Applying to Work Adopt AWS Glue: Migrate local ETL scripts to AWS Glue for automated, serverless data cleaning on larger datasets. SageMaker Deployment: Move experimental models from local Jupyter notebooks to SageMaker Studio to standardize the training and deployment process. Project Implementation: Execute the suggested mini-project to solidify understanding of the IMDb processing workflow. Event Experience The “Data Science on AWS” workshop was a bridge between university curriculum and enterprise reality.\nDirect Connection: It connected academic knowledge with the technologies used by top global enterprises. Practical Insight: Watching the IMDb dataset being cleaned and a Sentiment Analysis model being deployed live demystified the complexity of cloud-based AI. Expert Guidance: The interaction with AWS Community Builders provided deep insights into the \u0026ldquo;Cloud vs. On-premise\u0026rdquo; debate, helping me understand the strategic value of cloud migration beyond just technical features. Some event photos Add your event photos here\n"},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives: Master advanced administration of Amazon FSx for Windows File Server (Performance, Deduplication, Quotas). Deploy a global static website using Amazon S3 and Amazon CloudFront. Implement S3 data resiliency strategies (Versioning, Replication, Lifecycle). Understand the fundamentals of AWS Security, Identity, and Access Management (IAM \u0026amp; Cognito). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Deep dive into Lab 25 advanced features including creating file shares, testing and monitoring performance, enabling data deduplication, shadow copies, and managing user sessions and storage quotas. 10/06/2025 10/06/2025 3 - Finalize Lab 25 by practicing throughput and storage scaling, then delete the environment. Start Lab 57 by creating an S3 bucket, loading data, and enabling static website hosting features. 10/07/2025 10/07/2025 4 - Continue Lab 57 by configuring public access blocks and public objects, then set up and test an Amazon CloudFront distribution to serve the static website content with low latency. 10/08/2025 10/08/2025 5 - Complete Lab 57 with data management tasks: implementing Bucket Versioning, moving objects via Lifecycle rules, configuring Multi-Region Replication, and finally cleaning up all Lab resources. 10/09/2025 10/09/2025 6 - Begin Module 05 by studying the AWS Shared Responsibility Model, understanding the core concepts of AWS Identity and Access Management (IAM), and getting an overview of Amazon Cognito. 10/10/2025 10/10/2025 Week 6 Achievements: Advanced File Storage (FSx): Configured storage efficiency features like Data Deduplication and Shadow Copies. Managed user access controls through sessions and storage quotas. Performed scaling operations for throughput and storage capacity. Content Delivery \u0026amp; S3: Successfully hosted a static website on S3 and accelerated delivery using CloudFront CDN. Implemented data protection and lifecycle strategies (Versioning, Replication). Security Fundamentals: Grasped the Shared Responsibility Model between AWS and the customer. Understood the role of IAM for access control and Cognito for user identity management. "},{"uri":"https://datngo196.github.io/Internship_Report/5-workshop/5.6-cleanup/","title":"Cleanup","tags":[],"description":"","content":"Overview Congratulations on completing the MapVibe workshop!\nIn this workshop, you learned:\nHow to set up a monorepo with TurboRepo and Bun How to deploy serverless infrastructure using Terraform How to build and deploy React applications How to configure AWS services (Lambda, RDS, API Gateway, CloudFront, Cognito) How to integrate AI services (Bedrock, Rekognition, Textract) Cleanup Resources To avoid ongoing costs, clean up all AWS resources when you\u0026rsquo;re done.\n1. Destroy Infrastructure with Terraform The easiest way to clean up is using Terraform:\ncd infrastructure/terraform # Review what will be destroyed terraform plan -destroy # Destroy all resources terraform destroy This will remove:\nAll Lambda functions API Gateway RDS database instance CloudFront distributions S3 buckets (if empty) Cognito User Pool VPC and networking resources Route53 hosted zones WAF web ACLs Secrets Manager secrets Note: Some resources may take time to delete (e.g., RDS final snapshot, CloudFront propagation).\n2. Manual Cleanup (if needed) If Terraform destroy doesn\u0026rsquo;t remove everything, manually clean up:\nS3 Buckets:\n# List buckets aws s3 ls | grep mapvibe # Empty and delete each bucket aws s3 rm s3://bucket-name --recursive aws s3 rb s3://bucket-name CloudWatch Logs:\n# Delete log groups aws logs describe-log-groups --query \u0026#34;logGroups[?contains(logGroupName, \u0026#39;mapvibe\u0026#39;)]\u0026#34; --output table aws logs delete-log-group --log-group-name \u0026lt;log-group-name\u0026gt; Route53 Hosted Zones:\n# List hosted zones aws route53 list-hosted-zones --query \u0026#34;HostedZones[?contains(Name, \u0026#39;mapvibe\u0026#39;)]\u0026#34; # Delete hosted zone (requires deleting all records first) aws route53 delete-hosted-zone --id \u0026lt;hosted-zone-id\u0026gt; 3. Verify Cleanup Verify all resources are deleted:\n# Check Lambda functions aws lambda list-functions --query \u0026#34;Functions[?contains(FunctionName, \u0026#39;mapvibe\u0026#39;)]\u0026#34; # Check S3 buckets aws s3 ls | grep mapvibe # Check RDS instances aws rds describe-db-instances --query \u0026#34;DBInstances[?contains(DBInstanceIdentifier, \u0026#39;mapvibe\u0026#39;)]\u0026#34; Important Notes Data Loss: Destroying infrastructure will delete all data (database, S3 objects, etc.) Backup: Export any important data before cleanup Costs: Some resources (like RDS snapshots) may incur minimal storage costs DNS: If using a custom domain, update DNS records after cleanup Next Steps After cleanup:\nReview what you learned Experiment with modifications Consider production deployment patterns Explore additional AWS services Thank you for completing the MapVibe workshop!\n"},{"uri":"https://datngo196.github.io/Internship_Report/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"During my internship at Amazon Web Services Vietnam Co., Ltd. from 08/09/2025 to 19/12/2025, I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment. I participated in FCJ Cloud Intern, through which I improved my skills in Cloud Computing architecture, Infrastructure as Code (AWS CDK), DevOps practices (CI/CD), Generative AI applications, and professional communication.\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ☐ ☐ ✅ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ☐ ✅ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ✅ ☐ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ☐ ✅ ☐ 7 Communication Presenting ideas and reporting work clearly ✅ ☐ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ✅ ☐ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Needs Improvement Strengthen discipline and strictly comply with the rules and regulations of the company or any organization Improve problem-solving thinking Enhance communication skills in both daily interactions and professional contexts, including handling situations effectively "},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Understand enterprise security structures using AWS Organizations and Identity Center. Implement security posture management with AWS Security Hub and encryption with KMS. Build automated incident response workflows using AWS Lambda and Slack integration. Master resource organization and management using Tagging strategies and Resource Groups. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Watch theory videos on AWS Organizations, Identity Center, KMS, and Security Hub. Complete Lab 18 by enabling Security Hub to assess security scores and then cleaning up resources. 10/13/2025 10/13/2025 3 - Begin Lab 22 to build an automated response system. Set up the network infrastructure (VPC, Security Groups), launch an EC2 instance, and configure an Incoming Webhook for Slack integration. 10/14/2025 10/14/2025 4 - Finalize Lab 22 by creating IAM Roles for Lambda, deploying functions to automatically stop/start instances, and verifying the automation results through Slack notifications before cleanup. 10/15/2025 10/15/2025 5 - Perform Lab 27 to focus on resource management. Practice launching EC2 instances with tags, managing tags via both Console and CLI, and filtering resources efficiently. 10/16/2025 10/16/2025 6 - Complete Lab 27 by creating Resource Groups based on tags and cleaning up. Start Lab 28 by learning how to create and configure a secure IAM User. 10/17/2025 10/17/2025 Week 7 Achievements: Security Governance: Gained insight into managing multi-account environments with AWS Organizations and Identity Center. Used AWS Security Hub to monitor compliance and security standards. Automation \u0026amp; Integration: Successfully built a serverless automation workflow using AWS Lambda to manage EC2 states. Integrated AWS services with third-party tools (Slack) for real-time monitoring. Resource Management: Applied advanced tagging strategies to organize cloud resources. Utilized Resource Groups and CLI commands for efficient bulk resource management. "},{"uri":"https://datngo196.github.io/Internship_Report/4-eventparticipated/4.7-event7/","title":"Vietnam Cloud Day","tags":[],"description":"","content":"Summary Report: “Vietnam Cloud Day” Event Objectives Provide strategic insights for executive leadership on navigating the Generative AI revolution. Share best practices for building a unified, scalable data foundation on AWS. Introduce the AI-Driven Development Lifecycle (AI-DLC) and its impact on software implementation. Explore security fundamentals for Generative AI and the future of AI Agents. Speakers Eric Yeo – Country GM, Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS Dr. Jens Lottner – CEO, Techcombank Ms. Trang Phung – CEO \u0026amp; Co-Founder, U2U Network Jaime Valles – VP \u0026amp; GM APJ, AWS Jeff Johnson, Vu Van (ELSA), Nguyen Hoa Binh (Nexttech), Dieter Botha (TymeX) – Panelists Kien Nguyen, Jun Kai Loke, Tamelly Lim, Binh Tran, Taiki Dang, Michael Armentano – AWS Specialists Key Highlights 1. Strategic Leadership \u0026amp; Vision Keynotes: Industry leaders from AWS, Techcombank, and U2U Network shared their vision for cloud and AI adoption in the region. Executive Panel: A discussion on \u0026ldquo;Navigating the GenAI Revolution,\u0026rdquo; focusing on fostering an innovation culture, aligning AI with business objectives, and managing organizational change during AI integration. 2. Data Foundation \u0026amp; Roadmap Unified Data Foundation: The session outlined how to build a robust infrastructure handling data ingestion, storage, processing, and governance—a critical prerequisite for advanced analytics and AI workloads. GenAI Roadmap: AWS presented its comprehensive vision and emerging trends to empower organizations to leverage GenAI for efficiency. 3. The Future of Software Development AI-Driven Development Lifecycle (AI-DLC): A transformative approach where AI is not just an assistant but a central collaborator. It integrates AI-powered execution with human oversight to drastically improve speed and innovation, moving beyond traditional methods. 4. Security \u0026amp; Advanced Automation Securing GenAI: Addressed security at three layers: infrastructure, models, and applications. Emphasized built-in measures like encryption, zero-trust architecture, and fine-grained access controls. AI Agents: The closing session highlighted a paradigm shift from basic automation to Intelligent Agents—partners that learn, adapt, and execute complex tasks autonomously. Key Takeaways Cultural Shift AI-DLC: Software development is evolving from \u0026ldquo;human-driven with AI assistance\u0026rdquo; to \u0026ldquo;AI-centric collaboration,\u0026rdquo; requiring a shift in how teams approach coding and testing. Agents vs. Automation: There is a distinct difference between static automation scripts and dynamic AI Agents that can make decisions and adapt to changing inputs. Technical Pillars Data First: You cannot have successful GenAI without a unified and governed data foundation. Security by Design: Security for GenAI must be continuous and layered, ensuring data confidentiality throughout the lifecycle. Applying to Work Assess Data Readiness: Review current AWS data infrastructure to ensure it meets the scalability and governance requirements for GenAI (per the Unified Data Foundation session). Explore AI Agents: Identify manual, complex operational tasks that could be offloaded to autonomous AI Agents rather than simple scripts. Adopt AI-DLC: Experiment with embedding AI tools more deeply into the dev lifecycle to act as collaborators rather than just code completers. Event Experience This summit provided a holistic view of the GenAI landscape, balancing high-level executive strategy with deep technical dives.\nStrategic Insight: The panel with leaders from ELSA, Nexttech, and TymeX offered valuable real-world perspectives on managing the cultural changes AI brings. Technical Depth: The afternoon tracks were particularly useful, specifically the deep dive into AI-DLC and Securing GenAI, which are immediate concerns for our technical roadmap. Some event photos Add your event photos here\n"},{"uri":"https://datngo196.github.io/Internship_Report/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":"Overall Evaluation 1. Working Environment: The environment at FCJ is highly professional and strongly encourages a \u0026ldquo;Builder\u0026rdquo; mindset. The workspace is always filled with positive energy, not only comfortable but also inspiring creativity. I particularly appreciate how everyone debates candidly and constructively, not afraid of friction to find the optimal solution. Additionally, interns like myself can sit at the same table and discuss directly with mentors without hierarchical barriers. The open space is a key factor that helps me maintain excitement every day when arriving at the office.\n2. Support from Mentor / Team Admin: My mentor acted not just as a technical guide but as a problem-solving mindset coach. Instead of simply giving \u0026ldquo;right or wrong\u0026rdquo; answers, he often asked, \u0026ldquo;Why did you choose this approach?\u0026rdquo; or \u0026ldquo;If the user base scales 10x, will this still work?\u0026rdquo; This coaching method helped me hone my critical thinking and be more meticulous with every line of code. Support from the admin team was very swift, especially in granting access to Cloud resources and paid tools necessary for work.\n3. Relevance of Work to Academic Major: Knowledge of Operating Systems, Computer Networks, or Data Structures learned at school provided a good foundation, but applying them to actual work here elevated them to a new level. I was exposed to real-world problems regarding Cloud Computing, Microservices, and DevOps – areas where school often stops at theory. However, this is exactly what I liked most because it forced me to apply foundational knowledge to real production problems, helping bridge the gap between a student and a professional engineer.\n4. Learning \u0026amp; Skill Development Opportunities: This internship felt like an intensive career boot camp. Regarding technical skills (Hard skills), I became more proficient in using Git flow, writing Infrastructure as Code (IaC), and debugging distributed systems. As for soft skills, I learned how to work within Agile/Scrum processes, how to write technical documentation that is easy for others to understand, and most importantly, communication skills – knowing how to ask the right questions to the right people at the right time to solve problems fastest.\n5. Company Culture \u0026amp; Team Spirit: The company culture values transparency and the spirit of \u0026ldquo;Knowledge Sharing.\u0026rdquo; When an incident occurs, instead of finding someone to blame, the whole team sits down to conduct a Root Cause Analysis to ensure the error doesn\u0026rsquo;t repeat. Teamwork is also exceptional; I never felt alone when facing difficulties because colleagues were always ready to support, share documentation, or pair-program to help me untangle issues. Tech Talk sessions are great opportunities to bond and learn from each other.\n6. Internship Policies / Benefits: Being supported with an AWS account for unrestricted practice (sandbox environment) is a fantastic benefit for technical roles. Additionally, policies supporting international certification exams are a huge motivation for me to strive harder.\nAdditional Questions Most satisfying aspect: I participated in real projects, deployed code to real environments, and saw the actual impact of the features I built. Area for improvement: The initial technical documentation onboarding process is a bit fragmented, taking quite some time to piece together. Would you recommend it: Definitely YES. This is an ideal environment for those passionate about Cloud and technology, who want to experience real-world working pressure. Suggestions \u0026amp; Expectations Suggestion: Should organize more cross-team \u0026ldquo;Code Review\u0026rdquo; sessions between different intern groups to learn from each other\u0026rsquo;s coding styles and thinking. Future intent: I strongly hope to have the opportunity to become a full-time employee (Fresher/Junior) to continue contributing to unfinished projects and further develop the skills I have just started to grasp. Other comments: Thank you to the company for creating a truly high-quality playground for students. "},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Master advanced IAM concepts: Cross-region access, Role Switching, and Attribute-Based Access Control (ABAC) using Tags. Implement restrictive security policies and test IAM User boundaries. Deploy comprehensive data security and auditing using KMS, CloudTrail, and Amazon Athena. Simulate real-world identity management scenarios with IAM Groups and Admin Roles. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Complete Lab 28 by creating IAM Policies and Roles, practicing Switch Roles to access resources in different regions (Tokyo/N. Virginia) based on Tag compliance. Perform Lab 30 to create restriction policies and test IAM user limits. 10/20/2025 10/20/2025 3 - Begin Lab 33 focused on audit and encryption. Create necessary IAM Policies, Roles, Groups, and Users, then initialize a Key Management Service (KMS) key and prepare an S3 bucket for secure data upload. 10/21/2025 10/21/2025 4 - Finalize Lab 33 by configuring CloudTrail to log API events, setting up Amazon Athena to query those logs, and testing the sharing of KMS-encrypted data on S3 before cleaning up. 10/22/2025 10/22/2025 5 - Start Lab 44 to reinforce IAM structural knowledge. Create IAM Groups and Users, and perform detailed permission checks to understand how policies affect user access rights. 10/23/2025 10/23/2025 6 - Complete Lab 44 by creating an Admin IAM Role and configuring the Switch Role mechanism for privilege elevation. Review all security concepts learned and perform a full resource cleanup. 10/24/2025 10/24/2025 Week 8 Achievements: Advanced Identity Management: Successfully implemented Switch Role mechanisms for secure cross-role access. Enforced access controls based on resource tags (ABAC) across different AWS regions. Managed user permissions effectively using Groups and Restriction Policies. Security \u0026amp; Compliance: Secured data at rest using AWS KMS encryption. Established an audit trail using AWS CloudTrail and analyzed logs using SQL queries in Amazon Athena. "},{"uri":"https://datngo196.github.io/Internship_Report/4-eventparticipated/4.8-event8/","title":"Workshop: Data Science on AWS","tags":[],"description":"","content":"Summary Report: “Kick-off AWS First Cloud Journey Workforce OJT FALL 2025” Summary Report: “Workshop: Data Science on AWS” Event Objectives Officially launch the AWS First Cloud Journey (FCJ) Workforce OJT program for Fall 2025. Connect students with industry leaders from AWS, VNG, and G-Asia Pacific. Provide career orientation in Cloud Computing, DevOps, and GenAI. Share inspiring alumni stories and promote diversity with \u0026ldquo;She in Tech\u0026rdquo;. Speakers Mr. Nguyễn Trần Phước Bảo – Head of Enterprise Relations (School Representative) Mr. Nguyễn Gia Hưng – Head of Solutions Architect, AWS Vietnam Mr. Đỗ Huy Thắng – DevOps Lead, VNG Mr. Danh Hoàng Hiếu Nghị – GenAI Engineer, Renova Ms. Bùi Hồ Linh Nhi – AI Engineer, SoftwareOne Mr. Phạm Nguyễn Hải Anh – Cloud Engineer, G-Asia Pacific Mr. Nguyễn Đồng Thanh Hiệp – Principal Cloud Engineer, G-Asia Pacific Key Highlights 1. Opening \u0026amp; Vision Academic Partnership: Mr. Nguyễn Trần Phước Bảo opened the ceremony, emphasizing the strategic collaboration between the university and enterprises to bridge the gap between academic training and industry needs. Future Orientation: Mr. Nguyễn Gia Hưng (AWS) presented the vision of the \u0026ldquo;First Cloud Journey,\u0026rdquo; outlining how this OJT program serves as a launchpad for future cloud architects in Vietnam. 2. Career Pathways: DevOps \u0026amp; GenAI DevOps Reality: Mr. Đỗ Huy Thắng from VNG shared a realistic view of the DevOps career path, highlighting the essential skills required to survive and thrive in a major tech corporation. FCJ to GenAI: Alumni speakers Danh Hoàng Hiếu Nghị and Bùi Hồ Linh Nhi showcased their rapid evolution from FCJ interns to AI/GenAI Engineers, proving the program\u0026rsquo;s effectiveness. 3. Diversity \u0026amp; Daily Life She in Tech: Ms. Linh Nhi\u0026rsquo;s session highlighted the growing role of women in technology, encouraging female students to pursue technical roles in Cloud and AI. A Day in the Life: Speakers from G-Asia Pacific (Mr. Hải Anh \u0026amp; Mr. Hiệp) provided a transparent look at the daily responsibilities of a Cloud Engineer, from junior tasks to principal-level decision-making. Key Takeaways Career Roadmap Multiple Paths: The cloud industry offers diverse trajectories—from pure infrastructure (Cloud Engineer) to automation (DevOps) and cutting-edge innovation (GenAI). Foundation is Key: Success in specialized roles like GenAI starts with a strong foundation in Cloud Computing concepts gained during this OJT. Professional Mindset Adaptability: The transition from university to enterprise requires a shift in mindset—proactivity and continuous learning are non-negotiable. Community: Networking with mentors and alumni provides a crucial support system for career growth. Applying to Work Set OJT Goals: Define specific technical milestones (e.g., getting certified, mastering a specific AWS service) for the upcoming internship period based on speaker advice. Connect with Mentors: actively engage with the speakers and mentors introduced during the networking session. Explore GenAI: Dedicate time during the OJT to explore Generative AI services on AWS, as recommended by the alumni speakers. Event Experience Held at the Bitexco Financial Tower, the kick-off event set a professional and inspiring tone for the semester.\nAtmosphere: The energy was high, with a strong sense of community between the new cohort, alumni, and industry experts. Inspiration: Hearing former students share their success stories (\u0026ldquo;From FCJ to GenAI Engineer\u0026rdquo;) made the career goals feel tangible and achievable. Some event photos Add your event photos here\n"},{"uri":"https://datngo196.github.io/Internship_Report/4-eventparticipated/4.9-event9/","title":"CloudThinker: Agentic AI &amp; Orchestration on AWS","tags":[],"description":"","content":"Summary Report: “CloudThinker: Agentic AI \u0026amp; Orchestration on AWS” Event Objectives Deep dive into AWS Bedrock Agent Core and its capabilities. Explore real-world use cases for building Agentic Workflows. Understand advanced concepts like Agentic Orchestration and Context Optimization at a technical level (L300). Gain hands-on experience through the CloudThinker Hack workshop. Speakers Mr. Nguyen Gia Hung – Head of Solutions Architect, AWS Mr. Kien Nguyen – Solutions Architect, AWS Mr. Viet Pham – Founder \u0026amp; CEO Mr. Thang Ton – Co-founder \u0026amp; COO, CloudThinker Mr. Henry Bui – Head of Engineering, CloudThinker Mr. Kha Van – Workshop Facilitator Key Highlights 1. AWS Foundation Opening: Mr. Nguyen Gia Hung set the stage for the importance of Agentic AI in the current cloud landscape. Bedrock Agent Core: Mr. Kien Nguyen provided a technical overview of AWS Bedrock Agent Core, explaining how it simplifies the creation of agents that can plan and execute tasks by invoking APIs. 2. Practical Application \u0026amp; Use Cases Building Agentic Workflows: Mr. Viet Pham demonstrated a concrete use case, showing the end-to-end process of designing and deploying an agentic workflow on AWS. CloudThinker Introduction: Mr. Thang Ton introduced the CloudThinker ecosystem and their vision for AI-driven cloud solutions. 3. Deep Dive (Level 300) Agentic Orchestration \u0026amp; Context Optimization: This was the technical core of the morning. Mr. Henry Bui discussed advanced strategies for orchestrating multiple agents and optimizing context within Amazon Bedrock to ensure high accuracy and relevance in complex interactions. 4. Hands-on Experience CloudThinker Hack: Led by Mr. Kha Van, this 60-minute session allowed attendees to get their hands dirty, applying the morning\u0026rsquo;s concepts to build a prototype agent using the CloudThinker framework and AWS services. Key Takeaways Evolution of AI From Chat to Action: The industry is shifting from passive chatbots to active Agents that can perform complex orchestration and execute API calls. Context is Critical: As workflows get more complex, standard context windows aren\u0026rsquo;t enough. \u0026ldquo;Context Optimization\u0026rdquo; strategies are essential to keep costs down and accuracy up. Architecture Orchestration Patterns: Managing multiple agents require a robust orchestration layer to decide which agent handles which part of a user request. Applying to Work Prototype an Agent: Use AWS Bedrock Agent to build a simple internal tool that connects to a company API (e.g., checking leave balance or server status). Study Context Patterns: Research the context optimization techniques shared by Henry Bui to apply to our current RAG implementations. Participate in Hackathons: Encourage the team to join similar hands-on hacks to stay sharp on the latest AWS features. Event Experience This event was highly technical and focused.\nTechnical Depth: The L300 session on Orchestration was particularly valuable for understanding how to scale AI applications beyond simple demos. Interactive: The \u0026ldquo;CloudThinker Hack\u0026rdquo; provided immediate reinforcement of the theoretical knowledge, making it one of the most effective learning sessions. Some event photos Add your event photos here\n"},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Objectives: Finalize IAM security best practices by comparing Access Keys vs. IAM Roles. Understand AWS Database services (RDS, Aurora, Redshift, ElastiCache) and general database concepts. Deploy a 2-tier architecture web application using Amazon EC2 and Amazon RDS. Perform database operations including backup, restoration, and connectivity via RDP. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Complete Lab 44 by implementing conditional switch roles (IP/Time limits). Proceed to Lab 48 to practice generating IAM Access Keys versus using IAM Roles for EC2, understanding why Roles are more secure. 10/27/2025 10/27/2025 3 - Study Module 06 theory videos covering fundamental database concepts (OLTP/OLAP), Amazon RDS \u0026amp; Aurora architectures, and overview of specialized DBs like Redshift and ElastiCache.\n10/28/2025 10/28/2025 4 - Start Lab 05 (Deploying Web App with RDS) by setting up the network foundation: creating a VPC, configuring EC2 and RDS Security Groups, defining DB Subnet Groups, and launching the EC2 instance. 10/29/2025 10/29/2025 5 - Continue Lab 05 by provisioning an Amazon RDS database instance, configuring the application on EC2 to connect to the database, and verifying the successful deployment of the web application. 10/30/2025 10/30/2025 6 - Finalize Lab 05 by performing database backup and restore operations, then clean up all resources. Begin Lab 43 by learning how to connect to Windows instances using an RDP Client. 10/31/2025 10/31/2025 Week 9 Achievements: IAM Security Mastery: Implemented advanced conditional access policies (Date/IP based). Demonstrated the security benefits of using IAM Roles over long-term Access Keys. Database Implementation: Grasped the differences between various AWS database offerings (Relational vs. Key-value vs. Warehousing). Successfully deployed a managed Relational Database (RDS) inside a VPC. Application Deployment: Connected a web application hosted on EC2 to a backend RDS instance. Performed critical database maintenance tasks like snapshots and restoration. "},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Objectives: Perform heterogeneous database migrations (SQL Server/Oracle to Aurora MySQL) using AWS SCT and DMS. Troubleshoot complex migration scenarios involving schema conversion, memory pressure, and table errors. Build a Serverless Data Analytics pipeline using Amazon Kinesis, Glue, and Athena. Visualize business intelligence data using Amazon QuickSight. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Begin Lab 43 by connecting via EC2 Fleet Manager, configuring Source databases (SQL Server/Oracle), handling constraints, and preparing the Target Aurora MySQL environment. 11/03/2025 11/03/2025 3 - Continue Lab 43 by using the Schema Conversion Tool (SCT) to convert schemas, creating Migration Tasks and Endpoints, and launching a Serverless Migration process. 11/04/2025 11/04/2025 4 - Finalize Lab 43 by monitoring logs, troubleshooting specific test scenarios (Memory Pressure, Table Errors), validating the migrated data, and cleaning up migration resources. 11/05/2025 11/05/2025 5 - Start Module 07 (Lab 35) by setting up the ingestion layer: creating an S3 Bucket, configuring a Kinesis Data Firehose Delivery Stream, and generating sample data for analysis. 11/06/2025 11/06/2025 6 - Complete Lab 35 by configuring an AWS Glue Crawler to catalog data, performing SQL analysis with Amazon Athena, creating visualizations in QuickSight, and cleaning up resources. 11/07/2025 11/07/2025 Week 10 Achievements: Database Migration: Successfully migrated data from heterogeneous sources (SQL Server, Oracle) to AWS Aurora MySQL. Mastered the AWS Schema Conversion Tool (SCT) and Database Migration Service (DMS). Gained experience in troubleshooting migration failures (memory issues, mapping errors). Data Analytics Pipeline: Built a complete serverless data pipeline: Ingestion (Kinesis) -\u0026gt; Storage (S3) -\u0026gt; Catalog (Glue). Analyzed large datasets using SQL queries in Amazon Athena without managing servers. Business Intelligence: Connected Amazon QuickSight to the data source to create interactive visual reports. "},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11 Objectives: Master NoSQL database design and operations using Amazon DynamoDB (Backup, Global Tables). Implement cost allocation strategies using Tagging and Cost Management tools. Utilize AWS developer tools (CloudShell, SDK) for programmatic resource management. Perform visual data preparation, profiling, and cleaning using AWS Glue DataBrew. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Deep dive into Amazon DynamoDB (Lab 39): Explore the console, perform backup/restore operations, and study advanced design patterns for building global serverless applications. 11/10/2025 11/10/2025 3 - Complete Lab 40 focusing on Cost Allocation: Build a database, populate data, apply tagging strategies to track usage, and query cost allocation tags to understand spending patterns. 11/11/2025 11/11/2025 4 - Perform Lab 60 to practice managing AWS resources using command-line interfaces: Amazon CloudShell and the AWS SDK, understanding the difference between Console and programmatic access. 11/12/2025 11/12/2025 5 - Begin Lab 70 for data preparation: Launch a Cloud9 environment, download and upload datasets to S3, set up AWS Glue DataBrew, and run data profiling to understand data quality. 11/13/2025 11/13/2025 6 - Finalize Lab 70 by cleaning and transforming data with DataBrew recipes. Proceed to Lab 72 to ingest, store, and catalog data into the AWS Glue Data Catalog, then clean up all resources. 11/14/2025 11/14/2025 Week 11 Achievements: Serverless Database (NoSQL): Gained proficiency in DynamoDB core concepts and event-driven architectures. Implemented backup strategies for NoSQL data. Cost \u0026amp; Management: Applied effective tagging strategies for granular cost tracking and reporting. Demonstrated ability to interact with AWS via CLI/SDK in CloudShell. Data Engineering: Utilized AWS Glue DataBrew to profile and clean raw data without writing code. Built a foundational data catalog for analytics workflows. "},{"uri":"https://datngo196.github.io/Internship_Report/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Week 12 Objectives: Master advanced ETL (Extract, Transform, Load) processes using AWS Glue, DataBrew, and Amazon EMR. Implement real-time analytics with Kinesis and data warehousing with Amazon Redshift. Create professional, interactive Business Intelligence (BI) dashboards using Amazon QuickSight. Final Review: Consolidate knowledge from Modules 1-7 and finalize the end-of-term Worklog. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Perform advanced data transformation tasks in Lab 72 using various AWS Glue methods (Interactive Sessions, GUI, DataBrew) and process big data using Amazon EMR. 11/17/2025 11/17/2025 3 - Continue Lab 72 by running SQL queries with Amazon Athena, performing real-time analytics using Kinesis Data Analytics, and creating initial visualizations in QuickSight. 11/18/2025 11/18/2025 4 - Finalize Lab 72 by automating data serving via AWS Lambda and setting up a robust Data Warehouse using Amazon Redshift for complex query performance. 11/19/2025 11/19/2025 5 - Complete Lab 73 by building, refining, and publishing interactive Business Intelligence dashboards in Amazon QuickSight to visualize key insights.\n11/20/2025 11/20/2025 6 - General Review: Review key concepts from Modules 1 to 7, ensure all cloud resources are deleted to prevent costs, and finalize the complete Term Worklog for submission. 11/21/2025 11/21/2025 Week 12 Achievements: Advanced Data Engineering: Executed complex data transformations using Serverless (Glue) and Cluster-based (EMR) services. Built a Data Warehouse infrastructure using Amazon Redshift. Analytics \u0026amp; BI: Implemented real-time data stream processing with Kinesis. Designed and deployed interactive dashboards on Amazon QuickSight for decision-making support. Course Completion: Successfully reviewed the entire cloud journey (Compute, Storage, Database, Security, Analytics). Completed the final Worklog and cleaned up the AWS environment. "},{"uri":"https://datngo196.github.io/Internship_Report/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://datngo196.github.io/Internship_Report/tags/","title":"Tags","tags":[],"description":"","content":""}]